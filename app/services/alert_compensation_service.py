#!/usr/bin/env python
# -*- coding: utf-8 -*-

import logging
import asyncio
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from app.db.session import get_db
from app.models.alert import Alert, AlertResponse
from app.services.alert_service import connected_clients, DateTimeEncoder
from app.services.rabbitmq_client import rabbitmq_client
from app.core.config import settings

logger = logging.getLogger(__name__)

class AlertCompensationService:
    """æŠ¥è­¦è¡¥å¿æœåŠ¡ - å¤„ç†æœªæˆåŠŸå¤„ç†çš„æŠ¥è­¦"""
    
    def __init__(self):
        # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°
        self.compensation_interval = settings.ALERT_COMPENSATION_INTERVAL  # è¡¥å¿æ£€æŸ¥é—´éš”
        self.max_retry_hours = settings.ALERT_MAX_RETRY_HOURS  # æœ€å¤§é‡è¯•å°æ—¶æ•°
        self.max_compensation_count = settings.ALERT_MAX_COMPENSATION_COUNT  # å•æ¬¡æœ€å¤§è¡¥å¿æ•°é‡
        self.new_client_backfill_hours = settings.ALERT_NEW_CLIENT_BACKFILL_HOURS  # æ–°å®¢æˆ·ç«¯å›å¡«å°æ—¶æ•°
        self.is_running = False
        
    async def start_compensation_service(self):
        """å¯åŠ¨è¡¥å¿æœåŠ¡"""
        if self.is_running:
            logger.warning("æŠ¥è­¦è¡¥å¿æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
            
        self.is_running = True
        logger.info("ğŸ”„ å¯åŠ¨æŠ¥è­¦è¡¥å¿æœåŠ¡")
        
        while self.is_running:
            try:
                await self._check_and_compensate()
                await asyncio.sleep(self.compensation_interval)
            except Exception as e:
                logger.error(f"âŒ è¡¥å¿æœåŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
                await asyncio.sleep(5)  # å¼‚å¸¸æ—¶çŸ­æš‚ç­‰å¾…
    
    def stop_compensation_service(self):
        """åœæ­¢è¡¥å¿æœåŠ¡"""
        self.is_running = False
        logger.info("â¹ï¸ åœæ­¢æŠ¥è­¦è¡¥å¿æœåŠ¡")
    
    async def _check_and_compensate(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œè¡¥å¿é€»è¾‘"""
        if not connected_clients:
            logger.debug("ğŸ“¡ æ²¡æœ‰SSEå®¢æˆ·ç«¯è¿æ¥ï¼Œè·³è¿‡è¡¥å¿æ£€æŸ¥")
            return
        
        # 1. æ£€æŸ¥æœ€è¿‘çš„æœªå¹¿æ’­æŠ¥è­¦
        recent_alerts = self._get_recent_alerts()
        if not recent_alerts:
            logger.debug("âœ… æ²¡æœ‰éœ€è¦è¡¥å¿çš„æŠ¥è­¦")
            return
        
        logger.info(f"ğŸ” å‘ç° {len(recent_alerts)} ä¸ªå¯èƒ½éœ€è¦è¡¥å¿çš„æŠ¥è­¦")
        
        # 2. å¯¹æ–°è¿æ¥çš„å®¢æˆ·ç«¯æ¨é€æœ€è¿‘æŠ¥è­¦
        await self._compensate_recent_alerts(recent_alerts)
        
        # 3. æ£€æŸ¥RabbitMQæ­»ä¿¡é˜Ÿåˆ—ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        await self._check_dead_letter_queue()
    
    def _get_recent_alerts(self) -> List[Alert]:
        """è·å–æœ€è¿‘çš„æŠ¥è­¦è®°å½•"""
        try:
            with next(get_db()) as db:
                # è·å–æœ€è¿‘1å°æ—¶çš„æŠ¥è­¦
                cutoff_time = datetime.now() - timedelta(hours=1)
                alerts = (db.query(Alert)
                         .filter(Alert.timestamp >= cutoff_time)
                         .order_by(Alert.timestamp.desc())
                         .limit(50)  # é™åˆ¶æ•°é‡é¿å…è¿‡è½½
                         .all())
                
                logger.debug(f"ğŸ“Š æŸ¥è¯¢åˆ°æœ€è¿‘1å°æ—¶å†… {len(alerts)} ä¸ªæŠ¥è­¦")
                return alerts
                
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æœ€è¿‘æŠ¥è­¦å¤±è´¥: {str(e)}")
            return []
    
    async def _compensate_recent_alerts(self, alerts: List[Alert]):
        """å‘SSEå®¢æˆ·ç«¯è¡¥å¿æ¨é€æœ€è¿‘çš„æŠ¥è­¦"""
        if not alerts:
            return
        
        # åªå‘"æ–°"å®¢æˆ·ç«¯æ¨é€ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥è®°å½•å®¢æˆ·ç«¯è¿æ¥æ—¶é—´ï¼‰
        client_count = len(connected_clients)
        logger.info(f"ğŸ”„ å¼€å§‹å‘ {client_count} ä¸ªå®¢æˆ·ç«¯è¡¥å¿æ¨é€æœ€è¿‘çš„ {len(alerts)} ä¸ªæŠ¥è­¦")
        
        success_count = 0
        for alert in alerts[-10:]:  # åªæ¨é€æœ€è¿‘10ä¸ªï¼Œé¿å…è¿‡è½½
            try:
                # å°†Alertè½¬æ¢ä¸ºå­—å…¸
                alert_dict = AlertResponse.from_orm(alert).dict()
                
                # æ·»åŠ è¡¥å¿æ ‡è¯†
                alert_dict['is_compensation'] = True
                alert_dict['compensation_time'] = datetime.now().isoformat()
                
                # æ„é€ SSEæ¶ˆæ¯
                message = json.dumps(alert_dict, cls=DateTimeEncoder)
                sse_message = f"data: {message}\n\n"
                
                # å‘é€ç»™æ‰€æœ‰å®¢æˆ·ç«¯
                tasks = []
                for client_queue in connected_clients.copy():
                    tasks.append(self._safe_send_to_client(client_queue, sse_message))
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                client_success = sum(1 for result in results if result is True)
                
                if client_success > 0:
                    success_count += 1
                    logger.debug(f"ğŸ“¤ è¡¥å¿æ¨é€æŠ¥è­¦ [ID={alert.id}] åˆ° {client_success}/{client_count} ä¸ªå®¢æˆ·ç«¯")
                
            except Exception as e:
                logger.warning(f"âš ï¸ è¡¥å¿æ¨é€æŠ¥è­¦ [ID={alert.id}] å¤±è´¥: {str(e)}")
        
        if success_count > 0:
            logger.info(f"âœ… æˆåŠŸè¡¥å¿æ¨é€ {success_count}/{len(alerts[-10:])} ä¸ªæŠ¥è­¦")
    
    async def _safe_send_to_client(self, client_queue: asyncio.Queue, message: str) -> bool:
        """å®‰å…¨å‘é€æ¶ˆæ¯åˆ°å®¢æˆ·ç«¯"""
        try:
            # ä½¿ç”¨çŸ­è¶…æ—¶é¿å…é˜»å¡
            await asyncio.wait_for(client_queue.put(message), timeout=1.0)
            return True
        except (asyncio.TimeoutError, Exception):
            return False
    
    async def _check_dead_letter_queue(self):
        """æ£€æŸ¥RabbitMQæ­»ä¿¡é˜Ÿåˆ—ä¸­çš„å¤±è´¥æ¶ˆæ¯"""
        try:
            logger.debug("ğŸ” æ£€æŸ¥RabbitMQæ­»ä¿¡é˜Ÿåˆ—...")
            
            # è·å–æ­»ä¿¡æ¶ˆæ¯
            dead_messages = rabbitmq_client.get_dead_letter_messages(max_count=self.max_compensation_count)
            
            if not dead_messages:
                logger.debug("ğŸ“­ æ­»ä¿¡é˜Ÿåˆ—ä¸ºç©º")
                return
            
            logger.info(f"ğŸ’€ å‘ç° {len(dead_messages)} æ¡æ­»ä¿¡æ¶ˆæ¯éœ€è¦å¤„ç†")
            
            # å¤„ç†æ¯æ¡æ­»ä¿¡æ¶ˆæ¯
            processed_count = 0
            failed_count = 0
            
            for dead_info in dead_messages:
                try:
                    message_data = dead_info['message_data']
                    delivery_tag = dead_info['delivery_tag']
                    retry_count = dead_info.get('retry_count', 0)
                    death_count = dead_info.get('death_count', 0)
                    
                    # åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡æ–°å¤„ç†
                    should_reprocess = self._should_reprocess_dead_message(dead_info)
                    
                    if should_reprocess:
                        # é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯
                        success = rabbitmq_client.reprocess_dead_message(
                            delivery_tag, 
                            message_data, 
                            increase_retry=True
                        )
                        
                        if success:
                            processed_count += 1
                            logger.info(f"âœ… æ­»ä¿¡æ¶ˆæ¯é‡æ–°å¤„ç†æˆåŠŸ: ID={message_data.get('alert_id', 'unknown')}, "
                                      f"ç±»å‹={message_data.get('alert_type', 'unknown')}")
                        else:
                            failed_count += 1
                            logger.error(f"âŒ æ­»ä¿¡æ¶ˆæ¯é‡æ–°å¤„ç†å¤±è´¥: ID={message_data.get('alert_id', 'unknown')}")
                    else:
                        # æ°¸ä¹…ä¸¢å¼ƒè¯¥æ¶ˆæ¯
                        rabbitmq_client.channel.basic_ack(delivery_tag=delivery_tag)
                        failed_count += 1
                        logger.warning(f"ğŸ—‘ï¸ æ­»ä¿¡æ¶ˆæ¯å·²æ°¸ä¹…ä¸¢å¼ƒ: ID={message_data.get('alert_id', 'unknown')}, "
                                     f"é‡è¯•æ¬¡æ•°={retry_count}, æ­»ä¿¡æ¬¡æ•°={death_count}")
                    
                    # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡å¿«å¤„ç†
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    failed_count += 1
                    logger.error(f"âŒ å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¼‚å¸¸: {str(e)}")
            
            if processed_count > 0 or failed_count > 0:
                logger.info(f"ğŸ“Š æ­»ä¿¡é˜Ÿåˆ—å¤„ç†å®Œæˆ: æˆåŠŸ={processed_count}, å¤±è´¥={failed_count}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥æ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
    
    def _should_reprocess_dead_message(self, dead_info: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ­»ä¿¡æ¶ˆæ¯æ˜¯å¦åº”è¯¥é‡æ–°å¤„ç†"""
        try:
            retry_count = dead_info.get('retry_count', 0)
            death_count = dead_info.get('death_count', 0)
            dead_reason = dead_info.get('dead_reason', '')
            first_death_time = dead_info.get('first_death_time')
            
            # 1. æ£€æŸ¥é‡è¯•æ¬¡æ•°é™åˆ¶ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            if retry_count >= settings.DEAD_LETTER_MAX_RETRY_COUNT:
                logger.debug(f"ğŸ’€ æ­»ä¿¡æ¶ˆæ¯é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™: {retry_count}")
                return False
            
            # 2. æ£€æŸ¥æ­»ä¿¡æ¬¡æ•°é™åˆ¶ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
            if death_count >= settings.DEAD_LETTER_MAX_DEATH_COUNT:
                logger.debug(f"ğŸ’€ æ­»ä¿¡æ¶ˆæ¯æ­»ä¿¡æ¬¡æ•°å·²è¾¾ä¸Šé™: {death_count}")
                return False
            
            # 3. æ£€æŸ¥æ—¶é—´é™åˆ¶ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼Œè½¬æ¢ä¸ºç§’ï¼‰
            if first_death_time:
                try:
                    import dateutil.parser
                    death_time = dateutil.parser.parse(first_death_time)
                    time_diff = datetime.now() - death_time.replace(tzinfo=None)
                    if time_diff.total_seconds() > settings.DEAD_LETTER_REPROCESS_TIME_LIMIT:
                        logger.debug(f"ğŸ’€ æ­»ä¿¡æ¶ˆæ¯è¶…è¿‡æ—¶é—´é™åˆ¶: {time_diff}")
                        return False
                except:
                    pass
            
            # 4. æ£€æŸ¥æ­»ä¿¡åŸå› 
            if dead_reason in ['rejected', 'expired']:
                # è¢«æ‹’ç»æˆ–è¿‡æœŸçš„æ¶ˆæ¯ï¼Œæ ¹æ®ä¸šåŠ¡é‡è¦æ€§å†³å®š
                message_data = dead_info.get('message_data', {})
                alert_level = message_data.get('alert_level', 1)
                
                # é«˜çº§åˆ«æŠ¥è­¦ç»§ç»­é‡è¯•ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
                if alert_level >= settings.DEAD_LETTER_HIGH_PRIORITY_LEVEL:
                    logger.info(f"ğŸ”¥ é«˜çº§åˆ«æŠ¥è­¦æ­»ä¿¡æ¶ˆæ¯å‡†å¤‡é‡è¯•: level={alert_level}")
                    return True
                else:
                    logger.debug(f"âš ï¸ ä½çº§åˆ«æŠ¥è­¦æ­»ä¿¡æ¶ˆæ¯è·³è¿‡é‡è¯•: level={alert_level}")
                    return False
            
            # 5. å…¶ä»–æƒ…å†µé»˜è®¤é‡è¯•
            logger.debug(f"ğŸ”„ æ­»ä¿¡æ¶ˆæ¯ç¬¦åˆé‡è¯•æ¡ä»¶: retry={retry_count}, death={death_count}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ¤æ–­æ­»ä¿¡æ¶ˆæ¯é‡è¯•æ¡ä»¶å¤±è´¥: {str(e)}")
            return False  # å¼‚å¸¸æƒ…å†µä¸‹ä¸é‡è¯•ï¼Œé¿å…æ— é™å¾ªç¯
    
    async def compensate_for_new_client(self, client_queue: asyncio.Queue, 
                                       hours_back: Optional[int] = None) -> bool:
        """ä¸ºæ–°è¿æ¥çš„å®¢æˆ·ç«¯è¡¥å¿æœ€è¿‘çš„æŠ¥è­¦"""
        try:
            # å¦‚æœæœªæŒ‡å®šå›å¡«å°æ—¶æ•°ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
            if hours_back is None:
                hours_back = self.new_client_backfill_hours
                
            logger.info(f"ğŸ”„ ä¸ºæ–°å®¢æˆ·ç«¯è¡¥å¿æœ€è¿‘ {hours_back} å°æ—¶çš„æŠ¥è­¦")
            
            with next(get_db()) as db:
                cutoff_time = datetime.now() - timedelta(hours=hours_back)
                recent_alerts = (db.query(Alert)
                               .filter(Alert.timestamp >= cutoff_time)
                               .order_by(Alert.timestamp.desc())
                               .limit(20)  # é™åˆ¶æ•°é‡
                               .all())
            
            if not recent_alerts:
                logger.info("ğŸ“­ æ²¡æœ‰æœ€è¿‘çš„æŠ¥è­¦éœ€è¦è¡¥å¿")
                return True
            
            success_count = 0
            for alert in reversed(recent_alerts):  # æŒ‰æ—¶é—´é¡ºåºå‘é€
                try:
                    alert_dict = AlertResponse.from_orm(alert).dict()
                    alert_dict['is_compensation'] = True
                    alert_dict['compensation_reason'] = 'new_client_backfill'
                    
                    message = json.dumps(alert_dict, cls=DateTimeEncoder)
                    sse_message = f"data: {message}\n\n"
                    
                    await asyncio.wait_for(
                        client_queue.put(sse_message), 
                        timeout=2.0
                    )
                    success_count += 1
                    
                    # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡å¿«æ¨é€
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ å‘æ–°å®¢æˆ·ç«¯æ¨é€æŠ¥è­¦ [ID={alert.id}] å¤±è´¥: {str(e)}")
                    break  # å¦‚æœå‘é€å¤±è´¥ï¼Œåœæ­¢ç»§ç»­å‘é€
            
            logger.info(f"âœ… ä¸ºæ–°å®¢æˆ·ç«¯æˆåŠŸè¡¥å¿ {success_count}/{len(recent_alerts)} ä¸ªæŠ¥è­¦")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ æ–°å®¢æˆ·ç«¯è¡¥å¿å¤±è´¥: {str(e)}")
            return False
    
    def get_compensation_stats(self) -> Dict[str, Any]:
        """è·å–è¡¥å¿æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡
            dead_letter_stats = rabbitmq_client.get_dead_letter_queue_stats()
            
            return {
                "compensation_service": {
                    "is_running": self.is_running,
                    "check_interval_seconds": self.compensation_interval,
                    "max_retry_hours": self.max_retry_hours,
                    "service_status": "è¿è¡Œä¸­" if self.is_running else "å·²åœæ­¢"
                },
                "sse_clients": {
                    "connected_count": len(connected_clients),
                    "status": "æ­£å¸¸" if len(connected_clients) >= 0 else "å¼‚å¸¸"
                },
                "dead_letter_queue": dead_letter_stats,
                "system_status": {
                    "overall": "æ­£å¸¸" if self.is_running and dead_letter_stats.get('status') == 'available' else "å¼‚å¸¸",
                    "timestamp": datetime.now().isoformat()
                }
            }
        except Exception as e:
            logger.error(f"âŒ è·å–è¡¥å¿æœåŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {
                "compensation_service": {
                    "is_running": self.is_running,
                    "service_status": "è¿è¡Œä¸­" if self.is_running else "å·²åœæ­¢",
                    "error": str(e)
                },
                "sse_clients": {
                    "connected_count": len(connected_clients)
                },
                "dead_letter_queue": {
                    "status": "error",
                    "error": str(e)
                },
                "system_status": {
                    "overall": "å¼‚å¸¸",
                    "timestamp": datetime.now().isoformat()
                }
            }

# åˆ›å»ºå…¨å±€è¡¥å¿æœåŠ¡å®ä¾‹
compensation_service = AlertCompensationService()

# å¯¼å‡ºç»™å¤–éƒ¨ä½¿ç”¨çš„å‡½æ•°
async def start_compensation_service():
    """å¯åŠ¨è¡¥å¿æœåŠ¡çš„å¤–éƒ¨æ¥å£"""
    await compensation_service.start_compensation_service()

def stop_compensation_service():
    """åœæ­¢è¡¥å¿æœåŠ¡çš„å¤–éƒ¨æ¥å£"""
    compensation_service.stop_compensation_service()

async def compensate_new_client(client_queue: asyncio.Queue) -> bool:
    """ä¸ºæ–°å®¢æˆ·ç«¯è¡¥å¿çš„å¤–éƒ¨æ¥å£"""
    return await compensation_service.compensate_for_new_client(client_queue)

def get_compensation_stats() -> Dict[str, Any]:
    """è·å–è¡¥å¿ç»Ÿè®¡çš„å¤–éƒ¨æ¥å£"""
    return compensation_service.get_compensation_stats() 