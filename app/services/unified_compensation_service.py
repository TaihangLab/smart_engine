#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ğŸ¯ å®‰é˜²é¢„è­¦å®æ—¶é€šçŸ¥ç³»ç»Ÿ - ç»Ÿä¸€è¡¥å¿æœåŠ¡
================================================
ä¼ä¸šçº§ä¸‰å±‚è¡¥å¿æ¶æ„å®Œæ•´å®ç°ï¼š
1. ğŸš€ ç”Ÿäº§ç«¯è¡¥å¿ï¼šæ¶ˆæ¯ç”Ÿæˆ â†’ é˜Ÿåˆ—
2. âš¡ æ¶ˆè´¹ç«¯è¡¥å¿ï¼šé˜Ÿåˆ— â†’ MySQLæŒä¹…åŒ–  
3. ğŸ“¡ é€šçŸ¥ç«¯è¡¥å¿ï¼šMySQL â†’ å‰ç«¯SSEæ¨é€

è®¾è®¡ç‰¹ç‚¹ï¼š
- çŠ¶æ€é©±åŠ¨è¡¥å¿æµç¨‹
- é›¶é…ç½®è‡ªåŠ¨è¿è¡Œ
- å…¨é“¾è·¯å¯è¿½è¸ªæ€§
- æ™ºèƒ½é‡è¯•ç­–ç•¥
- å®Œå–„ç›‘æ§ç»Ÿè®¡
"""

import asyncio
import logging
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from concurrent.futures import ThreadPoolExecutor
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, desc, func, text

from app.core.config import settings
from app.db.session import SessionLocal
from app.models.compensation import (
    AlertPublishLog, AlertNotificationLog, CompensationTaskLog,
    PublishStatus, NotificationStatus, NotificationChannel, CompensationTaskType,
    AlertPublishLogCreate, AlertNotificationLogCreate, CompensationTaskLogCreate
)
from app.models.alert import Alert, AlertStatus
from app.services.rabbitmq_client import rabbitmq_client
from app.services.sse_connection_manager import sse_manager
from app.utils.message_id_generator import generate_message_id

logger = logging.getLogger(__name__)


class CompensationStats:
    """è¡¥å¿ç»Ÿè®¡ä¿¡æ¯ç®¡ç†"""
    
    def __init__(self):
        self.stats = {
            "total_cycles": 0,
            "producer_compensated": 0,
            "consumer_compensated": 0,
            "notification_compensated": 0,
            "total_errors": 0,
            "last_execution": None,
            "average_cycle_time": 0.0,
            "success_rate": 100.0
        }
        self.lock = threading.Lock()
    
    def update_cycle_stats(self, cycle_time: float, errors: int = 0):
        """æ›´æ–°å‘¨æœŸç»Ÿè®¡"""
        with self.lock:
            self.stats["total_cycles"] += 1
            self.stats["total_errors"] += errors
            self.stats["last_execution"] = datetime.utcnow().isoformat()
            
            # è®¡ç®—å¹³å‡å‘¨æœŸæ—¶é—´
            if self.stats["average_cycle_time"] == 0:
                self.stats["average_cycle_time"] = cycle_time
            else:
                self.stats["average_cycle_time"] = (
                    self.stats["average_cycle_time"] * 0.7 + cycle_time * 0.3
                )
            
            # è®¡ç®—æˆåŠŸç‡
            if self.stats["total_cycles"] > 0:
                self.stats["success_rate"] = (
                    (self.stats["total_cycles"] - self.stats["total_errors"]) 
                    / self.stats["total_cycles"] * 100
                )
    
    def increment_compensation(self, layer: str, count: int = 1):
        """å¢åŠ è¡¥å¿è®¡æ•°"""
        with self.lock:
            if layer == "producer":
                self.stats["producer_compensated"] += count
            elif layer == "consumer":
                self.stats["consumer_compensated"] += count
            elif layer == "notification":
                self.stats["notification_compensated"] += count
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return self.stats.copy()


class UnifiedCompensationService:
    """
    ğŸ¯ ç»Ÿä¸€è¡¥å¿æœåŠ¡ - ä¼ä¸šçº§ä¸‰å±‚è¡¥å¿æ¶æ„
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç”Ÿäº§ç«¯è¡¥å¿ï¼šé‡æ–°å‘é€å¤±è´¥çš„æ¶ˆæ¯åˆ°RabbitMQ
    2. æ¶ˆè´¹ç«¯è¡¥å¿ï¼šå¤„ç†æ­»ä¿¡é˜Ÿåˆ—ï¼Œé‡æ–°æ¶ˆè´¹å¤±è´¥æ¶ˆæ¯
    3. é€šçŸ¥ç«¯è¡¥å¿ï¼šé‡æ–°å‘é€å¤±è´¥çš„SSEé€šçŸ¥
    4. æ™ºèƒ½é‡è¯•ï¼šæŒ‡æ•°é€€é¿ã€ç†”æ–­ä¿æŠ¤
    5. å…¨é“¾è·¯ç›‘æ§ï¼šå®Œæ•´çš„æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
    """
    
    def __init__(self):
        self.is_running = False
        self.is_initialized = False
        self._stop_event = asyncio.Event()
        self._background_task = None
        
        # é…ç½®å‚æ•°
        self.compensation_interval = settings.UNIFIED_COMPENSATION_INTERVAL
        self.batch_size = settings.COMPENSATION_BATCH_SIZE
        self.worker_threads = settings.COMPENSATION_WORKER_THREADS
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = CompensationStats()
        
        # çº¿ç¨‹æ± 
        self.thread_pool = ThreadPoolExecutor(
            max_workers=self.worker_threads,
            thread_name_prefix="compensation_worker"
        )
        
        logger.info(f"ğŸ¯ ç»Ÿä¸€è¡¥å¿æœåŠ¡åˆå§‹åŒ–å®Œæˆ - é—´éš”: {self.compensation_interval}s")
    
    async def start(self):
        """å¯åŠ¨è¡¥å¿æœåŠ¡"""
        if self.is_running:
            logger.warning("ğŸ”„ è¡¥å¿æœåŠ¡å·²åœ¨è¿è¡Œ")
            return
            
        if not settings.COMPENSATION_ENABLE:
            logger.info("ğŸš« è¡¥å¿æœºåˆ¶å·²ç¦ç”¨")
            return
            
        self.is_running = True
        self._stop_event.clear()
        
        logger.info("ğŸš€ å¯åŠ¨ç»Ÿä¸€è¡¥å¿æœåŠ¡ - ä¼ä¸šçº§ä¸‰å±‚è¡¥å¿æ¶æ„")
        
        try:
            # åˆå§‹åŒ–æ£€æŸ¥
            await self._initialize()
            
            # å¯åŠ¨åå°è¡¥å¿ä»»åŠ¡
            self._background_task = asyncio.create_task(self._compensation_loop())
            
        except Exception as e:
            logger.error(f"âŒ è¡¥å¿æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
            await self.stop()
    
    async def _compensation_loop(self):
        """è¡¥å¿ä¸»å¾ªç¯"""
        logger.info("ğŸ”„ è¡¥å¿ä¸»å¾ªç¯å·²å¯åŠ¨")
        
        while self.is_running and not self._stop_event.is_set():
            try:
                cycle_start_time = datetime.now()
                error_count = 0
                
                # æ‰§è¡Œè¡¥å¿å‘¨æœŸ
                try:
                    await self._execute_compensation_cycle()
                except Exception as e:
                    error_count = 1
                    logger.error(f"âŒ è¡¥å¿å‘¨æœŸæ‰§è¡Œå¼‚å¸¸: {e}")
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                cycle_duration = (datetime.now() - cycle_start_time).total_seconds()
                self.stats.update_cycle_stats(cycle_duration, error_count)
                
                # ç­‰å¾…ä¸‹ä¸€å‘¨æœŸ
                try:
                    await asyncio.wait_for(
                        self._stop_event.wait(), 
                        timeout=self.compensation_interval
                    )
                    break  # æ”¶åˆ°åœæ­¢ä¿¡å·
                except asyncio.TimeoutError:
                    continue  # è¶…æ—¶ï¼Œç»§ç»­ä¸‹ä¸€å¾ªç¯
                    
            except Exception as e:
                logger.error(f"âŒ è¡¥å¿ä¸»å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(5)  # çŸ­æš‚ä¼‘æ¯åç»§ç»­
    
    async def _initialize(self):
        """åˆå§‹åŒ–è¡¥å¿æœåŠ¡"""
        if self.is_initialized:
            return
            
        logger.info("ğŸ”§ åˆå§‹åŒ–è¡¥å¿æœåŠ¡...")
        
        try:
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            db = SessionLocal()
            db.execute(text("SELECT 1"))
            db.close()
            logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
            
            # æ£€æŸ¥RabbitMQè¿æ¥
            if rabbitmq_client.is_connected:
                logger.info("âœ… RabbitMQè¿æ¥æ­£å¸¸")
            else:
                logger.warning("âš ï¸ RabbitMQè¿æ¥å¼‚å¸¸ï¼Œè¡¥å¿åŠŸèƒ½å¯èƒ½å—å½±å“")
            
            self.is_initialized = True
            logger.info("âœ… è¡¥å¿æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è¡¥å¿æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _execute_compensation_cycle(self):
        """æ‰§è¡Œè¡¥å¿å‘¨æœŸ - ä¸‰å±‚å¹¶è¡Œè¡¥å¿ï¼ˆå”¯ä¸€æ‰§è¡Œæ¨¡å¼ï¼‰"""
        logger.debug("ğŸ”„ å¼€å§‹è¡¥å¿å‘¨æœŸ")
        
        # è®°å½•è¡¥å¿ä»»åŠ¡
        task_id = generate_message_id()
        await self._log_compensation_task(task_id, CompensationTaskType.MONITORING)
        
        try:
            # å¹¶è¡Œæ‰§è¡Œä¸‰å±‚è¡¥å¿ï¼ˆç³»ç»Ÿå”¯ä¸€æ‰§è¡Œæ¨¡å¼ï¼‰
            compensation_tasks = []
            
            if settings.PRODUCER_COMPENSATION_ENABLE:
                compensation_tasks.append(self._compensate_producer())
                
            if settings.CONSUMER_COMPENSATION_ENABLE:
                compensation_tasks.append(self._compensate_consumer())
                
            if settings.SSE_COMPENSATION_ENABLE:
                compensation_tasks.append(self._compensate_notification())
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è¡¥å¿ä»»åŠ¡
            if compensation_tasks:
                results = await asyncio.gather(*compensation_tasks, return_exceptions=True)
                
                # ç»Ÿè®¡ç»“æœ
                success_count = sum(1 for r in results if not isinstance(r, Exception))
                error_count = len(results) - success_count
                
                logger.info(f"âœ… è¡¥å¿å‘¨æœŸå®Œæˆ: æˆåŠŸ={success_count}, å¤±è´¥={error_count}")
                
                # æ›´æ–°ä»»åŠ¡æ—¥å¿—
                await self._complete_compensation_task(
                    task_id, "success" if error_count == 0 else "partial_success",
                    success_count, error_count
                )
            else:
                logger.debug("ğŸ“­ æ‰€æœ‰è¡¥å¿å±‚éƒ½å·²ç¦ç”¨")
                
        except Exception as e:
            logger.error(f"âŒ è¡¥å¿å‘¨æœŸæ‰§è¡Œå¤±è´¥: {e}")
            await self._complete_compensation_task(task_id, "failed", 0, 1, str(e))
            raise
    
    async def _compensate_producer(self) -> Dict[str, Any]:
        """
        ğŸš€ ç”Ÿäº§ç«¯è¡¥å¿ - é‡æ–°å‘é€å¤±è´¥çš„æ¶ˆæ¯åˆ°RabbitMQ
        
        å¤„ç†é€»è¾‘ï¼š
        1. æŸ¥æ‰¾PENDINGæˆ–FAILEDçŠ¶æ€çš„å‘å¸ƒè®°å½•
        2. æ£€æŸ¥é‡è¯•æ¬¡æ•°é™åˆ¶
        3. ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥é‡æ–°å‘é€
        4. æ›´æ–°å‘å¸ƒçŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯
        """
        logger.debug("ğŸš€ å¼€å§‹ç”Ÿäº§ç«¯è¡¥å¿")
        
        db = SessionLocal()
        compensated_count = 0
        
        try:
            # æŸ¥æ‰¾éœ€è¦è¡¥å¿çš„å‘å¸ƒè®°å½•
            failed_publishes = db.query(AlertPublishLog).filter(
                and_(
                    AlertPublishLog.status.in_([
                        PublishStatus.PENDING, 
                        PublishStatus.FAILED
                    ]),
                    AlertPublishLog.retries < AlertPublishLog.max_retries,
                    AlertPublishLog.created_at > datetime.utcnow() - timedelta(
                        hours=settings.ALERT_MAX_RETRY_HOURS
                    )
                )
            ).order_by(AlertPublishLog.created_at.asc()).limit(self.batch_size).all()
            
            logger.info(f"ğŸ” å‘ç° {len(failed_publishes)} ä¸ªå¾…è¡¥å¿çš„å‘å¸ƒä»»åŠ¡")
            
            for publish_log in failed_publishes:
                try:
                    # è®¡ç®—é€€é¿æ—¶é—´
                    backoff_seconds = self._calculate_backoff_time(
                        publish_log.retries, settings.PRODUCER_RETRY_INTERVAL
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦åˆ°äº†é‡è¯•æ—¶é—´
                    if (datetime.utcnow() - publish_log.updated_at).total_seconds() < backoff_seconds:
                        continue
                    
                    # æ›´æ–°çŠ¶æ€ä¸ºè¡¥å¿ä¸­
                    publish_log.status = PublishStatus.COMPENSATING
                    publish_log.retries += 1
                    publish_log.updated_at = datetime.utcnow()
                    db.commit()
                    
                    # é‡æ–°å‘é€æ¶ˆæ¯
                    success = rabbitmq_client.publish_alert(publish_log.payload)
                    
                    if success:
                        publish_log.status = PublishStatus.ENQUEUED
                        publish_log.sent_at = datetime.utcnow()
                        publish_log.error_message = None
                        compensated_count += 1
                        
                        logger.info(f"âœ… ç”Ÿäº§ç«¯è¡¥å¿æˆåŠŸ: {publish_log.message_id} (é‡è¯• {publish_log.retries})")
                    else:
                        publish_log.status = PublishStatus.FAILED
                        publish_log.error_message = "RabbitMQå‘å¸ƒå¤±è´¥"
                        
                        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
                        if publish_log.retries >= publish_log.max_retries:
                            logger.error(f"ğŸ’€ ç”Ÿäº§ç«¯è¡¥å¿å½»åº•å¤±è´¥: {publish_log.message_id}")
                        
                    db.commit()
                    
                except Exception as e:
                    publish_log.status = PublishStatus.FAILED
                    publish_log.error_message = f"è¡¥å¿å¼‚å¸¸: {str(e)}"
                    db.commit()
                    logger.error(f"âŒ ç”Ÿäº§ç«¯è¡¥å¿å¤±è´¥: {publish_log.message_id} - {str(e)}")
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats.increment_compensation("producer", compensated_count)
            
            logger.info(f"ğŸš€ ç”Ÿäº§ç«¯è¡¥å¿å®Œæˆ: æˆåŠŸè¡¥å¿ {compensated_count} ä¸ªæ¶ˆæ¯")
            
            return {
                "layer": "producer",
                "processed": len(failed_publishes),
                "compensated": compensated_count,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿäº§ç«¯è¡¥å¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
        finally:
            db.close()
    
    async def _compensate_consumer(self) -> Dict[str, Any]:
        """
        âš¡ æ¶ˆè´¹ç«¯è¡¥å¿ - å¤„ç†æ­»ä¿¡é˜Ÿåˆ—å’Œå¤±è´¥æ¶ˆæ¯
        
        å¤„ç†é€»è¾‘ï¼š
        1. è·å–æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
        2. åˆ†ææ­»ä¿¡åŸå› å’Œæ­»ä¿¡æ¬¡æ•°
        3. ç¬¦åˆæ¡ä»¶çš„æ¶ˆæ¯é‡æ–°æŠ•é€’åˆ°ä¸»é˜Ÿåˆ—
        4. è¶…è¿‡é™åˆ¶çš„æ¶ˆæ¯è®°å½•ä¸ºå½»åº•å¤±è´¥
        """
        logger.debug("âš¡ å¼€å§‹æ¶ˆè´¹ç«¯è¡¥å¿")
        
        compensated_count = 0
        
        try:
            if not rabbitmq_client.is_connected:
                logger.warning("âš ï¸ RabbitMQæœªè¿æ¥ï¼Œè·³è¿‡æ¶ˆè´¹ç«¯è¡¥å¿")
                return {"layer": "consumer", "processed": 0, "compensated": 0, "status": "skipped"}
            
            # è·å–æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯
            dead_messages = rabbitmq_client.get_dead_letter_messages(max_count=self.batch_size)
            
            logger.info(f"ğŸ” å‘ç° {len(dead_messages)} æ¡æ­»ä¿¡æ¶ˆæ¯")
            
            for dead_msg in dead_messages:
                try:
                    message_data = dead_msg['message_data']
                    delivery_tag = dead_msg['delivery_tag']
                    death_count = dead_msg.get('death_count', 0)
                    dead_reason = dead_msg.get('dead_reason', 'unknown')
                    retry_count = dead_msg.get('retry_count', 0)
                    
                    message_id = message_data.get('message_id', 'unknown')
                    
                    # æ£€æŸ¥æ­»ä¿¡æ¬¡æ•°å’Œé‡è¯•é™åˆ¶
                    if (death_count < settings.DEAD_LETTER_MAX_DEATH_COUNT and 
                        retry_count < settings.CONSUMER_MAX_RETRIES):
                        
                        # å¢åŠ é‡è¯•è®¡æ•°
                        message_data['retry_count'] = retry_count + 1
                        message_data['last_retry_time'] = datetime.utcnow().isoformat()
                        message_data['retry_reason'] = f"æ­»ä¿¡è¡¥å¿: {dead_reason}"
                        
                        # é‡æ–°å¤„ç†æ¶ˆæ¯
                        success = rabbitmq_client.reprocess_dead_message(
                            delivery_tag, message_data, increase_retry=True
                        )
                        
                        if success:
                            compensated_count += 1
                            logger.info(f"âœ… æ¶ˆè´¹ç«¯è¡¥å¿æˆåŠŸ: {message_id} (æ­»ä¿¡æ¬¡æ•°: {death_count})")
                        else:
                            logger.error(f"âŒ æ¶ˆè´¹ç«¯è¡¥å¿å¤±è´¥: {message_id}")
                    else:
                        # è¶…è¿‡é™åˆ¶ï¼Œç¡®è®¤æ¶ˆæ¯å¹¶è®°å½•å½»åº•å¤±è´¥
                        rabbitmq_client.channel.basic_ack(delivery_tag=delivery_tag)
                        
                        logger.error(f"ğŸ’€ æ¶ˆæ¯å½»åº•å¤±è´¥: {message_id} "
                                   f"(æ­»ä¿¡æ¬¡æ•°: {death_count}, é‡è¯•æ¬¡æ•°: {retry_count})")
                        
                        # å¯ä»¥åœ¨è¿™é‡Œè®°å½•åˆ°å¤±è´¥æ—¥å¿—è¡¨
                        await self._log_permanent_failure(message_data, dead_reason)
                        
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                    # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
                    try:
                        rabbitmq_client.channel.basic_nack(
                            delivery_tag=dead_msg['delivery_tag'], 
                            requeue=False
                        )
                    except:
                        pass
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats.increment_compensation("consumer", compensated_count)
            
            logger.info(f"âš¡ æ¶ˆè´¹ç«¯è¡¥å¿å®Œæˆ: æˆåŠŸè¡¥å¿ {compensated_count} ä¸ªæ¶ˆæ¯")
            
            return {
                "layer": "consumer",
                "processed": len(dead_messages),
                "compensated": compensated_count,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¶ˆè´¹ç«¯è¡¥å¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    async def _compensate_notification(self) -> Dict[str, Any]:
        """
        ğŸ“¡ é€šçŸ¥ç«¯è¡¥å¿ - é‡æ–°å‘é€å¤±è´¥çš„SSEé€šçŸ¥
        
        å¤„ç†é€»è¾‘ï¼š
        1. æŸ¥æ‰¾PENDINGæˆ–FAILEDçŠ¶æ€çš„é€šçŸ¥è®°å½•
        2. æ£€æŸ¥ACKè¶…æ—¶å’Œé‡è¯•æ¬¡æ•°
        3. é‡æ–°å‘é€SSEé€šçŸ¥
        4. æ”¯æŒå¤šé€šé“é™çº§ï¼ˆSSEå¤±è´¥å¯é™çº§åˆ°å…¶ä»–é€šé“ï¼‰
        """
        logger.debug("ğŸ“¡ å¼€å§‹é€šçŸ¥ç«¯è¡¥å¿")
        
        db = SessionLocal()
        compensated_count = 0
        
        try:
            # æŸ¥æ‰¾éœ€è¦è¡¥å¿çš„é€šçŸ¥è®°å½•
            failed_notifications = db.query(AlertNotificationLog).filter(
                and_(
                    AlertNotificationLog.status.in_([
                        NotificationStatus.PENDING,
                        NotificationStatus.FAILED,
                        NotificationStatus.SENDING
                    ]),
                    AlertNotificationLog.retries < AlertNotificationLog.max_retries,
                    AlertNotificationLog.created_at > datetime.utcnow() - timedelta(
                        hours=settings.NOTIFICATION_COMPENSATION_INTERVAL // 3600 * 6
                    )
                )
            ).order_by(AlertNotificationLog.created_at.asc()).limit(self.batch_size).all()
            
            logger.info(f"ğŸ” å‘ç° {len(failed_notifications)} ä¸ªå¾…è¡¥å¿çš„é€šçŸ¥ä»»åŠ¡")
            
            for notification_log in failed_notifications:
                try:
                    # æ£€æŸ¥ACKè¶…æ—¶
                    if (notification_log.status == NotificationStatus.SENDING and
                        notification_log.ack_required and
                        notification_log.sent_at):
                        
                        ack_timeout = timedelta(seconds=notification_log.ack_timeout_seconds)
                        if datetime.utcnow() - notification_log.sent_at < ack_timeout:
                            continue  # è¿˜æ²¡æœ‰è¶…æ—¶
                    
                    # è®¡ç®—é€€é¿æ—¶é—´
                    backoff_seconds = self._calculate_backoff_time(
                        notification_log.retries, settings.SSE_NOTIFICATION_RETRY_INTERVAL
                    )
                    
                    if (datetime.utcnow() - notification_log.updated_at).total_seconds() < backoff_seconds:
                        continue
                    
                    # æ›´æ–°é‡è¯•ä¿¡æ¯
                    notification_log.retries += 1
                    notification_log.status = NotificationStatus.SENDING
                    notification_log.updated_at = datetime.utcnow()
                    db.commit()
                    
                    # é‡æ–°å‘é€é€šçŸ¥
                    success = await self._resend_notification(notification_log)
                    
                    if success:
                        notification_log.status = NotificationStatus.DELIVERED
                        notification_log.sent_at = datetime.utcnow()
                        notification_log.error_message = None
                        compensated_count += 1
                        
                        logger.info(f"âœ… é€šçŸ¥ç«¯è¡¥å¿æˆåŠŸ: ID={notification_log.id} "
                                   f"Alert={notification_log.alert_id} (é‡è¯• {notification_log.retries})")
                    else:
                        notification_log.status = NotificationStatus.FAILED
                        notification_log.error_message = "SSEå‘é€å¤±è´¥"
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦é™çº§å¤„ç†
                        if notification_log.retries >= notification_log.max_retries:
                            logger.warning(f"ğŸ“§ é€šçŸ¥å½»åº•å¤±è´¥ï¼Œè€ƒè™‘é™çº§å¤„ç†: Alert={notification_log.alert_id}")
                            # è¿™é‡Œå¯ä»¥å®ç°é™çº§åˆ°é‚®ä»¶ç­‰å…¶ä»–é€šé“
                    
                    db.commit()
                    
                except Exception as e:
                    notification_log.status = NotificationStatus.FAILED
                    notification_log.error_message = f"è¡¥å¿å¼‚å¸¸: {str(e)}"
                    db.commit()
                    logger.error(f"âŒ é€šçŸ¥ç«¯è¡¥å¿å¤±è´¥: ID={notification_log.id} - {str(e)}")
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats.increment_compensation("notification", compensated_count)
            
            logger.info(f"ğŸ“¡ é€šçŸ¥ç«¯è¡¥å¿å®Œæˆ: æˆåŠŸè¡¥å¿ {compensated_count} ä¸ªé€šçŸ¥")
            
            return {
                "layer": "notification",
                "processed": len(failed_notifications),
                "compensated": compensated_count,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"âŒ é€šçŸ¥ç«¯è¡¥å¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
        finally:
            db.close()
    
    async def _resend_notification(self, notification_log: AlertNotificationLog) -> bool:
        """é‡æ–°å‘é€é€šçŸ¥"""
        try:
            # è·å–é€šçŸ¥å†…å®¹
            notification_content = notification_log.notification_content
            
            # æ ¹æ®é€šçŸ¥æ¸ é“å‘é€
            if notification_log.channel == NotificationChannel.SSE:
                # SSEé€šçŸ¥
                if hasattr(sse_manager, 'connected_clients') and sse_manager.connected_clients:
                    success = await sse_manager.broadcast_to_all(notification_content)
                    return success
                else:
                    logger.warning(f"âš ï¸ æ²¡æœ‰æ´»è·ƒçš„SSEå®¢æˆ·ç«¯ï¼Œé€šçŸ¥å‘é€å¤±è´¥")
                    return False
            else:
                # å…¶ä»–é€šé“æš‚æœªå®ç°
                logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„é€šçŸ¥æ¸ é“: {notification_log.channel}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é‡æ–°å‘é€é€šçŸ¥å¤±è´¥: {str(e)}")
            return False
    
    def _calculate_backoff_time(self, retry_count: int, base_interval: int) -> int:
        """è®¡ç®—æŒ‡æ•°é€€é¿æ—¶é—´"""
        if not settings.PRODUCER_EXPONENTIAL_BACKOFF:
            return base_interval
        
        # æŒ‡æ•°é€€é¿ï¼šbase_interval * (2 ^ retry_count)ï¼Œæœ€å¤§ä¸è¶…è¿‡1å°æ—¶
        backoff_time = base_interval * (2 ** retry_count)
        return min(backoff_time, 3600)  # æœ€å¤§1å°æ—¶
    
    async def _log_compensation_task(self, task_id: str, task_type: CompensationTaskType):
        """è®°å½•è¡¥å¿ä»»åŠ¡å¼€å§‹"""
        db = SessionLocal()
        try:
            task_log = CompensationTaskLog(
                task_id=task_id,
                task_type=task_type,
                execution_result="running",
                started_at=datetime.utcnow(),
                executor_host=socket.gethostname() if 'socket' in globals() else "unknown"
            )
            db.add(task_log)
            db.commit()
        except Exception as e:
            logger.error(f"âŒ è®°å½•è¡¥å¿ä»»åŠ¡å¤±è´¥: {str(e)}")
        finally:
            db.close()
    
    async def _complete_compensation_task(self, task_id: str, result: str, 
                                        success_count: int, failed_count: int, 
                                        error_message: str = None):
        """å®Œæˆè¡¥å¿ä»»åŠ¡è®°å½•"""
        db = SessionLocal()
        try:
            task_log = db.query(CompensationTaskLog).filter(
                CompensationTaskLog.task_id == task_id
            ).first()
            
            if task_log:
                task_log.execution_result = result
                task_log.completed_at = datetime.utcnow()
                task_log.success_count = success_count
                task_log.failed_count = failed_count
                task_log.processed_count = success_count + failed_count
                task_log.error_message = error_message
                
                if task_log.started_at:
                    duration = (task_log.completed_at - task_log.started_at).total_seconds()
                    task_log.duration_ms = int(duration * 1000)
                
                db.commit()
        except Exception as e:
            logger.error(f"âŒ å®Œæˆè¡¥å¿ä»»åŠ¡è®°å½•å¤±è´¥: {str(e)}")
        finally:
            db.close()
    
    async def _log_permanent_failure(self, message_data: Dict[str, Any], reason: str):
        """è®°å½•æ°¸ä¹…å¤±è´¥çš„æ¶ˆæ¯"""
        try:
            logger.error(f"ğŸ’€ æ°¸ä¹…å¤±è´¥æ¶ˆæ¯: {message_data.get('message_id', 'unknown')} - {reason}")
            # è¿™é‡Œå¯ä»¥è®°å½•åˆ°ä¸“é—¨çš„å¤±è´¥æ—¥å¿—è¡¨æˆ–å‘é€å‘Šè­¦
        except Exception as e:
            logger.error(f"âŒ è®°å½•æ°¸ä¹…å¤±è´¥æ¶ˆæ¯å¤±è´¥: {str(e)}")
    
    async def stop(self):
        """åœæ­¢è¡¥å¿æœåŠ¡"""
        if not self.is_running:
            return
            
        logger.info("â¹ï¸ æ­£åœ¨åœæ­¢ç»Ÿä¸€è¡¥å¿æœåŠ¡...")
        
        self.is_running = False
        self._stop_event.set()
        
        # ç­‰å¾…åå°ä»»åŠ¡å®Œæˆ
        if self._background_task:
            try:
                await asyncio.wait_for(self._background_task, timeout=30)
            except asyncio.TimeoutError:
                logger.warning("âš ï¸ è¡¥å¿æœåŠ¡åœæ­¢è¶…æ—¶ï¼Œå¼ºåˆ¶ç»“æŸ")
                self._background_task.cancel()
        
        # å…³é—­çº¿ç¨‹æ± 
        self.thread_pool.shutdown(wait=False)
        
        logger.info("âœ… ç»Ÿä¸€è¡¥å¿æœåŠ¡å·²åœæ­¢")
    
    def get_compensation_stats(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´çš„è¡¥å¿ç»Ÿè®¡ä¿¡æ¯"""
        service_stats = self.stats.get_stats()
        
        return {
            "service_status": {
                "is_running": self.is_running,
                "is_initialized": self.is_initialized,
                "compensation_interval": self.compensation_interval,
                "batch_size": self.batch_size,
                "worker_threads": self.worker_threads
            },
            "execution_stats": service_stats,
            "configuration": {
                "producer_enabled": settings.PRODUCER_COMPENSATION_ENABLE,
                "consumer_enabled": settings.CONSUMER_COMPENSATION_ENABLE,
                "notification_enabled": settings.SSE_COMPENSATION_ENABLE,
                "producer_max_retries": settings.PRODUCER_MAX_RETRIES,
                "consumer_max_retries": settings.CONSUMER_MAX_RETRIES,
                "notification_max_retries": settings.SSE_NOTIFICATION_MAX_RETRIES
            },
            "timestamp": datetime.utcnow().isoformat()
        }


# å¯¼å…¥socketæ¨¡å—ï¼ˆç”¨äºè·å–ä¸»æœºåï¼‰
import socket

# å…¨å±€å®ä¾‹
unified_compensation_service = UnifiedCompensationService()


async def start_unified_compensation():
    """å¯åŠ¨ç»Ÿä¸€è¡¥å¿æœåŠ¡"""
    if settings.COMPENSATION_AUTO_START:
        await unified_compensation_service.start()


async def stop_unified_compensation():
    """åœæ­¢ç»Ÿä¸€è¡¥å¿æœåŠ¡"""
    await unified_compensation_service.stop()


def get_compensation_service_stats() -> Dict[str, Any]:
    """è·å–è¡¥å¿æœåŠ¡ç»Ÿè®¡"""
    return unified_compensation_service.get_compensation_stats()


async def get_compensation_health() -> Dict[str, Any]:
    """è·å–è¡¥å¿æœåŠ¡å¥åº·çŠ¶æ€"""
    stats = unified_compensation_service.get_compensation_stats()
    
    # è®¡ç®—å¥åº·åˆ†æ•°
    health_score = 100
    issues = []
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if not stats["service_status"]["is_running"]:
        health_score -= 50
        issues.append("è¡¥å¿æœåŠ¡æœªè¿è¡Œ")
    
    if not stats["service_status"]["is_initialized"]:
        health_score -= 30
        issues.append("è¡¥å¿æœåŠ¡æœªåˆå§‹åŒ–")
    
    # æ£€æŸ¥æˆåŠŸç‡
    success_rate = stats["execution_stats"].get("success_rate", 0)
    if success_rate < 90:
        health_score -= 20
        issues.append(f"æˆåŠŸç‡åä½: {success_rate:.1f}%")
    
    # æ£€æŸ¥é”™è¯¯ç‡
    total_errors = stats["execution_stats"].get("total_errors", 0)
    if total_errors > 10:
        health_score -= 15
        issues.append(f"é”™è¯¯æ¬¡æ•°è¿‡å¤š: {total_errors}")
    
    # ç¡®å®šå¥åº·ç­‰çº§
    if health_score >= 90:
        health_level = "healthy"
    elif health_score >= 70:
        health_level = "warning"
    else:
        health_level = "critical"
    
    return {
        "health_level": health_level,
        "health_score": max(0, health_score),
        "issues": issues,
        "stats": stats,
        "timestamp": datetime.utcnow().isoformat()
    }