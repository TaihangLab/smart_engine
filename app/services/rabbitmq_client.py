import json
import logging
import threading
import time
from typing import Callable, Dict, List, Any, Optional, Tuple
import pika
from pika.adapters.blocking_connection import BlockingChannel
from datetime import datetime

from app.core.config import settings

logger = logging.getLogger(__name__)

class RabbitMQClient:
    """RabbitMQå®¢æˆ·ç«¯ï¼Œç”¨äºæ¶ˆæ¯å‘å¸ƒå’Œè®¢é˜…ï¼Œæ”¯æŒæ­»ä¿¡é˜Ÿåˆ—"""
    
    def __init__(self):
        self.connection = None
        self.channel = None
        self.is_connected = False
        self.consumer_thread = None
        self._subscribers = {}  # ç”¨äºå­˜å‚¨æ¶ˆæ¯è®¢é˜…å›è°ƒå‡½æ•°
        self.health_monitor_thread = None  # å¥åº·ç›‘æ§çº¿ç¨‹
        
        # æ­»ä¿¡é˜Ÿåˆ—é…ç½®
        self.dead_letter_exchange = f"{settings.RABBITMQ_ALERT_EXCHANGE}.dlx"
        self.dead_letter_queue = f"{settings.RABBITMQ_ALERT_QUEUE}.dlq"
        self.dead_letter_routing_key = f"{settings.RABBITMQ_ALERT_ROUTING_KEY}.dead"
        
        # ğŸš€ åˆå§‹åŒ–è¿æ¥å’Œå¥åº·ç›‘æ§
        if self._connect():
            # å¯åŠ¨å¥åº·ç›‘æ§ï¼ˆ30ç§’æ£€æŸ¥é—´éš”ï¼‰
            self.start_health_monitor(check_interval=30)
            logger.info("ğŸ‰ RabbitMQå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œå¥åº·ç›‘æ§å·²å¯åŠ¨")
    
    def _connect(self) -> bool:
        """è¿æ¥åˆ°RabbitMQæœåŠ¡å™¨"""
        try:
            # è¿æ¥å‚æ•°
            credentials = pika.PlainCredentials(
                settings.RABBITMQ_USER, 
                settings.RABBITMQ_PASSWORD
            )
            parameters = pika.ConnectionParameters(
                host=settings.RABBITMQ_HOST,
                port=settings.RABBITMQ_PORT,
                credentials=credentials,
                heartbeat=600,
                blocked_connection_timeout=300,
                # å¢åŠ è¿æ¥ç¨³å®šæ€§å‚æ•°
                connection_attempts=3,
                retry_delay=2.0,
                socket_timeout=30.0,
                stack_timeout=30.0
            )
            
            # åˆ›å»ºè¿æ¥å’Œé€šé“
            self.connection = pika.BlockingConnection(parameters)
            self.channel = self.connection.channel()
            
            # é…ç½®æ­»ä¿¡é˜Ÿåˆ—
            self._setup_dead_letter_queue()
            
            # å£°æ˜ä¸»äº¤æ¢æœº
            self.channel.exchange_declare(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                exchange_type='direct',
                durable=True
            )
            
            # å£°æ˜ä¸»é˜Ÿåˆ—ï¼ˆå¸¦æ­»ä¿¡é˜Ÿåˆ—é…ç½®ï¼‰
            self.channel.queue_declare(
                queue=settings.RABBITMQ_ALERT_QUEUE,
                durable=True,
                arguments={
                    'x-dead-letter-exchange': self.dead_letter_exchange,
                    'x-dead-letter-routing-key': self.dead_letter_routing_key,
                    'x-message-ttl': settings.RABBITMQ_MESSAGE_TTL,  # ä»é…ç½®æ–‡ä»¶è·å–TTL
                    'x-max-retries': settings.RABBITMQ_MAX_RETRIES  # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§é‡è¯•æ¬¡æ•°
                }
            )
            
            # ç»‘å®šä¸»é˜Ÿåˆ—åˆ°äº¤æ¢æœº
            self.channel.queue_bind(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                queue=settings.RABBITMQ_ALERT_QUEUE,
                routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY
            )
            
            self.is_connected = True
            logger.info("âœ… å·²æˆåŠŸè¿æ¥åˆ°RabbitMQæœåŠ¡å™¨ï¼Œæ­»ä¿¡é˜Ÿåˆ—é…ç½®å®Œæˆ")
            return True
        
        except Exception as e:
            logger.error(f"âŒ è¿æ¥RabbitMQå¤±è´¥: {str(e)}")
            self.is_connected = False
            return False
    
    def _setup_dead_letter_queue(self) -> None:
        """é…ç½®æ­»ä¿¡é˜Ÿåˆ—"""
        try:
            # å£°æ˜æ­»ä¿¡äº¤æ¢æœº
            self.channel.exchange_declare(
                exchange=self.dead_letter_exchange,
                exchange_type='direct',
                durable=True
            )
            
            # å£°æ˜æ­»ä¿¡é˜Ÿåˆ—
            self.channel.queue_declare(
                queue=self.dead_letter_queue,
                durable=True,
                arguments={
                    'x-message-ttl': settings.RABBITMQ_DEAD_LETTER_TTL,  # ä»é…ç½®æ–‡ä»¶è·å–æ­»ä¿¡TTL
                    'x-max-length': settings.RABBITMQ_DEAD_LETTER_MAX_LENGTH  # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§é•¿åº¦
                }
            )
            
            # ç»‘å®šæ­»ä¿¡é˜Ÿåˆ—åˆ°æ­»ä¿¡äº¤æ¢æœº
            self.channel.queue_bind(
                exchange=self.dead_letter_exchange,
                queue=self.dead_letter_queue,
                routing_key=self.dead_letter_routing_key
            )
            
            logger.info(f"ğŸ”§ æ­»ä¿¡é˜Ÿåˆ—é…ç½®å®Œæˆ: {self.dead_letter_queue}")
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
            raise
    
    def publish_alert(self, alert_data: Dict[str, Any], max_retries: int = 3) -> bool:
        """å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯åˆ°RabbitMQ - å¢å¼ºç‰ˆæœ¬ï¼Œå¸¦è‡ªåŠ¨é‡è¿"""
        for attempt in range(max_retries):
            if not self.is_connected:
                if not self._connect():
                    if attempt < max_retries - 1:
                        time.sleep(1)
                        continue
                    return False
            
            try:
                # æ£€æŸ¥é€šé“çŠ¶æ€
                if not self.channel or self.channel.is_closed:
                    logger.warning("ğŸ“¡ é€šé“å·²å…³é—­ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                    self.is_connected = False
                    if not self._connect():
                        continue
                
                # å°†æ¶ˆæ¯è½¬æ¢ä¸ºJSON
                message = json.dumps(alert_data)
                
                # å‘å¸ƒæ¶ˆæ¯
                self.channel.basic_publish(
                    exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                    routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY,
                    body=message,
                    properties=pika.BasicProperties(
                        delivery_mode=2,  # æŒä¹…åŒ–æ¶ˆæ¯
                        content_type='application/json',
                        headers={
                            'retry_count': 0,  # åˆå§‹é‡è¯•æ¬¡æ•°
                            'first_attempt_time': str(int(time.time() * 1000))  # é¦–æ¬¡å°è¯•æ—¶é—´æˆ³
                        }
                    )
                )
                
                logger.info(f"ğŸ“¤ å·²å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯: ç±»å‹={alert_data.get('alert_type', 'unknown')}")
                return True
                
            except IndexError as e:
                # æ•è· pika å†…éƒ¨çš„ "pop from an empty deque" é”™è¯¯
                logger.warning(f"âš ï¸ pikaå†…éƒ¨é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                self.is_connected = False
                if attempt < max_retries - 1:
                    time.sleep(0.5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                    continue
                    
            except (pika.exceptions.AMQPConnectionError, 
                    pika.exceptions.AMQPChannelError,
                    pika.exceptions.StreamLostError) as e:
                logger.warning(f"âš ï¸ è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                self.is_connected = False
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                    
            except Exception as e:
                logger.error(f"âŒ å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯å¤±è´¥: {str(e)}")
                self.is_connected = False
                return False
        
        logger.error(f"âŒ å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
        return False
    
    def get_dead_letter_messages(self, max_count: int = 100) -> List[Dict[str, Any]]:
        """è·å–æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯"""
        if not self.is_connected:
            if not self._connect():
                return []
        
        dead_messages = []
        try:
            # è·å–æ­»ä¿¡é˜Ÿåˆ—ä¿¡æ¯
            queue_info = self.channel.queue_declare(
                queue=self.dead_letter_queue, 
                passive=True
            )
            message_count = queue_info.method.message_count
            
            if message_count == 0:
                logger.debug("ğŸ“­ æ­»ä¿¡é˜Ÿåˆ—ä¸ºç©º")
                return []
            
            logger.info(f"ğŸ” æ­»ä¿¡é˜Ÿåˆ—ä¸­æœ‰ {message_count} æ¡æ¶ˆæ¯")
            
            # è·å–æ­»ä¿¡æ¶ˆæ¯ï¼ˆä¸è‡ªåŠ¨ç¡®è®¤ï¼‰
            count = 0
            while count < min(max_count, message_count):
                method, properties, body = self.channel.basic_get(
                    queue=self.dead_letter_queue,
                    auto_ack=False
                )
                
                if method is None:
                    break
                
                try:
                    # è§£ææ¶ˆæ¯
                    message_data = json.loads(body.decode('utf-8'))
                    
                    # è·å–æ­»ä¿¡ç›¸å…³ä¿¡æ¯
                    dead_info = {
                        'message_data': message_data,
                        'delivery_tag': method.delivery_tag,
                        'routing_key': method.routing_key,
                        'dead_reason': properties.headers.get('x-first-death-reason') if properties.headers else 'unknown',
                        'death_count': properties.headers.get('x-death', [{}])[0].get('count', 0) if properties.headers else 0,
                        'first_death_time': properties.headers.get('x-first-death-time') if properties.headers else None,
                        'retry_count': properties.headers.get('retry_count', 0) if properties.headers else 0
                    }
                    
                    dead_messages.append(dead_info)
                    count += 1
                    
                    # æš‚æ—¶ä¸ç¡®è®¤æ¶ˆæ¯ï¼Œç­‰å¾…å¤„ç†ç»“æœ
                    
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ è§£ææ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                    # ç¡®è®¤å¹¶ä¸¢å¼ƒæ— æ³•è§£æçš„æ¶ˆæ¯
                    self.channel.basic_ack(delivery_tag=method.delivery_tag)
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                    # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
                    self.channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
            
            logger.info(f"ğŸ“‹ è·å–åˆ° {len(dead_messages)} æ¡æ­»ä¿¡æ¶ˆæ¯")
            return dead_messages
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return []
    
    def reprocess_dead_message(self, delivery_tag: int, message_data: Dict[str, Any], 
                              increase_retry: bool = True) -> bool:
        """é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯"""
        try:
            # å¢åŠ é‡è¯•è®¡æ•°
            if increase_retry:
                retry_count = message_data.get('retry_count', 0) + 1
                message_data['retry_count'] = retry_count
            
            # é‡æ–°å‘å¸ƒåˆ°ä¸»é˜Ÿåˆ—
            success = self.publish_alert(message_data)
            
            if success:
                # ç¡®è®¤æ­»ä¿¡æ¶ˆæ¯å·²å¤„ç†
                self.channel.basic_ack(delivery_tag=delivery_tag)
                logger.info(f"âœ… æ­»ä¿¡æ¶ˆæ¯é‡æ–°å¤„ç†æˆåŠŸ: {message_data.get('alert_type', 'unknown')}")
                return True
            else:
                # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
                self.channel.basic_nack(delivery_tag=delivery_tag, requeue=False)
                logger.error(f"âŒ æ­»ä¿¡æ¶ˆæ¯é‡æ–°å‘å¸ƒå¤±è´¥: {message_data.get('alert_type', 'unknown')}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¼‚å¸¸: {str(e)}")
            try:
                # å‘ç”Ÿå¼‚å¸¸æ—¶æ‹’ç»æ¶ˆæ¯
                self.channel.basic_nack(delivery_tag=delivery_tag, requeue=False)
            except:
                pass
            return False
    
    def purge_dead_letter_queue(self) -> int:
        """æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—"""
        try:
            result = self.channel.queue_purge(queue=self.dead_letter_queue)
            purged_count = result.method.message_count
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—ï¼Œåˆ é™¤äº† {purged_count} æ¡æ¶ˆæ¯")
            return purged_count
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
            return 0
    
    def get_dead_letter_queue_stats(self) -> Dict[str, Any]:
        """è·å–æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        try:
            queue_info = self.channel.queue_declare(
                queue=self.dead_letter_queue, 
                passive=True
            )
            
            return {
                'queue_name': self.dead_letter_queue,
                'message_count': queue_info.method.message_count,
                'consumer_count': queue_info.method.consumer_count,
                'status': 'available'
            }
        except Exception as e:
            logger.error(f"âŒ è·å–æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {
                'queue_name': self.dead_letter_queue,
                'message_count': 0,
                'consumer_count': 0,
                'status': 'error',
                'error': str(e)
            }
    
    def subscribe_to_alerts(self, callback: Callable[[Dict[str, Any]], None]) -> None:
        """ğŸ“® æ™ºèƒ½è®¢é˜…æŠ¥è­¦æ¶ˆæ¯ - å¢å¼ºçŠ¶æ€ç®¡ç†"""
        logger.info(f"ğŸ“® æ–°å¢é¢„è­¦è®¢é˜…è€…: {callback.__qualname__ if hasattr(callback, '__qualname__') else 'unknown'}")
        
        # ğŸ”§ ç¡®ä¿è¿æ¥çŠ¶æ€
        if not self.is_connected:
            logger.info("ğŸ”„ æ£€æµ‹åˆ°è¿æ¥æ–­å¼€ï¼Œé‡æ–°è¿æ¥...")
            if not self._connect():
                logger.error("âŒ é‡æ–°è¿æ¥å¤±è´¥ï¼Œè®¢é˜…å¯èƒ½ä¸ä¼šç«‹å³ç”Ÿæ•ˆ")
        
        # æ·»åŠ å›è°ƒå‡½æ•°åˆ°è®¢é˜…è€…åˆ—è¡¨
        queue_name = settings.RABBITMQ_ALERT_QUEUE
        if queue_name not in self._subscribers:
            self._subscribers[queue_name] = []
        
        # ğŸ›¡ï¸ é¿å…é‡å¤è®¢é˜…
        if callback not in self._subscribers[queue_name]:
            self._subscribers[queue_name].append(callback)
            logger.info(f"âœ… è®¢é˜…è€…å·²æ·»åŠ ï¼Œå½“å‰è®¢é˜…è€…æ•°é‡: {len(self._subscribers[queue_name])}")
        else:
            logger.warning("âš ï¸ è®¢é˜…è€…å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤æ·»åŠ ")
        
        # ğŸš€ æ™ºèƒ½å¯åŠ¨æˆ–é‡å¯æ¶ˆè´¹è€…çº¿ç¨‹
        if self.consumer_thread is None or not self.consumer_thread.is_alive():
            logger.info(f"ğŸš€ å¯åŠ¨RabbitMQæ¶ˆè´¹è€…çº¿ç¨‹ï¼Œè®¢é˜…é˜Ÿåˆ—: {queue_name}")
            self.consumer_thread = threading.Thread(target=self._start_consuming, daemon=True)
            self.consumer_thread.start()
            
            # ğŸ” éªŒè¯å¯åŠ¨çŠ¶æ€
            time.sleep(1)
            if self.consumer_thread.is_alive():
                logger.info("âœ… æ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨æˆåŠŸ")
            else:
                logger.error("âŒ æ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨å¤±è´¥")
        else:
            logger.debug("ğŸŸ¢ æ¶ˆè´¹è€…çº¿ç¨‹å·²è¿è¡Œï¼Œæ— éœ€é‡å¯")
        
        # ğŸ“Š è®°å½•å½“å‰çŠ¶æ€
        logger.info(f"ğŸ“Š è®¢é˜…çŠ¶æ€: æ€»è®¢é˜…è€…={sum(len(callbacks) for callbacks in self._subscribers.values())}, æ¶ˆè´¹è€…çº¿ç¨‹è¿è¡Œ={self.consumer_thread.is_alive() if self.consumer_thread else False}")
    
    def _start_consuming(self) -> None:
        """å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯çš„å†…éƒ¨æ–¹æ³• - ä¼ä¸šçº§å¼‚å¸¸æ¢å¤æ¶æ„"""
        consecutive_failures = 0
        max_consecutive_failures = 5
        
        while True:  # ğŸ”„ æŒç»­è¿è¡Œï¼Œæ”¯æŒå¼‚å¸¸æ¢å¤
            try:
                # ğŸ”§ ç¡®ä¿è¿æ¥çŠ¶æ€æ­£å¸¸
                if not self.is_connected or not self.channel or self.channel.is_closed:
                    logger.info("ğŸ”„ æ£€æµ‹åˆ°è¿æ¥æ–­å¼€ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                    if not self._connect():
                        consecutive_failures += 1
                        wait_time = min(consecutive_failures * 2, 30)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§30ç§’
                        logger.warning(f"ğŸš¨ é‡è¿å¤±è´¥ #{consecutive_failures}ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        
                        if consecutive_failures >= max_consecutive_failures:
                            logger.error(f"ğŸ’¥ è¿ç»­é‡è¿å¤±è´¥{max_consecutive_failures}æ¬¡ï¼Œæ¶ˆè´¹è€…çº¿ç¨‹é€€å‡º")
                            break
                        continue
                
                # ğŸ¯ é‡ç½®å¤±è´¥è®¡æ•°å™¨
                consecutive_failures = 0
                
                def _callback(ch: BlockingChannel, method, properties, body):
                    """æ¶ˆæ¯å›è°ƒå‡½æ•° - å¢å¼ºå¼‚å¸¸å¤„ç†"""
                    try:
                        # è§£ææ¶ˆæ¯
                        message = json.loads(body.decode('utf-8'))
                        
                        # è·å–é‡è¯•ä¿¡æ¯
                        retry_count = properties.headers.get('retry_count', 0) if properties.headers else 0
                        max_retries = settings.RABBITMQ_MAX_RETRIES
                        
                        logger.info(f"ğŸ”” æ¥æ”¶åˆ°æŠ¥è­¦æ¶ˆæ¯: ç±»å‹={message.get('alert_type', 'unknown')}, "
                                    f"æ‘„åƒå¤´={message.get('camera_id', 'unknown')}, é‡è¯•æ¬¡æ•°={retry_count}")
                        
                        # è°ƒç”¨æ‰€æœ‰è®¢é˜…è€…çš„å›è°ƒå‡½æ•°
                        consuming_queue = settings.RABBITMQ_ALERT_QUEUE
                        success = True
                        
                        # ğŸ”§ å¢å¼ºè®¢é˜…è€…æ£€æŸ¥å’Œå®¹é”™
                        if consuming_queue in self._subscribers and self._subscribers[consuming_queue]:
                            active_callbacks = []
                            for callback in self._subscribers[consuming_queue]:
                                try:
                                    logger.debug(f"ğŸ“ è°ƒç”¨è®¢é˜…è€…å›è°ƒ: {callback.__qualname__ if hasattr(callback, '__qualname__') else 'unknown'}")
                                    callback(message)
                                    active_callbacks.append(callback)
                                except Exception as callback_error:
                                    logger.error(f"âŒ è®¢é˜…è€…å›è°ƒå¼‚å¸¸: {str(callback_error)}", exc_info=True)
                                    # ğŸ›¡ï¸ ä¸å› å•ä¸ªå›è°ƒå¤±è´¥è€Œå½±å“æ•´ä½“å¤„ç†
                                    continue
                            
                            # ğŸ”§ æ¸…ç†å¤±æ•ˆçš„å›è°ƒå‡½æ•°
                            self._subscribers[consuming_queue] = active_callbacks
                            success = len(active_callbacks) > 0
                        else:
                            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é˜Ÿåˆ— '{consuming_queue}' çš„æœ‰æ•ˆè®¢é˜…è€…")
                            success = False
                        
                        if success:
                            # å¤„ç†æˆåŠŸï¼Œç¡®è®¤æ¶ˆæ¯
                            ch.basic_ack(delivery_tag=method.delivery_tag)
                            logger.debug(f"âœ… ç¡®è®¤å¤„ç†æŠ¥è­¦æ¶ˆæ¯: {message.get('alert_type', 'unknown')}")
                        else:
                            # å¤„ç†å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                            if retry_count < max_retries:
                                # é‡æ–°å‘å¸ƒæ¶ˆæ¯åˆ°é˜Ÿåˆ—å°¾éƒ¨
                                self._republish_with_retry(message, retry_count + 1)
                                ch.basic_ack(delivery_tag=method.delivery_tag)  # ç¡®è®¤åŸæ¶ˆæ¯
                                logger.warning(f"ğŸ”„ æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œé‡è¯• {retry_count + 1}/{max_retries}: {message.get('alert_type', 'unknown')}")
                            else:
                                # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ‹’ç»æ¶ˆæ¯ï¼ˆå°†è¿›å…¥æ­»ä¿¡é˜Ÿåˆ—ï¼‰
                                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                                logger.error(f"ğŸ’€ æ¶ˆæ¯å¤„ç†å¤±è´¥è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—: {message.get('alert_type', 'unknown')}")
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ è§£ææ¶ˆæ¯å¤±è´¥: {body}, é”™è¯¯: {str(e)}")
                        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                    
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}", exc_info=True)
                        
                        # è·å–é‡è¯•æ¬¡æ•°
                        retry_count = properties.headers.get('retry_count', 0) if properties.headers else 0
                        
                        if retry_count < settings.RABBITMQ_MAX_RETRIES:
                            # é‡æ–°å…¥é˜Ÿç­‰å¾…é‡è¯•
                            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
                            logger.warning(f"ğŸ”„ æ¶ˆæ¯é‡æ–°å…¥é˜Ÿç­‰å¾…é‡è¯•: {retry_count + 1}/{settings.RABBITMQ_MAX_RETRIES}")
                        else:
                            # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—
                            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                            logger.error(f"ğŸ’€ æ¶ˆæ¯è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—")
                
                # è®¾ç½®QoS
                self.channel.basic_qos(prefetch_count=1)
                
                # å¼€å§‹æ¶ˆè´¹
                self.channel.basic_consume(
                    queue=settings.RABBITMQ_ALERT_QUEUE,
                    on_message_callback=_callback
                )
                
                logger.info(f"ğŸ§ å¼€å§‹æ¶ˆè´¹æŠ¥è­¦æ¶ˆæ¯ï¼Œé˜Ÿåˆ—: {settings.RABBITMQ_ALERT_QUEUE}")
                self.channel.start_consuming()
                
            except KeyboardInterrupt:
                logger.info("â¹ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢æ¶ˆè´¹æ¶ˆæ¯")
                break
                
            except Exception as e:
                consecutive_failures += 1
                logger.error(f"âŒ æ¶ˆè´¹æ¶ˆæ¯å¼‚å¸¸ #{consecutive_failures}: {str(e)}", exc_info=True)
                
                # ğŸ”„ å¼‚å¸¸æ¢å¤ç­–ç•¥
                try:
                    if self.channel and not self.channel.is_closed:
                        self.channel.stop_consuming()
                except:
                    pass
                
                self.is_connected = False
                
                if consecutive_failures >= max_consecutive_failures:
                    logger.error(f"ğŸ’¥ æ¶ˆè´¹è€…è¿ç»­å¼‚å¸¸{max_consecutive_failures}æ¬¡ï¼Œçº¿ç¨‹é€€å‡º")
                    break
                
                # ğŸ• æŒ‡æ•°é€€é¿é‡è¯•
                wait_time = min(consecutive_failures * 3, 60)
                logger.warning(f"ğŸ”„ {wait_time}ç§’åå°è¯•æ¢å¤æ¶ˆè´¹...")
                time.sleep(wait_time)
        
        logger.warning("âš ï¸ RabbitMQæ¶ˆè´¹è€…çº¿ç¨‹å·²é€€å‡º")
    
    def _republish_with_retry(self, message_data: Dict[str, Any], retry_count: int) -> bool:
        """é‡æ–°å‘å¸ƒæ¶ˆæ¯ï¼ˆå¸¦é‡è¯•è®¡æ•°ï¼‰- å¢å¼ºå¼‚å¸¸å¤„ç†"""
        for attempt in range(3):
            try:
                # æ£€æŸ¥é€šé“çŠ¶æ€
                if not self.channel or self.channel.is_closed:
                    logger.warning("ğŸ“¡ é‡æ–°å‘å¸ƒæ—¶é€šé“å·²å…³é—­ï¼Œå°è¯•é‡è¿...")
                    if not self._connect():
                        continue
                
                message_json = json.dumps(message_data)
                
                # å‘å¸ƒæ¶ˆæ¯ï¼ˆå»¶è¿Ÿä¸€æ®µæ—¶é—´å†é‡è¯•ï¼‰
                self.channel.basic_publish(
                    exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                    routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY,
                    body=message_json,
                    properties=pika.BasicProperties(
                        delivery_mode=2,
                        content_type='application/json',
                        headers={
                            'retry_count': retry_count,
                            'first_attempt_time': str(int(time.time() * 1000)),
                            'retry_delay': min(retry_count * 5, 30)  # é€’å¢å»¶è¿Ÿï¼Œæœ€å¤§30ç§’
                        }
                    )
                )
                return True
                
            except IndexError as e:
                # æ•è· pika å†…éƒ¨çš„ deque é”™è¯¯
                logger.warning(f"âš ï¸ _republish pikaå†…éƒ¨é”™è¯¯: {str(e)}")
                self.is_connected = False
                time.sleep(0.5)
                continue
                
            except Exception as e:
                logger.error(f"âŒ é‡æ–°å‘å¸ƒæ¶ˆæ¯å¤±è´¥: {str(e)}")
                self.is_connected = False
                if attempt < 2:
                    time.sleep(0.5)
                    continue
                return False
        
        return False
    
    def close(self) -> None:
        """å…³é—­è¿æ¥"""
        if self.channel:
            if self.channel.is_open:
                try:
                    self.channel.close()
                except Exception as e:
                    logger.error(f"å…³é—­é€šé“å¤±è´¥: {str(e)}")
        
        if self.connection:
            if self.connection.is_open:
                try:
                    self.connection.close()
                except Exception as e:
                    logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {str(e)}")
        
        self.is_connected = False
        logger.info("RabbitMQè¿æ¥å·²å…³é—­")
    
    def health_check(self) -> Dict[str, Any]:
        """ğŸ¥ å…¨é¢å¥åº·æ£€æŸ¥ - ä½¿ç”¨ç‹¬ç«‹è¿æ¥é¿å…ä¸æ¶ˆè´¹è€…çº¿ç¨‹å†²çª"""
        health_status = {
            "rabbitmq_connected": self.is_connected,
            "channel_open": self.channel is not None and not self.channel.is_closed if self.channel else False,
            "consumer_thread_alive": self.consumer_thread is not None and self.consumer_thread.is_alive(),
            "subscribers_count": sum(len(callbacks) for callbacks in self._subscribers.values()),
            "timestamp": datetime.now().isoformat()
        }
        
        # ä½¿ç”¨ç‹¬ç«‹è¿æ¥è·å–é˜Ÿåˆ—çŠ¶æ€ï¼Œé¿å…ä¸æ¶ˆè´¹è€… channel å†²çª
        # pika BlockingConnection ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œä¸èƒ½åœ¨å¥åº·ç›‘æ§çº¿ç¨‹ä¸­ä½¿ç”¨æ¶ˆè´¹è€…çš„ channel
        temp_connection = None
        temp_channel = None
        try:
            if self.is_connected:
                # åˆ›å»ºä¸´æ—¶è¿æ¥è¿›è¡ŒæŸ¥è¯¢
                credentials = pika.PlainCredentials(
                    settings.RABBITMQ_USER,
                    settings.RABBITMQ_PASSWORD
                )
                parameters = pika.ConnectionParameters(
                    host=settings.RABBITMQ_HOST,
                    port=settings.RABBITMQ_PORT,
                    credentials=credentials,
                    heartbeat=30,
                    blocked_connection_timeout=10
                )
                
                temp_connection = pika.BlockingConnection(parameters)
                temp_channel = temp_connection.channel()
                
                queue_info = temp_channel.queue_declare(queue=settings.RABBITMQ_ALERT_QUEUE, passive=True)
                health_status["queue_message_count"] = queue_info.method.message_count
                health_status["queue_consumer_count"] = queue_info.method.consumer_count
                health_status["queue_accessible"] = True
            else:
                health_status["queue_accessible"] = False
        except Exception as e:
            health_status["queue_accessible"] = False
            health_status["queue_error"] = str(e)
        finally:
            # ç¡®ä¿å…³é—­ä¸´æ—¶è¿æ¥
            try:
                if temp_channel and temp_channel.is_open:
                    temp_channel.close()
            except:
                pass
            try:
                if temp_connection and temp_connection.is_open:
                    temp_connection.close()
            except:
                pass
        
        # æ•´ä½“å¥åº·è¯„ä¼°
        critical_checks = [
            health_status["rabbitmq_connected"],
            health_status["channel_open"], 
            health_status["consumer_thread_alive"],
            health_status["queue_accessible"]
        ]
        
        health_status["overall_healthy"] = all(critical_checks)
        health_status["critical_issues"] = len([check for check in critical_checks if not check])
        
        return health_status
    
    def start_health_monitor(self, check_interval: int = 30) -> None:
        """ğŸ©º å¯åŠ¨å¥åº·ç›‘æ§çº¿ç¨‹"""
        if hasattr(self, 'health_monitor_thread') and self.health_monitor_thread and self.health_monitor_thread.is_alive():
            logger.info("ğŸ©º å¥åº·ç›‘æ§çº¿ç¨‹å·²åœ¨è¿è¡Œ")
            return
        
        def health_monitor():
            """å¥åº·ç›‘æ§ä¸»å¾ªç¯"""
            consecutive_unhealthy = 0
            max_unhealthy_counts = 3
            
            while True:
                try:
                    time.sleep(check_interval)
                    
                    health = self.health_check()
                    
                    if health["overall_healthy"]:
                        consecutive_unhealthy = 0
                        logger.debug(f"ğŸŸ¢ ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡: è®¢é˜…è€…æ•°={health['subscribers_count']}")
                    else:
                        consecutive_unhealthy += 1
                        logger.warning(f"ğŸŸ¡ ç³»ç»Ÿå¥åº·æ£€æŸ¥å¼‚å¸¸ #{consecutive_unhealthy}: å…³é”®é—®é¢˜æ•°={health['critical_issues']}")
                        
                        # ğŸš¨ è¿ç»­ä¸å¥åº·è¾¾åˆ°é˜ˆå€¼ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤
                        if consecutive_unhealthy >= max_unhealthy_counts:
                            logger.error(f"ğŸš¨ è¿ç»­{max_unhealthy_counts}æ¬¡å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå¯åŠ¨è‡ªåŠ¨ä¿®å¤...")
                            
                            try:
                                self.auto_repair()
                                consecutive_unhealthy = 0  # é‡ç½®è®¡æ•°å™¨
                            except Exception as repair_error:
                                logger.error(f"âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥: {str(repair_error)}")
                    
                except Exception as e:
                    logger.error(f"âŒ å¥åº·ç›‘æ§å¼‚å¸¸: {str(e)}")
                    time.sleep(5)  # çŸ­æš‚ç­‰å¾…åç»§ç»­
        
        self.health_monitor_thread = threading.Thread(target=health_monitor, daemon=True)
        self.health_monitor_thread.start()
        logger.info(f"ğŸ©º å¥åº·ç›‘æ§å·²å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {check_interval}ç§’")
    
    def auto_repair(self) -> bool:
        """ğŸ”§ æ™ºèƒ½è‡ªåŠ¨ä¿®å¤"""
        logger.info("ğŸ”§ å¼€å§‹æ™ºèƒ½è‡ªåŠ¨ä¿®å¤æµç¨‹...")
        
        repair_success = True
        
        try:
            # 1. ä¿®å¤RabbitMQè¿æ¥
            if not self.is_connected or not self.channel or self.channel.is_closed:
                logger.info("ğŸ”„ ä¿®å¤RabbitMQè¿æ¥...")
                if self._connect():
                    logger.info("âœ… RabbitMQè¿æ¥ä¿®å¤æˆåŠŸ")
                else:
                    logger.error("âŒ RabbitMQè¿æ¥ä¿®å¤å¤±è´¥")
                    repair_success = False
            
            # 2. ä¿®å¤æ¶ˆè´¹è€…çº¿ç¨‹
            if not self.consumer_thread or not self.consumer_thread.is_alive():
                logger.info("ğŸ”„ é‡å¯æ¶ˆè´¹è€…çº¿ç¨‹...")
                
                # åœæ­¢æ—§çº¿ç¨‹
                if self.consumer_thread:
                    try:
                        self.channel.stop_consuming()
                    except:
                        pass
                
                # å¯åŠ¨æ–°çº¿ç¨‹
                self.consumer_thread = threading.Thread(target=self._start_consuming, daemon=True)
                self.consumer_thread.start()
                
                # ç­‰å¾…çº¿ç¨‹å¯åŠ¨
                time.sleep(2)
                
                if self.consumer_thread.is_alive():
                    logger.info("âœ… æ¶ˆè´¹è€…çº¿ç¨‹é‡å¯æˆåŠŸ")
                else:
                    logger.error("âŒ æ¶ˆè´¹è€…çº¿ç¨‹é‡å¯å¤±è´¥")
                    repair_success = False
            
            # 3. é‡æ–°æ³¨å†Œæ‰€æœ‰è®¢é˜…è€…ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self._subscribers:
                logger.info("ğŸ”„ é‡æ–°éªŒè¯è®¢é˜…è€…æ³¨å†Œ...")
                for queue_name, callbacks in self._subscribers.items():
                    valid_callbacks = [cb for cb in callbacks if callable(cb)]
                    self._subscribers[queue_name] = valid_callbacks
                    logger.info(f"âœ… é˜Ÿåˆ— {queue_name} è®¢é˜…è€…éªŒè¯å®Œæˆ: {len(valid_callbacks)}ä¸ªæœ‰æ•ˆå›è°ƒ")
            
            if repair_success:
                logger.info("ğŸ‰ æ™ºèƒ½è‡ªåŠ¨ä¿®å¤å®Œæˆï¼")
            else:
                logger.error("ğŸ’¥ æ™ºèƒ½è‡ªåŠ¨ä¿®å¤éƒ¨åˆ†å¤±è´¥")
            
            return repair_success
            
        except Exception as e:
            logger.error(f"âŒ è‡ªåŠ¨ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
            return False
    
    def restart_consumer(self) -> bool:
        """ğŸ”„ æ‰‹åŠ¨é‡å¯æ¶ˆè´¹è€…ï¼ˆç®¡ç†æ¥å£ï¼‰"""
        logger.info("ğŸ”„ æ‰‹åŠ¨é‡å¯RabbitMQæ¶ˆè´¹è€…...")
        
        try:
            # åœæ­¢ç°æœ‰æ¶ˆè´¹è€…
            if self.consumer_thread and self.consumer_thread.is_alive():
                try:
                    if self.channel and not self.channel.is_closed:
                        self.channel.stop_consuming()
                except:
                    pass
                
                # ç­‰å¾…çº¿ç¨‹ç»“æŸ
                self.consumer_thread.join(timeout=5)
            
            # é‡æ–°è¿æ¥
            if not self._connect():
                logger.error("âŒ é‡æ–°è¿æ¥RabbitMQå¤±è´¥")
                return False
            
            # å¯åŠ¨æ–°çš„æ¶ˆè´¹è€…çº¿ç¨‹
            self.consumer_thread = threading.Thread(target=self._start_consuming, daemon=True)
            self.consumer_thread.start()
            
            # éªŒè¯å¯åŠ¨çŠ¶æ€
            time.sleep(2)
            if self.consumer_thread.is_alive():
                logger.info("âœ… æ¶ˆè´¹è€…é‡å¯æˆåŠŸ")
                return True
            else:
                logger.error("âŒ æ¶ˆè´¹è€…é‡å¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é‡å¯æ¶ˆè´¹è€…å¼‚å¸¸: {str(e)}", exc_info=True)
            return False
    
    def get_consumer_status(self) -> Dict[str, Any]:
        """ğŸ“Š è·å–æ¶ˆè´¹è€…è¯¦ç»†çŠ¶æ€"""
        status = {
            "consumer_thread_id": self.consumer_thread.ident if self.consumer_thread else None,
            "consumer_thread_name": self.consumer_thread.name if self.consumer_thread else None,
            "consumer_thread_alive": self.consumer_thread.is_alive() if self.consumer_thread else False,
            "consumer_thread_daemon": self.consumer_thread.daemon if self.consumer_thread else None,
            "connection_status": {
                "is_connected": self.is_connected,
                "connection_open": self.connection.is_open if self.connection else False,
                "channel_open": not self.channel.is_closed if self.channel else False
            },
            "subscribers": {
                queue: len(callbacks) for queue, callbacks in self._subscribers.items()
            },
            "total_subscribers": sum(len(callbacks) for callbacks in self._subscribers.values()),
            "timestamp": datetime.now().isoformat()
        }
        
        # æ·»åŠ é˜Ÿåˆ—ç»Ÿè®¡
        try:
            if self.is_connected and self.channel:
                queue_info = self.channel.queue_declare(queue=settings.RABBITMQ_ALERT_QUEUE, passive=True)
                status["queue_stats"] = {
                    "message_count": queue_info.method.message_count,
                    "consumer_count": queue_info.method.consumer_count,
                    "queue_name": settings.RABBITMQ_ALERT_QUEUE
                }
        except Exception as e:
            status["queue_stats"] = {"error": str(e)}
        
        return status

# åˆ›å»ºå…¨å±€RabbitMQå®¢æˆ·ç«¯å®ä¾‹
rabbitmq_client = RabbitMQClient() 