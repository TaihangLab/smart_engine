import json
import logging
import threading
import time
from typing import Callable, Dict, List, Any, Optional, Tuple
import pika
from pika.adapters.blocking_connection import BlockingChannel

from app.core.config import settings

logger = logging.getLogger(__name__)

class RabbitMQClient:
    """RabbitMQå®¢æˆ·ç«¯ï¼Œç”¨äºæ¶ˆæ¯å‘å¸ƒå’Œè®¢é˜…ï¼Œæ”¯æŒæ­»ä¿¡é˜Ÿåˆ—"""
    
    def __init__(self):
        self.connection = None
        self.channel = None
        self.is_connected = False
        self.consumer_thread = None
        self._subscribers = {}  # ç”¨äºå­˜å‚¨æ¶ˆæ¯è®¢é˜…å›è°ƒå‡½æ•°
        
        # æ­»ä¿¡é˜Ÿåˆ—é…ç½®
        self.dead_letter_exchange = f"{settings.RABBITMQ_ALERT_EXCHANGE}.dlx"
        self.dead_letter_queue = f"{settings.RABBITMQ_ALERT_QUEUE}.dlq"
        self.dead_letter_routing_key = f"{settings.RABBITMQ_ALERT_ROUTING_KEY}.dead"
        
        self._connect()
    
    def _connect(self) -> bool:
        """è¿æ¥åˆ°RabbitMQæœåŠ¡å™¨"""
        try:
            # è¿æ¥å‚æ•°
            credentials = pika.PlainCredentials(
                settings.RABBITMQ_USER, 
                settings.RABBITMQ_PASSWORD
            )
            parameters = pika.ConnectionParameters(
                host=settings.RABBITMQ_HOST,
                port=settings.RABBITMQ_PORT,
                credentials=credentials,
                heartbeat=600,
                blocked_connection_timeout=300
            )
            
            # åˆ›å»ºè¿æ¥å’Œé€šé“
            self.connection = pika.BlockingConnection(parameters)
            self.channel = self.connection.channel()
            
            # é…ç½®æ­»ä¿¡é˜Ÿåˆ—
            self._setup_dead_letter_queue()
            
            # å£°æ˜ä¸»äº¤æ¢æœº
            self.channel.exchange_declare(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                exchange_type='direct',
                durable=True
            )
            
            # å£°æ˜ä¸»é˜Ÿåˆ—ï¼ˆå¸¦æ­»ä¿¡é˜Ÿåˆ—é…ç½®ï¼‰
            self.channel.queue_declare(
                queue=settings.RABBITMQ_ALERT_QUEUE,
                durable=True,
                arguments={
                    'x-dead-letter-exchange': self.dead_letter_exchange,
                    'x-dead-letter-routing-key': self.dead_letter_routing_key,
                    'x-message-ttl': settings.RABBITMQ_MESSAGE_TTL,  # ä»é…ç½®æ–‡ä»¶è·å–TTL
                    'x-max-retries': settings.RABBITMQ_MAX_RETRIES  # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§é‡è¯•æ¬¡æ•°
                }
            )
            
            # ç»‘å®šä¸»é˜Ÿåˆ—åˆ°äº¤æ¢æœº
            self.channel.queue_bind(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                queue=settings.RABBITMQ_ALERT_QUEUE,
                routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY
            )
            
            self.is_connected = True
            logger.info("âœ… å·²æˆåŠŸè¿æ¥åˆ°RabbitMQæœåŠ¡å™¨ï¼Œæ­»ä¿¡é˜Ÿåˆ—é…ç½®å®Œæˆ")
            return True
        
        except Exception as e:
            logger.error(f"âŒ è¿æ¥RabbitMQå¤±è´¥: {str(e)}")
            self.is_connected = False
            return False
    
    def _setup_dead_letter_queue(self) -> None:
        """é…ç½®æ­»ä¿¡é˜Ÿåˆ—"""
        try:
            # å£°æ˜æ­»ä¿¡äº¤æ¢æœº
            self.channel.exchange_declare(
                exchange=self.dead_letter_exchange,
                exchange_type='direct',
                durable=True
            )
            
            # å£°æ˜æ­»ä¿¡é˜Ÿåˆ—
            self.channel.queue_declare(
                queue=self.dead_letter_queue,
                durable=True,
                arguments={
                    'x-message-ttl': settings.RABBITMQ_DEAD_LETTER_TTL,  # ä»é…ç½®æ–‡ä»¶è·å–æ­»ä¿¡TTL
                    'x-max-length': settings.RABBITMQ_DEAD_LETTER_MAX_LENGTH  # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§é•¿åº¦
                }
            )
            
            # ç»‘å®šæ­»ä¿¡é˜Ÿåˆ—åˆ°æ­»ä¿¡äº¤æ¢æœº
            self.channel.queue_bind(
                exchange=self.dead_letter_exchange,
                queue=self.dead_letter_queue,
                routing_key=self.dead_letter_routing_key
            )
            
            logger.info(f"ğŸ”§ æ­»ä¿¡é˜Ÿåˆ—é…ç½®å®Œæˆ: {self.dead_letter_queue}")
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
            raise
    
    def publish_alert(self, alert_data: Dict[str, Any]) -> bool:
        """å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯åˆ°RabbitMQ"""
        if not self.is_connected:
            if not self._connect():
                return False
        
        try:
            # å°†æ¶ˆæ¯è½¬æ¢ä¸ºJSON
            message = json.dumps(alert_data)
            
            # å‘å¸ƒæ¶ˆæ¯
            self.channel.basic_publish(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY,
                body=message,
                properties=pika.BasicProperties(
                    delivery_mode=2,  # æŒä¹…åŒ–æ¶ˆæ¯
                    content_type='application/json',
                    headers={
                        'retry_count': 0,  # åˆå§‹é‡è¯•æ¬¡æ•°
                        'first_attempt_time': str(int(time.time() * 1000))  # é¦–æ¬¡å°è¯•æ—¶é—´æˆ³
                    }
                )
            )
            
            logger.info(f"ğŸ“¤ å·²å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯: ç±»å‹={alert_data.get('alert_type', 'unknown')}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒæŠ¥è­¦æ¶ˆæ¯å¤±è´¥: {str(e)}")
            self.is_connected = False
            return False
    
    def get_dead_letter_messages(self, max_count: int = 100) -> List[Dict[str, Any]]:
        """è·å–æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯"""
        if not self.is_connected:
            if not self._connect():
                return []
        
        dead_messages = []
        try:
            # è·å–æ­»ä¿¡é˜Ÿåˆ—ä¿¡æ¯
            queue_info = self.channel.queue_declare(
                queue=self.dead_letter_queue, 
                passive=True
            )
            message_count = queue_info.method.message_count
            
            if message_count == 0:
                logger.debug("ğŸ“­ æ­»ä¿¡é˜Ÿåˆ—ä¸ºç©º")
                return []
            
            logger.info(f"ğŸ” æ­»ä¿¡é˜Ÿåˆ—ä¸­æœ‰ {message_count} æ¡æ¶ˆæ¯")
            
            # è·å–æ­»ä¿¡æ¶ˆæ¯ï¼ˆä¸è‡ªåŠ¨ç¡®è®¤ï¼‰
            count = 0
            while count < min(max_count, message_count):
                method, properties, body = self.channel.basic_get(
                    queue=self.dead_letter_queue,
                    auto_ack=False
                )
                
                if method is None:
                    break
                
                try:
                    # è§£ææ¶ˆæ¯
                    message_data = json.loads(body.decode('utf-8'))
                    
                    # è·å–æ­»ä¿¡ç›¸å…³ä¿¡æ¯
                    dead_info = {
                        'message_data': message_data,
                        'delivery_tag': method.delivery_tag,
                        'routing_key': method.routing_key,
                        'dead_reason': properties.headers.get('x-first-death-reason') if properties.headers else 'unknown',
                        'death_count': properties.headers.get('x-death', [{}])[0].get('count', 0) if properties.headers else 0,
                        'first_death_time': properties.headers.get('x-first-death-time') if properties.headers else None,
                        'retry_count': properties.headers.get('retry_count', 0) if properties.headers else 0
                    }
                    
                    dead_messages.append(dead_info)
                    count += 1
                    
                    # æš‚æ—¶ä¸ç¡®è®¤æ¶ˆæ¯ï¼Œç­‰å¾…å¤„ç†ç»“æœ
                    
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ è§£ææ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                    # ç¡®è®¤å¹¶ä¸¢å¼ƒæ— æ³•è§£æçš„æ¶ˆæ¯
                    self.channel.basic_ack(delivery_tag=method.delivery_tag)
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                    # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
                    self.channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
            
            logger.info(f"ğŸ“‹ è·å–åˆ° {len(dead_messages)} æ¡æ­»ä¿¡æ¶ˆæ¯")
            return dead_messages
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return []
    
    def reprocess_dead_message(self, delivery_tag: int, message_data: Dict[str, Any], 
                              increase_retry: bool = True) -> bool:
        """é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯"""
        try:
            # å¢åŠ é‡è¯•è®¡æ•°
            if increase_retry:
                retry_count = message_data.get('retry_count', 0) + 1
                message_data['retry_count'] = retry_count
            
            # é‡æ–°å‘å¸ƒåˆ°ä¸»é˜Ÿåˆ—
            success = self.publish_alert(message_data)
            
            if success:
                # ç¡®è®¤æ­»ä¿¡æ¶ˆæ¯å·²å¤„ç†
                self.channel.basic_ack(delivery_tag=delivery_tag)
                logger.info(f"âœ… æ­»ä¿¡æ¶ˆæ¯é‡æ–°å¤„ç†æˆåŠŸ: {message_data.get('alert_type', 'unknown')}")
                return True
            else:
                # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
                self.channel.basic_nack(delivery_tag=delivery_tag, requeue=False)
                logger.error(f"âŒ æ­»ä¿¡æ¶ˆæ¯é‡æ–°å‘å¸ƒå¤±è´¥: {message_data.get('alert_type', 'unknown')}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯å¼‚å¸¸: {str(e)}")
            try:
                # å‘ç”Ÿå¼‚å¸¸æ—¶æ‹’ç»æ¶ˆæ¯
                self.channel.basic_nack(delivery_tag=delivery_tag, requeue=False)
            except:
                pass
            return False
    
    def purge_dead_letter_queue(self) -> int:
        """æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—"""
        try:
            result = self.channel.queue_purge(queue=self.dead_letter_queue)
            purged_count = result.method.message_count
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—ï¼Œåˆ é™¤äº† {purged_count} æ¡æ¶ˆæ¯")
            return purged_count
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
            return 0
    
    def get_dead_letter_queue_stats(self) -> Dict[str, Any]:
        """è·å–æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        try:
            queue_info = self.channel.queue_declare(
                queue=self.dead_letter_queue, 
                passive=True
            )
            
            return {
                'queue_name': self.dead_letter_queue,
                'message_count': queue_info.method.message_count,
                'consumer_count': queue_info.method.consumer_count,
                'status': 'available'
            }
        except Exception as e:
            logger.error(f"âŒ è·å–æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {
                'queue_name': self.dead_letter_queue,
                'message_count': 0,
                'consumer_count': 0,
                'status': 'error',
                'error': str(e)
            }
    
    def subscribe_to_alerts(self, callback: Callable[[Dict[str, Any]], None]) -> None:
        """è®¢é˜…æŠ¥è­¦æ¶ˆæ¯"""
        if not self.is_connected:
            self._connect()
        
        # æ·»åŠ å›è°ƒå‡½æ•°åˆ°è®¢é˜…è€…åˆ—è¡¨
        queue_name = settings.RABBITMQ_ALERT_QUEUE
        if queue_name not in self._subscribers:
            self._subscribers[queue_name] = []
        self._subscribers[queue_name].append(callback)
        
        # å¦‚æœæ¶ˆè´¹è€…çº¿ç¨‹æœªå¯åŠ¨ï¼Œåˆ™å¯åŠ¨å®ƒ
        if self.consumer_thread is None or not self.consumer_thread.is_alive():
            self.consumer_thread = threading.Thread(target=self._start_consuming)
            self.consumer_thread.daemon = True
            logger.info(f"å¯åŠ¨RabbitMQæ¶ˆè´¹è€…çº¿ç¨‹ï¼Œè®¢é˜…é˜Ÿåˆ—: {queue_name}")
            self.consumer_thread.start()
    
    def _start_consuming(self) -> None:
        """å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯çš„å†…éƒ¨æ–¹æ³•"""
        try:
            def _callback(ch: BlockingChannel, method, properties, body):
                """æ¶ˆæ¯å›è°ƒå‡½æ•°"""
                try:
                    # è§£ææ¶ˆæ¯
                    message = json.loads(body.decode('utf-8'))
                    
                    # è·å–é‡è¯•ä¿¡æ¯
                    retry_count = properties.headers.get('retry_count', 0) if properties.headers else 0
                    max_retries = settings.RABBITMQ_MAX_RETRIES  # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§é‡è¯•æ¬¡æ•°
                    
                    logger.info(f"ğŸ”” æ¥æ”¶åˆ°æŠ¥è­¦æ¶ˆæ¯: ç±»å‹={message.get('alert_type', 'unknown')}, "
                                f"æ‘„åƒå¤´={message.get('camera_id', 'unknown')}, é‡è¯•æ¬¡æ•°={retry_count}")
                    
                    # è°ƒç”¨æ‰€æœ‰è®¢é˜…è€…çš„å›è°ƒå‡½æ•°
                    consuming_queue = settings.RABBITMQ_ALERT_QUEUE
                    success = True
                    
                    if consuming_queue in self._subscribers:
                        for callback in self._subscribers[consuming_queue]:
                            try:
                                logger.debug(f"ğŸ“ è°ƒç”¨è®¢é˜…è€…å›è°ƒ: {callback.__qualname__ if hasattr(callback, '__qualname__') else 'unknown'}")
                                callback(message)
                            except Exception as callback_error:
                                logger.error(f"âŒ è®¢é˜…è€…å›è°ƒå¼‚å¸¸: {str(callback_error)}", exc_info=True)
                                success = False
                                break
                    else:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é˜Ÿåˆ— '{consuming_queue}' çš„è®¢é˜…è€…")
                        success = False
                    
                    if success:
                        # å¤„ç†æˆåŠŸï¼Œç¡®è®¤æ¶ˆæ¯
                        ch.basic_ack(delivery_tag=method.delivery_tag)
                        logger.debug(f"âœ… ç¡®è®¤å¤„ç†æŠ¥è­¦æ¶ˆæ¯: {message.get('alert_type', 'unknown')}")
                    else:
                        # å¤„ç†å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                        if retry_count < max_retries:
                            # é‡æ–°å‘å¸ƒæ¶ˆæ¯åˆ°é˜Ÿåˆ—å°¾éƒ¨
                            self._republish_with_retry(message, retry_count + 1)
                            ch.basic_ack(delivery_tag=method.delivery_tag)  # ç¡®è®¤åŸæ¶ˆæ¯
                            logger.warning(f"ğŸ”„ æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œé‡è¯• {retry_count + 1}/{max_retries}: {message.get('alert_type', 'unknown')}")
                        else:
                            # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ‹’ç»æ¶ˆæ¯ï¼ˆå°†è¿›å…¥æ­»ä¿¡é˜Ÿåˆ—ï¼‰
                            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                            logger.error(f"ğŸ’€ æ¶ˆæ¯å¤„ç†å¤±è´¥è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—: {message.get('alert_type', 'unknown')}")
                    
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ è§£ææ¶ˆæ¯å¤±è´¥: {body}, é”™è¯¯: {str(e)}")
                    ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}", exc_info=True)
                    
                    # è·å–é‡è¯•æ¬¡æ•°
                    retry_count = properties.headers.get('retry_count', 0) if properties.headers else 0
                    
                    if retry_count < settings.RABBITMQ_MAX_RETRIES:  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æœ€å¤§é‡è¯•æ¬¡æ•°
                        # é‡æ–°å…¥é˜Ÿç­‰å¾…é‡è¯•
                        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
                        logger.warning(f"ğŸ”„ æ¶ˆæ¯é‡æ–°å…¥é˜Ÿç­‰å¾…é‡è¯•: {retry_count + 1}/{settings.RABBITMQ_MAX_RETRIES}")
                    else:
                        # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—
                        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
                        logger.error(f"ï¿½ï¿½ æ¶ˆæ¯è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—")
            
            # è®¾ç½®QoS
            self.channel.basic_qos(prefetch_count=1)
            
            # å¼€å§‹æ¶ˆè´¹
            self.channel.basic_consume(
                queue=settings.RABBITMQ_ALERT_QUEUE,
                on_message_callback=_callback
            )
            
            logger.info(f"ğŸ§ å¼€å§‹æ¶ˆè´¹æŠ¥è­¦æ¶ˆæ¯ï¼Œé˜Ÿåˆ—: {settings.RABBITMQ_ALERT_QUEUE}")
            self.channel.start_consuming()
            
        except Exception as e:
            logger.error(f"âŒ æ¶ˆè´¹æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}", exc_info=True)
            self.is_connected = False
    
    def _republish_with_retry(self, message_data: Dict[str, Any], retry_count: int) -> bool:
        """é‡æ–°å‘å¸ƒæ¶ˆæ¯ï¼ˆå¸¦é‡è¯•è®¡æ•°ï¼‰"""
        try:
            message_json = json.dumps(message_data)
            
            # å‘å¸ƒæ¶ˆæ¯ï¼ˆå»¶è¿Ÿä¸€æ®µæ—¶é—´å†é‡è¯•ï¼‰
            self.channel.basic_publish(
                exchange=settings.RABBITMQ_ALERT_EXCHANGE,
                routing_key=settings.RABBITMQ_ALERT_ROUTING_KEY,
                body=message_json,
                properties=pika.BasicProperties(
                    delivery_mode=2,
                    content_type='application/json',
                    headers={
                        'retry_count': retry_count,
                        'first_attempt_time': str(int(time.time() * 1000)),
                        'retry_delay': min(retry_count * 5, 30)  # é€’å¢å»¶è¿Ÿï¼Œæœ€å¤§30ç§’
                    }
                )
            )
            return True
        except Exception as e:
            logger.error(f"âŒ é‡æ–°å‘å¸ƒæ¶ˆæ¯å¤±è´¥: {str(e)}")
            return False
    
    def close(self) -> None:
        """å…³é—­è¿æ¥"""
        if self.channel:
            if self.channel.is_open:
                try:
                    self.channel.close()
                except Exception as e:
                    logger.error(f"å…³é—­é€šé“å¤±è´¥: {str(e)}")
        
        if self.connection:
            if self.connection.is_open:
                try:
                    self.connection.close()
                except Exception as e:
                    logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {str(e)}")
        
        self.is_connected = False
        logger.info("RabbitMQè¿æ¥å·²å…³é—­")

# åˆ›å»ºå…¨å±€RabbitMQå®¢æˆ·ç«¯å®ä¾‹
rabbitmq_client = RabbitMQClient() 