"""
åŸºäºLangGraphçš„æ™ºèƒ½ä»£ç†å·¥ä½œæµç¼–æ’å™¨

ä½¿ç”¨LangGraphæ„å»º7å±‚åˆ†ææµç¨‹çš„çŠ¶æ€æœºï¼š
1. YOLOå¿«é€Ÿæ£€æµ‹
2. åœºæ™¯ç†è§£ï¼ˆç…¤çŸ¿å¤šæ¨¡æ€LLMï¼‰
3. æ™ºèƒ½å†³ç­–ï¼ˆæ€è€ƒLLM + RAGï¼‰
4. å¸§æ”¶é›†
5. æ—¶åºåˆ†æï¼ˆç…¤çŸ¿å¤šæ¨¡æ€LLMï¼‰
6. ç»¼åˆæ¨ç†ï¼ˆæ€è€ƒLLMï¼‰
7. è‡ªåŠ¨å¤„ç½®
"""
import logging
from typing import Dict, Any, Optional, List, TypedDict, Annotated
import numpy as np
import base64
import cv2
from operator import add

# LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

logger = logging.getLogger(__name__)


# ==================== çŠ¶æ€å®šä¹‰ ====================

class AgentState(TypedDict):
    """
    å·¥ä½œæµçŠ¶æ€å®šä¹‰
    
    LangGraphçš„æ ¸å¿ƒæ˜¯Stateï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½è¯»å†™è¿™ä¸ªState
    """
    # è¾“å…¥
    frame: np.ndarray  # å½“å‰å¸§
    task_id: int  # ä»»åŠ¡ID
    camera_id: int  # æ‘„åƒå¤´ID
    task_config: Dict[str, Any]  # ä»»åŠ¡é…ç½®
    
    # ç¬¬1å±‚ï¼šYOLOæ£€æµ‹
    yolo_result: Optional[Dict[str, Any]]  # YOLOæ£€æµ‹ç»“æœ
    has_target: bool  # æ˜¯å¦æ£€æµ‹åˆ°ç›®æ ‡
    
    # ç¬¬2å±‚ï¼šåœºæ™¯ç†è§£
    scene_description: Optional[str]  # åœºæ™¯æè¿°
    
    # ç¬¬3å±‚ï¼šæ™ºèƒ½å†³ç­–
    decision_type: Optional[str]  # A, B1, B2
    task_type: Optional[str]  # ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ï¼šå—é™ç©ºé—´ä½œä¸šï¼‰
    expected_duration: Optional[int]  # é¢„æœŸæ—¶é•¿
    checklist: Optional[List[Dict[str, Any]]]  # æ£€æŸ¥æ¸…å•
    risk_level: Optional[str]  # é£é™©ç­‰çº§
    
    # ç¬¬4å±‚ï¼šå¸§æ”¶é›†
    frame_buffer: Annotated[List[np.ndarray], add]  # å¸§ç¼“å†²åŒºï¼ˆä½¿ç”¨addä½œä¸ºreducerï¼‰
    buffer_full: bool  # ç¼“å†²åŒºæ˜¯å¦æ»¡
    current_batch: int  # å½“å‰æ‰¹æ¬¡
    
    # ç¬¬5å±‚ï¼šæ—¶åºåˆ†æ
    batch_analyses: Annotated[List[Dict[str, Any]], add]  # æ‰¹æ¬¡åˆ†æç»“æœï¼ˆç´¯ç§¯ï¼‰
    task_completed: bool  # ä½œä¸šæ˜¯å¦å®Œæˆ
    current_stage: Optional[str]  # å½“å‰é˜¶æ®µ
    
    # ç¬¬6å±‚ï¼šç»¼åˆæ¨ç†
    violation_detected: bool  # æ˜¯å¦è¿è§„
    violation_type: Optional[str]  # è¿è§„ç±»å‹
    severity_level: int  # ä¸¥é‡ç­‰çº§
    disposal_plan: Optional[Dict[str, Any]]  # å¤„ç½®æ–¹æ¡ˆ
    
    # ç¬¬7å±‚ï¼šè‡ªåŠ¨å¤„ç½®
    disposal_result: Optional[Dict[str, Any]]  # å¤„ç½®ç»“æœ
    
    # æ§åˆ¶æµ
    next_action: Optional[str]  # ä¸‹ä¸€æ­¥åŠ¨ä½œ
    messages: Annotated[List[BaseMessage], add]  # LangChainæ¶ˆæ¯ï¼ˆç”¨äºLLMäº¤äº’ï¼‰


# ==================== èŠ‚ç‚¹å®šä¹‰ ====================

class Layer1YOLODetection:
    """ç¬¬1å±‚ï¼šYOLOå¿«é€Ÿæ£€æµ‹ï¼ˆé€šç”¨ï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹å±‚
        
        Args:
            config: YOLOé…ç½®ï¼ŒåŒ…å«skill_name, target_classes, confidence_thresholdç­‰
        """
        self.yolo_skill_name = config.get("skill_name", "coco_detector")
        self.target_classes = config.get("target_classes")
        self.confidence_threshold = config.get("confidence_threshold")
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """
        æ‰§è¡ŒYOLOæ£€æµ‹
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            çŠ¶æ€æ›´æ–°
        """
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 1] YOLOå¿«é€Ÿæ£€æµ‹ - å¼€å§‹")
        logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}, æ‘„åƒå¤´ID: {state.get('camera_id')}")
        logger.info(f"âš™ï¸ YOLOæŠ€èƒ½: {self.yolo_skill_name}")
        logger.info(f"ğŸ¯ ç›®æ ‡ç±»åˆ«: {self.target_classes}")
        
        try:
            frame = state["frame"]
            logger.info(f"ğŸ–¼ï¸ è¾“å…¥å¸§å°ºå¯¸: {frame.shape if hasattr(frame, 'shape') else 'N/A'}")
            
            # å®é™…è°ƒç”¨YOLOæŠ€èƒ½
            try:
                from app.skills.skill_factory import skill_factory
                yolo_skill = skill_factory.create_skill(self.yolo_skill_name)
                logger.debug(f"âœ… YOLOæŠ€èƒ½åŠ è½½æˆåŠŸ: {self.yolo_skill_name}")
                
                result = yolo_skill.process(frame)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹åˆ°ç›®æ ‡
                if result.success and result.data:
                    detections = result.data.get("detections", [])
                    has_target = len(detections) > 0
                    yolo_result = {
                        "detections": detections,
                        "processing_time": result.data.get("processing_time", 0)
                    }
                else:
                    # YOLOæŠ€èƒ½å¤±è´¥ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
                    detections = []
                    has_target = True  # é™çº§ç­–ç•¥ï¼šå‡è®¾æœ‰ç›®æ ‡ï¼Œç»§ç»­åç»­æµç¨‹
                    yolo_result = {
                        "detections": [],
                        "processing_time": 0,
                        "error": result.error_message if hasattr(result, 'error_message') else "Unknown error"
                    }
                
                logger.info(f"âœ… YOLOæ£€æµ‹å®Œæˆ: æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
                if detections:
                    for i, det in enumerate(detections[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        logger.debug(f"   ç›®æ ‡{i+1}: {det.get('class')} (ç½®ä¿¡åº¦: {det.get('confidence', 0):.2f})")
                
            except Exception as e:
                logger.warning(f"âš ï¸ YOLOæŠ€èƒ½è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é™çº§ç­–ç•¥: {str(e)}")
                # é™çº§ï¼šé»˜è®¤è®¤ä¸ºæœ‰ç›®æ ‡
                has_target = True
                yolo_result = {
                    "detections": [],
                    "processing_time": 0,
                    "error": str(e)
                }
            
            elapsed = time.time() - start_time
            next_action = "scene_understanding" if has_target else "skip"
            
            logger.info(f"ğŸ¯ æ£€æµ‹ç»“æœ: has_target={has_target}")
            logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: {next_action}")
            logger.info(f"â±ï¸ Layer 1 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 1] YOLOå¿«é€Ÿæ£€æµ‹ - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "yolo_result": yolo_result,
                "has_target": has_target,
                "next_action": next_action
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 1] YOLOæ£€æµ‹å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 1 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "has_target": False,
                "next_action": "skip"
            }


class Layer2SceneUnderstanding:
    """ç¬¬2å±‚ï¼šåœºæ™¯ç†è§£ï¼ˆé€šç”¨å¤šæ¨¡æ€LLMï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–åœºæ™¯ç†è§£å±‚
        
        Args:
            config: åœºæ™¯ç†è§£é…ç½®ï¼ŒåŒ…å«model_name, system_prompt, user_promptç­‰
        """
        self.model_name = config.get("model_name", "multimodal_llm")
        self.system_prompt = config.get("system_prompt", "ä½ æ˜¯åœºæ™¯åˆ†æä¸“å®¶ã€‚")
        self.user_prompt = config.get("user_prompt", "è¯·æè¿°ç”»é¢å†…å®¹ã€‚")
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œåœºæ™¯ç†è§£"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 2] åœºæ™¯ç†è§£ - å¼€å§‹")
        logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}")
        logger.info(f"ğŸ¤– æ¨¡å‹: {self.model_name}")
        logger.info(f"ğŸ’¬ ç³»ç»Ÿæç¤ºè¯: {self.system_prompt[:50]}...")
        
        try:
            frame = state["frame"]
            
            # ç¼–ç å›¾åƒ
            image_data = frame  # LLMæœåŠ¡æ”¯æŒç›´æ¥ä¼ å…¥numpyæ•°ç»„
            logger.debug(f"ğŸ–¼ï¸ å›¾åƒæ•°æ®å‡†å¤‡å®Œæˆ")
            
            # ä½¿ç”¨é…ç½®çš„æç¤ºè¯
            system_prompt = self.system_prompt
            user_prompt = self.user_prompt
            
            logger.info(f"ğŸ“ ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(user_prompt)} å­—ç¬¦")
            
            # è°ƒç”¨LLMæœåŠ¡
            try:
                from app.services.llm_service import llm_service
                logger.debug(f"ğŸ”„ å¼€å§‹è°ƒç”¨LLMæœåŠ¡...")
                
                result = llm_service.call_llm(
                    prompt=user_prompt,
                    system_prompt=system_prompt,
                    image_data=image_data,
                    skill_type=self.model_name
                )
                
                if result.success:
                    scene_description = result.response
                    logger.info(f"âœ… LLMè°ƒç”¨æˆåŠŸ")
                    logger.info(f"ğŸ“„ åœºæ™¯æè¿°é•¿åº¦: {len(scene_description)} å­—ç¬¦")
                    logger.debug(f"ğŸ“„ åœºæ™¯æè¿°é¢„è§ˆ: {scene_description[:100]}...")
                else:
                    logger.warning(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {result.error_message}")
                    scene_description = "åœºæ™¯åˆ†æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æè¿°"
                    
            except Exception as e:
                logger.warning(f"âš ï¸ LLMæœåŠ¡è°ƒç”¨å¼‚å¸¸: {str(e)}")
                # é™çº§å¤„ç†
                scene_description = f"åœºæ™¯åˆ†æå¼‚å¸¸ï¼ˆ{str(e)[:30]}...ï¼‰ï¼Œç»§ç»­å¤„ç†"
            
            elapsed = time.time() - start_time
            
            logger.info(f"ğŸ“„ åœºæ™¯æè¿°: {scene_description[:80]}...")
            logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: decision_engine")
            logger.info(f"â±ï¸ Layer 2 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 2] åœºæ™¯ç†è§£ - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "scene_description": scene_description,
                "messages": [AIMessage(content=scene_description)],
                "next_action": "decision_engine"
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 2] åœºæ™¯ç†è§£å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 2 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "scene_description": f"åœºæ™¯ç†è§£å¤±è´¥: {str(e)}",
                "next_action": "decision_engine"  # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­æµç¨‹
            }
    
    def _encode_frame(self, frame: np.ndarray) -> str:
        """ç¼–ç å¸§ä¸ºbase64"""
        _, buffer = cv2.imencode('.jpg', frame)
        return base64.b64encode(buffer).decode('utf-8')


class Layer3DecisionEngine:
    """ç¬¬3å±‚ï¼šæ™ºèƒ½å†³ç­–å¼•æ“ï¼ˆé€šç”¨æ€è€ƒLLM + RAGï¼‰"""
    
    def __init__(self, config: Dict[str, Any], knowledge_base=None, skill=None):
        """
        åˆå§‹åŒ–å†³ç­–å¼•æ“å±‚
        
        Args:
            config: å†³ç­–é…ç½®ï¼ŒåŒ…å«model_name, system_prompt, user_prompt_templateç­‰
            knowledge_base: çŸ¥è¯†åº“æœåŠ¡
            skill: æŠ€èƒ½å®ä¾‹ï¼ˆç”¨äºè°ƒç”¨infer_task_typeæ–¹æ³•ï¼‰
        """
        self.model_name = config.get("model_name", "reasoning_llm")
        self.system_prompt = config.get("system_prompt", "ä½ æ˜¯å†³ç­–å¼•æ“ã€‚")
        self.user_prompt_template = config.get("user_prompt_template", "{scene_description}")
        self.knowledge_base = knowledge_base
        self.skill = skill
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œæ™ºèƒ½å†³ç­–"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 3] æ™ºèƒ½å†³ç­–å¼•æ“ - å¼€å§‹")
        logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}")
        logger.info(f"ğŸ¤– å†³ç­–æ¨¡å‹: {self.model_name}")
        logger.info(f"ğŸ“š çŸ¥è¯†åº“: {'å·²è¿æ¥' if self.knowledge_base else 'æœªè¿æ¥'}")
        
        try:
            scene_description = state["scene_description"]
            logger.info(f"ğŸ“„ åœºæ™¯æè¿°: {scene_description[:60]}...")
            
            # ä»çŸ¥è¯†åº“æ£€ç´¢
            task_context = ""
            expected_duration = None
            checklist = []
            task_type = None
            
            if self.knowledge_base:
                # ä½¿ç”¨æŠ€èƒ½çš„æ¨æ–­æ–¹æ³•
                if self.skill and hasattr(self.skill, 'infer_task_type'):
                    task_type = self.skill.infer_task_type(scene_description)
                    logger.info(f"ğŸ” æ¨æ–­ä»»åŠ¡ç±»å‹: {task_type if task_type else 'æœªè¯†åˆ«'}")
                
                if task_type:
                    regulation = self.knowledge_base.query_regulation(task_type)
                    if regulation:
                        task_context = f"ç›¸å…³å®‰å…¨è§„èŒƒï¼š{regulation['title']}\n"
                        logger.debug(f"ğŸ“‹ è·å–å®‰å…¨è§„èŒƒ: {regulation['title']}")
                    
                    duration_info = self.knowledge_base.get_expected_duration(task_type)
                    if duration_info:
                        expected_duration = duration_info.get("typical")
                        logger.info(f"â±ï¸ é¢„æœŸæ—¶é•¿: {expected_duration}ç§’")
                    
                    checklist = self.knowledge_base.get_checklist(task_type)
                    logger.info(f"âœ… æ£€æŸ¥æ¸…å•: {len(checklist)}é¡¹")
            
            # ä½¿ç”¨é…ç½®çš„æç¤ºè¯æ¨¡æ¿
            system_prompt = self.system_prompt
            user_prompt = self.user_prompt_template.format(
                scene_description=scene_description,
                task_context=task_context if task_context else "æš‚æ— "
            )
            logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(user_prompt)} å­—ç¬¦")
            
            # è°ƒç”¨æ€è€ƒLLM
            try:
                from app.services.llm_service import llm_service
                logger.debug(f"ğŸ”„ å¼€å§‹è°ƒç”¨å†³ç­–LLM...")
                
                result = llm_service.call_llm(
                    system_prompt=system_prompt,
                    prompt=user_prompt,
                    response_format={"type": "json_object"},
                    skill_type=self.model_name
                )
                
                if result.success and result.analysis_result:
                    decision_data = result.analysis_result
                    decision_type = decision_data.get("decision", "B2")
                    risk_level = decision_data.get("risk_level", "medium")
                    logger.info(f"âœ… LLMå†³ç­–æˆåŠŸ")
                    logger.info(f"ğŸ“Š å†³ç­–ç»“æœ: {decision_data}")
                else:
                    logger.warning(f"âš ï¸ LLMå†³ç­–å¤±è´¥: {result.error_message}")
                    # é™çº§ï¼šé»˜è®¤ä½¿ç”¨æ—¶åºåˆ†æ
                    decision_type = "B2"
                    risk_level = "medium"
                    
            except Exception as e:
                logger.warning(f"âš ï¸ LLMæœåŠ¡è°ƒç”¨å¼‚å¸¸: {str(e)}")
                # é™çº§å¤„ç†
                decision_type = "B2"
                risk_level = "medium"
            
            elapsed = time.time() - start_time
            next_action = decision_type.lower()
            
            logger.info(f"ğŸ¯ å†³ç­–ç±»å‹: {decision_type}")
            logger.info(f"ğŸ·ï¸ ä»»åŠ¡ç±»å‹: {task_type if task_type else 'N/A'}")
            logger.info(f"âš ï¸ é£é™©ç­‰çº§: {risk_level}")
            logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: {next_action}")
            logger.info(f"â±ï¸ Layer 3 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 3] æ™ºèƒ½å†³ç­–å¼•æ“ - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "decision_type": decision_type,
                "task_type": task_type,
                "expected_duration": expected_duration,
                "checklist": checklist,
                "risk_level": risk_level,
                "next_action": next_action
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 3] å†³ç­–å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 3 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "decision_type": "A",
                "next_action": "a"
            }


class Layer4FrameCollection:
    """ç¬¬4å±‚ï¼šå¸§åºåˆ—æ”¶é›†ï¼ˆé€šç”¨ï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å¸§æ”¶é›†å±‚
        
        Args:
            config: å¸§æ”¶é›†é…ç½®ï¼ŒåŒ…å«max_frames, default_sample_rateç­‰
        """
        self.max_frames = config.get("max_frames", 50)
        self.default_sample_rate = config.get("default_sample_rate", 2.0)
        self.adaptive = config.get("adaptive", True)
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ”¶é›†å¸§"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 4] å¸§åºåˆ—æ”¶é›† - å¼€å§‹")
        
        try:
            current_buffer = state.get("frame_buffer", [])
            frame = state["frame"]
            logger.info(f"ğŸ“¦ å½“å‰ç¼“å†²åŒº: {len(current_buffer)}å¸§")
            logger.info(f"âš™ï¸ ç¼“å†²åŒºä¸Šé™: {self.max_frames}å¸§")
            logger.info(f"ğŸ“· é‡‡æ ·ç‡: {self.default_sample_rate} fps")
            
            # æ·»åŠ å¸§åˆ°ç¼“å†²åŒº
            new_buffer = current_buffer + [frame.copy()]
            buffer_full = len(new_buffer) >= self.max_frames
            
            elapsed = time.time() - start_time
            
            logger.info(f"âœ… å¸§å·²æ·»åŠ : {len(new_buffer)}/{self.max_frames}")
            logger.info(f"ğŸ“Š è¿›åº¦: {len(new_buffer)/self.max_frames*100:.1f}%")
            
            if buffer_full:
                logger.info(f"ğŸ¯ ç¼“å†²åŒºå·²æ»¡ï¼Œå‡†å¤‡æ—¶åºåˆ†æ")
                logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: temporal_analysis")
                logger.info(f"â±ï¸ Layer 4 è€—æ—¶: {elapsed:.3f}ç§’")
                logger.info("âœ… [Layer 4] å¸§åºåˆ—æ”¶é›† - å®Œæˆ")
                logger.info("="*60 + "\n")
                
                return {
                    "frame_buffer": new_buffer,
                    "buffer_full": True,
                    "next_action": "temporal_analysis"
                }
            else:
                logger.info(f"â³ ç¼“å†²åŒºæœªæ»¡ï¼Œç»§ç»­æ”¶é›†")
                logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: collect_more")
                logger.info(f"â±ï¸ Layer 4 è€—æ—¶: {elapsed:.3f}ç§’")
                logger.info("âœ… [Layer 4] å¸§åºåˆ—æ”¶é›† - ç»§ç»­")
                logger.info("="*60 + "\n")
                
                return {
                    "frame_buffer": new_buffer,
                    "buffer_full": False,
                    "next_action": "collect_more"  # éœ€è¦ç»§ç»­æ”¶é›†
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 4] å¸§æ”¶é›†å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 4 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "next_action": "skip"
            }


class Layer5TemporalAnalysis:
    """ç¬¬5å±‚ï¼šæ—¶åºåŠ¨ä½œåˆ†æï¼ˆé€šç”¨å¤šæ¨¡æ€LLMï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ—¶åºåˆ†æå±‚
        
        Args:
            config: æ—¶åºåˆ†æé…ç½®ï¼ŒåŒ…å«model_name, max_key_frames, system_prompt, user_prompt_templateç­‰
        """
        self.model_name = config.get("model_name", "multimodal_llm")
        self.max_key_frames = config.get("max_key_frames", 10)
        self.system_prompt = config.get("system_prompt", "ä½ æ˜¯æ—¶åºåˆ†æä¸“å®¶ã€‚")
        self.user_prompt_template = config.get("user_prompt_template", "è¯·åˆ†æè§†é¢‘åºåˆ—ã€‚")
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œæ—¶åºåˆ†æ"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 5] æ—¶åºåŠ¨ä½œåˆ†æ - å¼€å§‹")
        
        try:
            frames = state["frame_buffer"]
            checklist = state.get("checklist", [])
            batch_history = state.get("batch_analyses", [])
            current_batch = state.get("current_batch", 0) + 1
            
            logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}")
            logger.info(f"ğŸ¤– åˆ†ææ¨¡å‹: {self.model_name}")
            logger.info(f"ğŸ“¦ å¸§ç¼“å†²åŒº: {len(frames)}å¸§")
            logger.info(f"ğŸ“‹ æ‰¹æ¬¡ç¼–å·: {current_batch}")
            logger.info(f"ğŸ“ æ£€æŸ¥æ¸…å•: {len(checklist)}é¡¹")
            logger.info(f"ğŸ“š å†å²æ‰¹æ¬¡: {len(batch_history)}æ¬¡")
            
            # é€‰æ‹©å…³é”®å¸§
            key_frames = self._select_key_frames(frames, max_frames=self.max_key_frames)
            logger.info(f"ğŸ”‘ å…³é”®å¸§é€‰æ‹©: {len(key_frames)}/{len(frames)}å¸§")
            
            # æ„å»ºä¸Šä¸‹æ–‡
            previous_context = ""
            if batch_history:
                previous_context = "ã€ä¹‹å‰æ‰¹æ¬¡ã€‘\n" + "\n".join(
                    [f"æ‰¹æ¬¡{b.get('batch_id')}: {b.get('summary', '')}" 
                     for b in batch_history[-2:]]
                )
                logger.debug(f"ğŸ“– ä¸Šä¸‹æ–‡: å¼•ç”¨å‰{min(len(batch_history), 2)}ä¸ªæ‰¹æ¬¡")
            
            # æ„å»ºæ£€æŸ¥æ¸…å•æ–‡æœ¬
            checklist_text = "ã€æ£€æŸ¥æ¸…å•ã€‘\n" + "\n".join(
                [f"{i+1}. {item['item']}" for i, item in enumerate(checklist)]
            ) if checklist else ""
            
            # ä½¿ç”¨é…ç½®çš„æç¤ºè¯æ¨¡æ¿
            system_prompt = self.system_prompt
            user_prompt = self.user_prompt_template.format(
                frame_count=len(key_frames),
                previous_context=previous_context,
                checklist_text=checklist_text
            )
            logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(user_prompt)} å­—ç¬¦")
            
            # è°ƒç”¨å¤šæ¨¡æ€LLMï¼ˆä¼ é€’å®Œæ•´å¸§åºåˆ—ï¼‰
            try:
                from app.services.llm_service import llm_service
                
                # ä¼ é€’æ‰€æœ‰å…³é”®å¸§ç»™å¤šæ¨¡æ€LLMè¿›è¡Œæ—¶åºåˆ†æ
                logger.debug(f"ğŸ”„ å¼€å§‹è°ƒç”¨æ—¶åºåˆ†æLLMï¼ˆä¼ é€’{len(key_frames)}å¸§ï¼‰...")
                
                result = llm_service.call_llm(
                    system_prompt=system_prompt,
                    prompt=user_prompt,
                    video_frames=key_frames,  # âœ… ä¼ é€’å®Œæ•´å¸§åºåˆ—
                    fps=2.0,  # å…³é”®å¸§æå–åçš„å¸§ç‡ï¼ˆå¯é…ç½®ï¼‰
                    response_format={"type": "json_object"},
                    use_video_format=True  # ä½¿ç”¨OpenAIè§†é¢‘æ ¼å¼
                )
                
                if result.success and result.analysis_result:
                    analysis_result = result.analysis_result
                    analysis_result["batch_id"] = current_batch
                    # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
                    if "task_completed" not in analysis_result:
                        analysis_result["task_completed"] = current_batch >= 10
                    if "completion_rate" not in analysis_result:
                        analysis_result["completion_rate"] = min(current_batch * 10, 100)
                    if "current_stage" not in analysis_result:
                        analysis_result["current_stage"] = f"é˜¶æ®µ{current_batch}"
                    
                    logger.info(f"âœ… LLMæ—¶åºåˆ†ææˆåŠŸ")
                    logger.info(f"ğŸ“Š åˆ†æç»“æœ: {analysis_result.get('batch_summary', 'N/A')[:60]}...")
                else:
                    logger.warning(f"âš ï¸ LLMåˆ†æå¤±è´¥: {result.error_message}")
                    # é™çº§å¤„ç†
                    analysis_result = {
                        "batch_id": current_batch,
                        "batch_summary": f"æ‰¹æ¬¡{current_batch}åˆ†æï¼ˆé™çº§ï¼‰",
                        "checklist_results": {},
                        "current_stage": f"é˜¶æ®µ{current_batch}",
                        "completion_rate": min(current_batch * 10, 100),
                        "task_completed": current_batch >= 10,
                        "key_findings": []
                    }
                    
            except Exception as e:
                logger.warning(f"âš ï¸ LLMæœåŠ¡è°ƒç”¨å¼‚å¸¸: {str(e)}")
                # é™çº§å¤„ç†
                analysis_result = {
                    "batch_id": current_batch,
                    "batch_summary": f"æ‰¹æ¬¡{current_batch}åˆ†æå¼‚å¸¸",
                    "checklist_results": {},
                    "current_stage": f"é˜¶æ®µ{current_batch}",
                    "completion_rate": min(current_batch * 10, 100),
                    "task_completed": current_batch >= 10,
                    "key_findings": [],
                    "error": str(e)[:50]
                }
            
            # æ›´æ–°çŠ¶æ€
            task_completed = analysis_result["task_completed"]
            next_action = "final_reasoning" if task_completed else "collect_more"
            
            elapsed = time.time() - start_time
            
            logger.info(f"ğŸ“‹ æ‰¹æ¬¡ç¼–å·: {current_batch}")
            logger.info(f"ğŸ“Š å®Œæˆåº¦: {analysis_result['completion_rate']}%")
            logger.info(f"ğŸ·ï¸ å½“å‰é˜¶æ®µ: {analysis_result['current_stage']}")
            logger.info(f"ğŸ¯ ä»»åŠ¡å®Œæˆ: {task_completed}")
            logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: {next_action}")
            logger.info(f"â±ï¸ Layer 5 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 5] æ—¶åºåŠ¨ä½œåˆ†æ - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "batch_analyses": [analysis_result],  # ä¼šè¢«add reducerç´¯ç§¯
                "task_completed": task_completed,
                "current_stage": analysis_result["current_stage"],
                "current_batch": current_batch,
                "frame_buffer": [],  # æ¸…ç©ºç¼“å†²åŒº
                "buffer_full": False,
                "next_action": next_action
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 5] æ—¶åºåˆ†æå¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 5 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "next_action": "skip"
            }
    
    def _select_key_frames(self, frames: List[np.ndarray], max_frames: int = 10):
        """é€‰æ‹©å…³é”®å¸§"""
        if len(frames) <= max_frames:
            return frames
        indices = np.linspace(0, len(frames) - 1, max_frames, dtype=int)
        return [frames[i] for i in indices]
    
    def _encode_frame(self, frame: np.ndarray) -> str:
        """ç¼–ç å¸§"""
        _, buffer = cv2.imencode('.jpg', frame)
        return base64.b64encode(buffer).decode('utf-8')


class Layer6FinalReasoning:
    """ç¬¬6å±‚ï¼šç»¼åˆæ¨ç†ä¸å†³ç­–ï¼ˆé€šç”¨æ€è€ƒLLMï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–ç»¼åˆæ¨ç†å±‚
        
        Args:
            config: æ¨ç†é…ç½®ï¼ŒåŒ…å«model_name, system_prompt, user_prompt_templateç­‰
        """
        self.model_name = config.get("model_name", "reasoning_llm")
        self.system_prompt = config.get("system_prompt", "ä½ æ˜¯ç»¼åˆæ¨ç†å¼•æ“ã€‚")
        self.user_prompt_template = config.get("user_prompt_template", "{analysis_content}")
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œç»¼åˆæ¨ç†"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 6] ç»¼åˆæ¨ç†ä¸å†³ç­– - å¼€å§‹")
        logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}")
        logger.info(f"ğŸ¤– æ¨ç†æ¨¡å‹: {self.model_name}")
        
        try:
            decision_type = state["decision_type"]
            logger.info(f"ğŸ¯ å†³ç­–ç±»å‹: {decision_type}")
            
            if decision_type == "B1":
                # å•å¸§åˆ¤æ–­
                analysis_content = f"ã€å•å¸§åˆ†æã€‘\n{state['scene_description']}"
                logger.info(f"ğŸ“„ ä½¿ç”¨å•å¸§åœºæ™¯æè¿°è¿›è¡Œæ¨ç†")
            else:  # B2
                # æ—¶åºåˆ†æ
                batch_history = state.get("batch_analyses", [])
                analysis_content = "ã€æ—¶åºåˆ†æã€‘\n" + "\n".join(
                    [f"æ‰¹æ¬¡{b.get('batch_id')}: {b.get('batch_summary', '')}" 
                     for b in batch_history]
                )
                logger.info(f"ğŸ“š ä½¿ç”¨æ—¶åºåˆ†æç»“æœè¿›è¡Œæ¨ç† ({len(batch_history)}æ‰¹æ¬¡)")
            
            # ä½¿ç”¨é…ç½®çš„æç¤ºè¯æ¨¡æ¿
            system_prompt = self.system_prompt
            user_prompt = self.user_prompt_template.format(
                analysis_content=analysis_content
            )
            logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(user_prompt)} å­—ç¬¦")
            
            # è°ƒç”¨æ€è€ƒLLM
            try:
                from app.services.llm_service import llm_service
                logger.debug(f"ğŸ”„ å¼€å§‹è°ƒç”¨æ¨ç†LLM...")
                
                result = llm_service.call_llm(
                    system_prompt=system_prompt,
                    prompt=user_prompt,
                    response_format={"type": "json_object"},
                    skill_type=self.model_name
                )
                
                if result.success and result.analysis_result:
                    reasoning_data = result.analysis_result
                    violation_detected = reasoning_data.get("violation_detected", False)
                    violation_type = reasoning_data.get("violation_type", "æœªçŸ¥è¿è§„")
                    severity_level = reasoning_data.get("severity_level", 1)
                    disposal_plan = reasoning_data.get("disposal_plan", {
                        "voice_broadcast": "è¯·æ³¨æ„å®‰å…¨",
                        "record_violation": False,
                        "penalty_amount": 0,
                        "safety_education": ""
                    })
                    logger.info(f"âœ… LLMæ¨ç†æˆåŠŸ")
                    logger.info(f"ğŸ“Š æ¨ç†ç»“æœ: {reasoning_data}")
                else:
                    logger.warning(f"âš ï¸ LLMæ¨ç†å¤±è´¥: {result.error_message}")
                    # é™çº§ï¼šä¿å®ˆåˆ¤æ–­
                    violation_detected = False
                    violation_type = "æ¨ç†å¤±è´¥"
                    severity_level = 0
                    disposal_plan = {}
                    
            except Exception as e:
                logger.warning(f"âš ï¸ LLMæœåŠ¡è°ƒç”¨å¼‚å¸¸: {str(e)}")
                # é™çº§å¤„ç†ï¼šä¿å®ˆåˆ¤æ–­
                violation_detected = False
                violation_type = f"æ¨ç†å¼‚å¸¸: {str(e)[:30]}"
                severity_level = 0
                disposal_plan = {}
            
            elapsed = time.time() - start_time
            next_action = "disposal" if violation_detected else "end"
            
            logger.info(f"ğŸ¯ è¿è§„æ£€æµ‹: {violation_detected}")
            if violation_detected:
                logger.info(f"âš ï¸ è¿è§„ç±»å‹: {violation_type}")
                logger.info(f"ğŸ”´ ä¸¥é‡ç­‰çº§: {severity_level}")
                logger.info(f"ğŸ“‹ å¤„ç½®æ–¹æ¡ˆ: {disposal_plan.get('voice_broadcast', 'N/A')[:40]}...")
            logger.info(f"â¡ï¸ ä¸‹ä¸€æ­¥: {next_action}")
            logger.info(f"â±ï¸ Layer 6 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 6] ç»¼åˆæ¨ç†ä¸å†³ç­– - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "violation_detected": violation_detected,
                "violation_type": violation_type,
                "severity_level": severity_level,
                "disposal_plan": disposal_plan,
                "next_action": next_action
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 6] ç»¼åˆæ¨ç†å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 6 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "violation_detected": False,
                "next_action": "end"
            }


class Layer7AutoDisposal:
    """ç¬¬7å±‚ï¼šè‡ªåŠ¨å¤„ç½®æ‰§è¡Œ"""
    
    def __init__(self, disposal_executor=None):
        self.disposal_executor = disposal_executor
        
    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œè‡ªåŠ¨å¤„ç½®"""
        import time
        start_time = time.time()
        
        logger.info("="*60)
        logger.info("ğŸš€ [Layer 7] è‡ªåŠ¨å¤„ç½®æ‰§è¡Œ - å¼€å§‹")
        logger.info(f"ğŸ“· ä»»åŠ¡ID: {state.get('task_id')}")
        logger.info(f"âš ï¸ è¿è§„ç±»å‹: {state.get('violation_type')}")
        logger.info(f"ğŸ”´ ä¸¥é‡ç­‰çº§: {state.get('severity_level')}")
        
        try:
            disposal_plan = state["disposal_plan"]
            task_id = state["task_id"]
            
            logger.info(f"ğŸ“‹ å¤„ç½®è®¡åˆ’:")
            logger.info(f"   ğŸ”Š è¯­éŸ³å¹¿æ’­: {disposal_plan.get('voice_broadcast', 'N/A')}")
            logger.info(f"   ğŸ“ è®°å½•è¿è§„: {disposal_plan.get('record_violation', False)}")
            logger.info(f"   ğŸ’° ç½šæ¬¾é‡‘é¢: Â¥{disposal_plan.get('penalty_amount', 0)}")
            logger.info(f"   ğŸ“š å®‰å…¨æ•™è‚²: {disposal_plan.get('safety_education', 'N/A')}")
            
            if not self.disposal_executor:
                logger.warning("âš ï¸ å¤„ç½®æ‰§è¡Œå™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ‰§è¡Œ")
                elapsed = time.time() - start_time
                logger.info(f"â±ï¸ Layer 7 è€—æ—¶: {elapsed:.3f}ç§’")
                logger.info("âš ï¸ [Layer 7] è‡ªåŠ¨å¤„ç½®æ‰§è¡Œ - è·³è¿‡")
                logger.info("="*60 + "\n")
                return {
                    "disposal_result": {"success": False, "error": "æœªåˆå§‹åŒ–"},
                    "next_action": "end"
                }
            
            # æ‰§è¡Œå¤„ç½®
            logger.debug(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå¤„ç½®åŠ¨ä½œ...")
            result = self.disposal_executor.execute_disposal(
                violation_info={
                    "violation_type": state["violation_type"],
                    "severity_level": state["severity_level"],
                    "disposal_plan": disposal_plan
                },
                task_id=task_id,
                task_config=state["task_config"]
            )
            
            elapsed = time.time() - start_time
            executed_actions = result.get('executed_actions', [])
            
            logger.info(f"âœ… å¤„ç½®æ‰§è¡Œå®Œæˆ")
            logger.info(f"ğŸ“Š å·²æ‰§è¡ŒåŠ¨ä½œ: {executed_actions}")
            logger.info(f"ğŸ“ˆ æ‰§è¡Œç»“æœ: {result.get('success', False)}")
            if not result.get('success'):
                logger.warning(f"âš ï¸ æ‰§è¡Œé”™è¯¯: {result.get('error', 'N/A')}")
            
            logger.info(f"â±ï¸ Layer 7 è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("âœ… [Layer 7] è‡ªåŠ¨å¤„ç½®æ‰§è¡Œ - å®Œæˆ")
            logger.info("="*60 + "\n")
            
            return {
                "disposal_result": result,
                "next_action": "end"
            }
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ [Layer 7] è‡ªåŠ¨å¤„ç½®å¤±è´¥: {str(e)}")
            logger.error(f"â±ï¸ Layer 7 å¤±è´¥è€—æ—¶: {elapsed:.3f}ç§’")
            logger.info("="*60 + "\n")
            return {
                "disposal_result": {"success": False, "error": str(e)},
                "next_action": "end"
            }


# ==================== æ¡ä»¶è¾¹ï¼ˆå†³ç­–åˆ†æ”¯ï¼‰====================

def should_skip(state: AgentState) -> str:
    """åˆ¤æ–­æ˜¯å¦è·³è¿‡åç»­å¤„ç†"""
    if not state.get("has_target"):
        return "skip"
    return "scene_understanding"


def decision_router(state: AgentState) -> str:
    """æ ¹æ®å†³ç­–ç±»å‹è·¯ç”±"""
    decision = state.get("decision_type", "A")
    if decision == "A":
        return "skip"
    elif decision == "B1":
        return "final_reasoning"
    else:  # B2
        return "frame_collection"


def collection_router(state: AgentState) -> str:
    """å¸§æ”¶é›†è·¯ç”±"""
    if state.get("buffer_full"):
        return "temporal_analysis"
    else:
        return "collect_more"  # éœ€è¦ç»§ç»­æ”¶é›†


def temporal_router(state: AgentState) -> str:
    """æ—¶åºåˆ†æè·¯ç”±"""
    if state.get("task_completed"):
        return "final_reasoning"
    else:
        return "frame_collection"  # ç»§ç»­æ”¶é›†ä¸‹ä¸€æ‰¹æ¬¡


def disposal_router(state: AgentState) -> str:
    """å¤„ç½®è·¯ç”±"""
    if state.get("violation_detected"):
        return "disposal"
    else:
        return END


# ==================== æ„å»ºLangGraph ====================

class AgentOrchestratorLangGraph:
    """
    åŸºäºLangGraphçš„æ™ºèƒ½ä»£ç†ç¼–æ’å™¨ï¼ˆé€šç”¨ï¼‰
    
    ä½¿ç”¨LangGraphçš„StateGraphæ„å»ºå®Œæ•´çš„7å±‚å·¥ä½œæµ
    ç¼–æ’å™¨æœ¬èº«ä¿æŒé€šç”¨ï¼Œæ‰€æœ‰å…·ä½“é…ç½®ç”±æŠ€èƒ½æä¾›
    """
    
    def __init__(self, config: Dict[str, Any], knowledge_base=None, disposal_executor=None, skill=None):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            config: é…ç½®å­—å…¸
            knowledge_base: çŸ¥è¯†åº“æœåŠ¡
            disposal_executor: å¤„ç½®æ‰§è¡Œå™¨
            skill: æŠ€èƒ½å®ä¾‹ï¼ˆæä¾›å±‚çº§é…ç½®ï¼‰
        """
        self.config = config
        self.knowledge_base = knowledge_base
        self.disposal_executor = disposal_executor
        self.skill = skill
        
        # æ„å»ºå·¥ä½œæµå›¾
        self.graph = self._build_graph()
        
        logger.info("LangGraphå·¥ä½œæµç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        
        # åˆ›å»ºStateGraph
        workflow = StateGraph(AgentState)
        
        # ä»æŠ€èƒ½è·å–å„å±‚é…ç½®
        if self.skill:
            yolo_config = self.skill.get_yolo_config() if hasattr(self.skill, 'get_yolo_config') else {}
            scene_config = self.skill.get_scene_understanding_config() if hasattr(self.skill, 'get_scene_understanding_config') else {}
            decision_config = self.skill.get_decision_config() if hasattr(self.skill, 'get_decision_config') else {}
            frame_config = self.skill.get_frame_collection_config() if hasattr(self.skill, 'get_frame_collection_config') else {}
            temporal_config = self.skill.get_temporal_analysis_config() if hasattr(self.skill, 'get_temporal_analysis_config') else {}
            reasoning_config = self.skill.get_final_reasoning_config() if hasattr(self.skill, 'get_final_reasoning_config') else {}
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            yolo_config = {}
            scene_config = {}
            decision_config = {}
            frame_config = {}
            temporal_config = {}
            reasoning_config = {}
        
        # æ·»åŠ èŠ‚ç‚¹ï¼ˆæ¯ä¸€å±‚ï¼‰
        workflow.add_node("yolo_detection", Layer1YOLODetection(yolo_config))
        workflow.add_node("scene_understanding", Layer2SceneUnderstanding(scene_config))
        workflow.add_node("decision_engine", Layer3DecisionEngine(
            config=decision_config,
            knowledge_base=self.knowledge_base,
            skill=self.skill
        ))
        workflow.add_node("frame_collection", Layer4FrameCollection(frame_config))
        workflow.add_node("temporal_analysis", Layer5TemporalAnalysis(temporal_config))
        workflow.add_node("final_reasoning", Layer6FinalReasoning(reasoning_config))
        workflow.add_node("disposal", Layer7AutoDisposal(
            disposal_executor=self.disposal_executor
        ))
        
        # æ·»åŠ è¾¹ï¼ˆå·¥ä½œæµï¼‰
        workflow.add_edge(START, "yolo_detection")
        workflow.add_conditional_edges(
            "yolo_detection",
            should_skip,
            {
                "skip": END,
                "scene_understanding": "scene_understanding"
            }
        )
        workflow.add_edge("scene_understanding", "decision_engine")
        workflow.add_conditional_edges(
            "decision_engine",
            decision_router,
            {
                "skip": END,
                "final_reasoning": "final_reasoning",
                "frame_collection": "frame_collection"
            }
        )
        workflow.add_conditional_edges(
            "frame_collection",
            collection_router,
            {
                "temporal_analysis": "temporal_analysis",
                "collect_more": END  # é€€å‡ºï¼Œç­‰å¾…ä¸‹ä¸€å¸§
            }
        )
        workflow.add_conditional_edges(
            "temporal_analysis",
            temporal_router,
            {
                "final_reasoning": "final_reasoning",
                "frame_collection": "frame_collection"
            }
        )
        workflow.add_conditional_edges(
            "final_reasoning",
            disposal_router,
            {
                "disposal": "disposal",
                END: END
            }
        )
        workflow.add_edge("disposal", END)
        
        # ç¼–è¯‘å›¾ï¼ˆå¯ä»¥æ·»åŠ checkpointerç”¨äºæŒä¹…åŒ–ï¼‰
        # memory = MemorySaver()  # å†…å­˜checkpointer
        # graph = workflow.compile(checkpointer=memory)
        graph = workflow.compile()
        
        return graph
    
    def execute_workflow(self, frame: np.ndarray, task_id: int, camera_id: int,
                        task_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥ä½œæµ
        
        Args:
            frame: å½“å‰å¸§
            task_id: ä»»åŠ¡ID
            camera_id: æ‘„åƒå¤´ID
            task_config: ä»»åŠ¡é…ç½®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # åˆå§‹åŒ–çŠ¶æ€
            initial_state = {
                "frame": frame,
                "task_id": task_id,
                "camera_id": camera_id,
                "task_config": task_config,
                "has_target": False,
                "buffer_full": False,
                "task_completed": False,
                "violation_detected": False,
                "severity_level": 0,
                "current_batch": 0,
                "frame_buffer": [],
                "batch_analyses": [],
                "messages": []
            }
            
            # æ‰§è¡Œå›¾
            result = self.graph.invoke(initial_state)
            
            # æå–å…³é”®ç»“æœ
            output = {
                "success": True,
                "decision_type": result.get("decision_type"),
                "violation_detected": result.get("violation_detected", False),
                "violation_type": result.get("violation_type"),
                "severity_level": result.get("severity_level", 0),
                "disposal_result": result.get("disposal_result"),
                "task_completed": result.get("task_completed", False)
            }
            
            logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {output}")
            
            return output
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_graph_visualization(self) -> str:
        """
        è·å–å›¾çš„å¯è§†åŒ–ï¼ˆMermaidæ ¼å¼ï¼‰
        
        Returns:
            Mermaidå›¾å®šä¹‰
        """
        try:
            # LangGraphæä¾›äº†å›¾å¯è§†åŒ–åŠŸèƒ½
            return self.graph.get_graph().draw_mermaid()
        except Exception as e:
            logger.error(f"å›¾å¯è§†åŒ–å¤±è´¥: {str(e)}")
            return ""

