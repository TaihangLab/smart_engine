#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ğŸ¯ å®‰é˜²é¢„è­¦å®æ—¶é€šçŸ¥ç³»ç»Ÿ - è¡¥å¿æœºåˆ¶APIæ¥å£
================================================
ä¼ä¸šçº§è¡¥å¿æœºåˆ¶ç®¡ç†æ¥å£ï¼Œæä¾›ï¼š

1. ğŸ“Š è¡¥å¿ç»Ÿè®¡åˆ†æï¼šæ€§èƒ½æŒ‡æ ‡ã€æˆåŠŸç‡ã€é”™è¯¯åˆ†æ
2. ğŸš¨ å¥åº·çŠ¶æ€ç›‘æ§ï¼šå®æ—¶å¥åº·æ£€æŸ¥å’Œå‘Šè­¦
3. ğŸ“ˆ è¡¥å¿å†å²æŸ¥è¯¢ï¼šè¯¦ç»†çš„è¡¥å¿æ‰§è¡Œè®°å½•
4. âš™ï¸  é…ç½®ç®¡ç†ï¼šåŠ¨æ€é…ç½®è°ƒæ•´å’Œä¼˜åŒ–å»ºè®®

APIè®¾è®¡ç‰¹ç‚¹ï¼š
- RESTfulé£æ ¼ï¼šæ ‡å‡†HTTPæ–¹æ³•å’ŒçŠ¶æ€ç 
- å®æ—¶ç›‘æ§ï¼šWebSocketå’ŒSSEæ”¯æŒ
- å®‰å…¨è®¤è¯ï¼šAPIå¯†é’¥å’Œæƒé™æ§åˆ¶
- å®Œæ•´æ–‡æ¡£ï¼šOpenAPIè§„èŒƒå’Œç¤ºä¾‹
- æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜å’Œåˆ†é¡µæ”¯æŒ

è¡¥å¿æ‰§è¡Œç‰¹æ€§ï¼š
- é›¶é…ç½®è‡ªåŠ¨è¿è¡Œï¼šç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å¼€å§‹è¡¥å¿
- å¹¶è¡Œæ‰§è¡Œæ¨¡å¼ï¼šä¸‰å±‚è¡¥å¿ï¼ˆç”Ÿäº§ç«¯/æ¶ˆè´¹ç«¯/é€šçŸ¥ç«¯ï¼‰å¹¶è¡Œå¤„ç†
- çŠ¶æ€é©±åŠ¨ï¼šåŸºäºçŠ¶æ€æœºçš„æ™ºèƒ½è¡¥å¿æµç¨‹
- æ— æ‰‹åŠ¨å¹²é¢„ï¼šå®Œå…¨è‡ªåŠ¨åŒ–ï¼Œä¸æä¾›æ‰‹åŠ¨è§¦å‘åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, Query, Path, BackgroundTasks
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import Dict, Any, List, Optional, Union
from datetime import datetime, timedelta
import json
import asyncio
from pydantic import BaseModel, Field

from app.db.session import get_db
from app.core.config import settings
from app.models.compensation import (
    AlertPublishLog, AlertNotificationLog, CompensationTaskLog,
    PublishStatus, NotificationStatus, CompensationTaskType,
    CompensationStats
)
from app.services.unified_compensation_service import (
    unified_compensation_service,
    get_compensation_service_stats,
    get_compensation_health
)
from app.utils.message_id_generator import (
    generate_message_id, parse_message_id, MessageIdUtils,
    benchmark_id_generation, MessageIdType
)

# åˆ›å»ºè·¯ç”±å™¨ "ğŸ’ ä¼ä¸šçº§è¡¥å¿æœºåˆ¶"
router = APIRouter(
    prefix="/compensation",
    responses={
        404: {"description": "èµ„æºæœªæ‰¾åˆ°"},
        500: {"description": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
    }
)


# ================================================================
# ğŸ“ APIæ•°æ®æ¨¡å‹
# ================================================================

class CompensationServiceStatus(BaseModel):
    """è¡¥å¿æœåŠ¡çŠ¶æ€æ¨¡å‹"""
    is_running: bool = Field(..., description="æœåŠ¡æ˜¯å¦è¿è¡Œä¸­")
    is_initialized: bool = Field(..., description="æœåŠ¡æ˜¯å¦å·²åˆå§‹åŒ–")
    uptime_seconds: int = Field(..., description="è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰")
    last_execution: Optional[str] = Field(None, description="æœ€åæ‰§è¡Œæ—¶é—´")
    next_execution: Optional[str] = Field(None, description="ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´")


class CompensationQueryParams(BaseModel):
    """è¡¥å¿æŸ¥è¯¢å‚æ•°æ¨¡å‹"""
    start_time: Optional[datetime] = Field(None, description="å¼€å§‹æ—¶é—´")
    end_time: Optional[datetime] = Field(None, description="ç»“æŸæ—¶é—´")
    status: Optional[str] = Field(None, description="çŠ¶æ€ç­›é€‰")
    limit: int = Field(100, description="é™åˆ¶æ•°é‡")
    offset: int = Field(0, description="åç§»é‡")


# ================================================================
# ğŸ“Š è¡¥å¿æœåŠ¡çŠ¶æ€æŸ¥è¯¢æ¥å£
# ================================================================

@router.get("/status", 
           summary="ğŸ“Š è·å–è¡¥å¿æœåŠ¡çŠ¶æ€",
           description="è·å–è¡¥å¿æœåŠ¡çš„å®Œæ•´è¿è¡ŒçŠ¶æ€ï¼ŒåŒ…æ‹¬æ€§èƒ½æŒ‡æ ‡å’Œç»Ÿè®¡ä¿¡æ¯",
           response_model=Dict[str, Any])
async def get_compensation_status():
    """
    è·å–è¡¥å¿æœåŠ¡çŠ¶æ€
    
    è¿”å›å®Œæ•´çš„æœåŠ¡çŠ¶æ€ä¿¡æ¯ï¼š
    - æœåŠ¡è¿è¡ŒçŠ¶æ€
    - æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
    - é…ç½®å‚æ•°
    - æ€§èƒ½æŒ‡æ ‡
    """
    try:
        stats = get_compensation_service_stats()
        return {
            "status": "success",
            "data": stats,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¡¥å¿æœåŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/config",
           summary="âš™ï¸ è·å–è¡¥å¿é…ç½®ä¿¡æ¯",
           description="è·å–å½“å‰è¡¥å¿æœºåˆ¶çš„é…ç½®å‚æ•°",
           response_model=Dict[str, Any])
async def get_compensation_config():
    """
    è·å–è¡¥å¿é…ç½®ä¿¡æ¯
    
    è¿”å›å½“å‰çš„é…ç½®å‚æ•°ï¼š
    - è¡¥å¿é—´éš”è®¾ç½®
    - æ‰¹å¤„ç†å¤§å°
    - é‡è¯•æ¬¡æ•°
    - è‡ªåŠ¨è¡¥å¿å¼€å…³
    """
    try:
        config = {
            "producer_compensation": {
                "enabled": settings.PRODUCER_COMPENSATION_ENABLE,
                "interval_seconds": settings.COMPENSATION_PRODUCER_INTERVAL,
                "batch_size": settings.COMPENSATION_PRODUCER_BATCH_SIZE,
                "max_retries": settings.COMPENSATION_PRODUCER_MAX_RETRIES,
                "retry_backoff_seconds": settings.COMPENSATION_PRODUCER_RETRY_BACKOFF
            },
            "consumer_compensation": {
                "enabled": settings.CONSUMER_COMPENSATION_ENABLE,
                "interval_seconds": settings.COMPENSATION_CONSUMER_INTERVAL,
                "batch_size": settings.COMPENSATION_CONSUMER_BATCH_SIZE,
                "max_retries": settings.COMPENSATION_CONSUMER_MAX_RETRIES,
                "retry_backoff_seconds": settings.COMPENSATION_CONSUMER_RETRY_BACKOFF
            },
            "notification_compensation": {
                "enabled": settings.SSE_COMPENSATION_ENABLE,
                "interval_seconds": settings.COMPENSATION_NOTIFICATION_INTERVAL,
                "batch_size": settings.COMPENSATION_NOTIFICATION_BATCH_SIZE,
                "max_retries": settings.COMPENSATION_NOTIFICATION_MAX_RETRIES,
                "retry_backoff_seconds": settings.COMPENSATION_NOTIFICATION_RETRY_BACKOFF,
                "fallback_enabled": settings.NOTIFICATION_FALLBACK_ENABLE
            },
            "general": {
                "auto_start_enabled": settings.COMPENSATION_AUTO_START,
                "parallel_processing": True,
                "health_check_interval": settings.HEALTH_CHECK_INTERVAL,
                "data_retention_days": 7,
                "enable_monitoring": settings.COMPENSATION_MONITORING
            }
        }
        
        return {
            "status": "success",
            "data": config,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¡¥å¿é…ç½®å¤±è´¥: {str(e)}")


# ================================================================
# ğŸ“ˆ è¡¥å¿ç»Ÿè®¡åˆ†ææ¥å£
# ================================================================

@router.get("/stats",
           summary="ğŸ“ˆ è·å–è¡¥å¿ç»Ÿè®¡ä¿¡æ¯",
           description="è·å–è¯¦ç»†çš„è¡¥å¿ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬æˆåŠŸç‡ã€æ€§èƒ½æŒ‡æ ‡ç­‰",
           response_model=Dict[str, Any])
async def get_compensation_statistics(
    days: int = Query(7, description="ç»Ÿè®¡å¤©æ•°", ge=1, le=30),
    db: Session = Depends(get_db)
):
    """
    è·å–è¡¥å¿ç»Ÿè®¡ä¿¡æ¯
    
    æä¾›è¯¦ç»†çš„ç»Ÿè®¡åˆ†æï¼š
    - ç”Ÿäº§ç«¯è¡¥å¿ç»Ÿè®¡
    - æ¶ˆè´¹ç«¯è¡¥å¿ç»Ÿè®¡  
    - é€šçŸ¥ç«¯è¡¥å¿ç»Ÿè®¡
    - æ•´ä½“æˆåŠŸç‡å’Œæ€§èƒ½æŒ‡æ ‡
    """
    try:
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)
        
        # æŸ¥è¯¢å„ç±»æ—¥å¿—
        publish_logs = db.query(AlertPublishLog).filter(
            AlertPublishLog.created_at >= start_time,
            AlertPublishLog.created_at <= end_time
        ).all()
        
        notification_logs = db.query(AlertNotificationLog).filter(
            AlertNotificationLog.created_at >= start_time,
            AlertNotificationLog.created_at <= end_time
        ).all()
        
        task_logs = db.query(CompensationTaskLog).filter(
            CompensationTaskLog.created_at >= start_time,
            CompensationTaskLog.created_at <= end_time
        ).all()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        publish_stats = _calculate_publish_stats(publish_logs)
        notification_stats = _calculate_notification_stats(notification_logs)
        task_stats = _calculate_task_stats(task_logs)
        overall_stats = _calculate_overall_stats(publish_logs, notification_logs, task_logs)
        
        return {
            "status": "success",
            "data": {
                "query_period": {
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "days": days
                },
                "producer_compensation": publish_stats,
                "notification_compensation": notification_stats,
                "task_execution": task_stats,
                "overall_performance": overall_stats
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¡¥å¿ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


# ================================================================
# ğŸš¨ å¥åº·çŠ¶æ€ç›‘æ§æ¥å£
# ================================================================

@router.get("/health",
           summary="ğŸš¨ è·å–è¡¥å¿å¥åº·çŠ¶æ€",
           description="è·å–è¡¥å¿æœåŠ¡çš„å¥åº·çŠ¶æ€å’Œè¯Šæ–­ä¿¡æ¯",
           response_model=Dict[str, Any])
async def get_compensation_health_status():
    """
    è·å–è¡¥å¿å¥åº·çŠ¶æ€
    
    æä¾›å…¨é¢çš„å¥åº·æ£€æŸ¥ï¼š
    - æœåŠ¡è¿è¡ŒçŠ¶æ€
    - ä¾èµ–æœåŠ¡çŠ¶æ€
    - æ€§èƒ½æŒ‡æ ‡
    - å¼‚å¸¸è¯Šæ–­
    """
    try:
        health = get_compensation_health()
        return {
            "status": "success",
            "data": health,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¡¥å¿å¥åº·çŠ¶æ€å¤±è´¥: {str(e)}")


# ================================================================
# ğŸ“‹ è¡¥å¿æ—¥å¿—æŸ¥è¯¢æ¥å£
# ================================================================

@router.get("/logs/publish",
           summary="ğŸ“‹ æŸ¥è¯¢å‘å¸ƒæ—¥å¿—",
           description="æŸ¥è¯¢é¢„è­¦æ¶ˆæ¯å‘å¸ƒæ—¥å¿—ï¼Œæ”¯æŒç­›é€‰å’Œåˆ†é¡µ",
           response_model=Dict[str, Any])
async def get_publish_logs(
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    start_time: Optional[datetime] = Query(None, description="å¼€å§‹æ—¶é—´"),
    end_time: Optional[datetime] = Query(None, description="ç»“æŸæ—¶é—´"),
    limit: int = Query(100, description="é™åˆ¶æ•°é‡", ge=1, le=1000),
    offset: int = Query(0, description="åç§»é‡", ge=0),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢é¢„è­¦æ¶ˆæ¯å‘å¸ƒæ—¥å¿—"""
    try:
        query = db.query(AlertPublishLog)
        
        # çŠ¶æ€ç­›é€‰
        if status:
            query = query.filter(AlertPublishLog.publish_status == status)
        
        # æ—¶é—´èŒƒå›´ç­›é€‰
        if start_time:
            query = query.filter(AlertPublishLog.created_at >= start_time)
        if end_time:
            query = query.filter(AlertPublishLog.created_at <= end_time)
        
        # åˆ†é¡µå’Œæ’åº
        total = query.count()
        logs = query.order_by(AlertPublishLog.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "status": "success",
            "data": {
                "total": total,
                "offset": offset,
                "limit": limit,
                "logs": [_log_to_dict(log) for log in logs]
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å‘å¸ƒæ—¥å¿—å¤±è´¥: {str(e)}")


@router.get("/logs/notification",
           summary="ğŸ“‹ æŸ¥è¯¢é€šçŸ¥æ—¥å¿—",
           description="æŸ¥è¯¢é¢„è­¦é€šçŸ¥æ—¥å¿—ï¼Œæ”¯æŒç­›é€‰å’Œåˆ†é¡µ",
           response_model=Dict[str, Any])
async def get_notification_logs(
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    channel: Optional[str] = Query(None, description="æ¸ é“ç­›é€‰"),
    start_time: Optional[datetime] = Query(None, description="å¼€å§‹æ—¶é—´"),
    end_time: Optional[datetime] = Query(None, description="ç»“æŸæ—¶é—´"),
    limit: int = Query(100, description="é™åˆ¶æ•°é‡", ge=1, le=1000),
    offset: int = Query(0, description="åç§»é‡", ge=0),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢é¢„è­¦é€šçŸ¥æ—¥å¿—"""
    try:
        query = db.query(AlertNotificationLog)
        
        # çŠ¶æ€ç­›é€‰
        if status:
            query = query.filter(AlertNotificationLog.notification_status == status)
        
        # æ¸ é“ç­›é€‰
        if channel:
            query = query.filter(AlertNotificationLog.notification_channel == channel)
        
        # æ—¶é—´èŒƒå›´ç­›é€‰
        if start_time:
            query = query.filter(AlertNotificationLog.created_at >= start_time)
        if end_time:
            query = query.filter(AlertNotificationLog.created_at <= end_time)
        
        # åˆ†é¡µå’Œæ’åº
        total = query.count()
        logs = query.order_by(AlertNotificationLog.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "status": "success",
            "data": {
                "total": total,
                "offset": offset,
                "limit": limit,
                "logs": [_log_to_dict(log) for log in logs]
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢é€šçŸ¥æ—¥å¿—å¤±è´¥: {str(e)}")


@router.get("/logs/task",
           summary="ğŸ“‹ æŸ¥è¯¢ä»»åŠ¡æ—¥å¿—",
           description="æŸ¥è¯¢è¡¥å¿ä»»åŠ¡æ‰§è¡Œæ—¥å¿—ï¼Œæ”¯æŒç­›é€‰å’Œåˆ†é¡µ",
           response_model=Dict[str, Any])
async def get_task_logs(
    task_type: Optional[str] = Query(None, description="ä»»åŠ¡ç±»å‹ç­›é€‰"),
    execution_result: Optional[str] = Query(None, description="æ‰§è¡Œç»“æœç­›é€‰"),
    start_time: Optional[datetime] = Query(None, description="å¼€å§‹æ—¶é—´"),
    end_time: Optional[datetime] = Query(None, description="ç»“æŸæ—¶é—´"),
    limit: int = Query(100, description="é™åˆ¶æ•°é‡", ge=1, le=1000),
    offset: int = Query(0, description="åç§»é‡", ge=0),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢è¡¥å¿ä»»åŠ¡æ‰§è¡Œæ—¥å¿—"""
    try:
        query = db.query(CompensationTaskLog)
        
        # ä»»åŠ¡ç±»å‹ç­›é€‰
        if task_type:
            query = query.filter(CompensationTaskLog.task_type == task_type)
        
        # æ‰§è¡Œç»“æœç­›é€‰
        if execution_result:
            query = query.filter(CompensationTaskLog.execution_result == execution_result)
        
        # æ—¶é—´èŒƒå›´ç­›é€‰
        if start_time:
            query = query.filter(CompensationTaskLog.created_at >= start_time)
        if end_time:
            query = query.filter(CompensationTaskLog.created_at <= end_time)
        
        # åˆ†é¡µå’Œæ’åº
        total = query.count()
        logs = query.order_by(CompensationTaskLog.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "status": "success",
            "data": {
                "total": total,
                "offset": offset,
                "limit": limit,
                "logs": [_log_to_dict(log) for log in logs]
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢ä»»åŠ¡æ—¥å¿—å¤±è´¥: {str(e)}")


# ================================================================
# ğŸ†” æ¶ˆæ¯IDå·¥å…·æ¥å£
# ================================================================

@router.post("/message-id/generate",
            summary="ğŸ†” ç”Ÿæˆæ¶ˆæ¯ID",
            description="ç”Ÿæˆæ–°çš„æ¶ˆæ¯IDï¼Œæ”¯æŒå¤šç§ç”Ÿæˆç­–ç•¥",
            response_model=Dict[str, Any])
async def generate_new_message_id(
    id_type: Optional[str] = Query("snowflake", description="IDç±»å‹"),
    prefix: Optional[str] = Query(None, description="IDå‰ç¼€"),
    count: int = Query(1, description="ç”Ÿæˆæ•°é‡", ge=1, le=100)
):
    """ç”Ÿæˆæ–°çš„æ¶ˆæ¯ID"""
    try:
        id_type_enum = MessageIdType(id_type)
        
        if count == 1:
            message_id = generate_message_id(id_type_enum, prefix)
            return {
                "status": "success",
                "data": {"message_id": message_id},
                "timestamp": datetime.utcnow().isoformat()
            }
        else:
            message_ids = [generate_message_id(id_type_enum, prefix) for _ in range(count)]
            return {
                "status": "success",
                "data": {"message_ids": message_ids, "count": len(message_ids)},
                "timestamp": datetime.utcnow().isoformat()
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆæ¶ˆæ¯IDå¤±è´¥: {str(e)}")


@router.post("/message-id/parse",
            summary="ğŸ” è§£ææ¶ˆæ¯ID",
            description="è§£ææ¶ˆæ¯IDï¼Œæå–æ—¶é—´æˆ³ã€å·¥ä½œæœºå™¨IDç­‰ä¿¡æ¯",
            response_model=Dict[str, Any])
async def parse_message_id_info(message_id: str):
    """è§£ææ¶ˆæ¯IDä¿¡æ¯"""
    try:
        parsed_info = parse_message_id(message_id)
        return {
            "status": "success",
            "data": parsed_info,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è§£ææ¶ˆæ¯IDå¤±è´¥: {str(e)}")


@router.post("/message-id/benchmark",
            summary="ğŸš€ æ¶ˆæ¯IDæ€§èƒ½æµ‹è¯•",
            description="æµ‹è¯•æ¶ˆæ¯IDç”Ÿæˆæ€§èƒ½ï¼Œç”¨äºæ€§èƒ½è°ƒä¼˜",
            response_model=Dict[str, Any])
async def benchmark_message_id_generation(
    count: int = Query(10000, description="æµ‹è¯•æ•°é‡", ge=1000, le=100000),
    id_type: str = Query("snowflake", description="IDç±»å‹")
):
    """æ¶ˆæ¯IDç”Ÿæˆæ€§èƒ½æµ‹è¯•"""
    try:
        id_type_enum = MessageIdType(id_type)
        
        # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        benchmark_result = benchmark_id_generation(count, id_type_enum)
        
        return {
            "status": "success",
            "data": {
                "test_config": {
                    "count": count,
                    "id_type": id_type
                },
                "performance": benchmark_result
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¶ˆæ¯IDæ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")


# ================================================================
# ğŸ› ï¸ å†…éƒ¨è¾…åŠ©å‡½æ•°
# ================================================================

def _log_to_dict(log) -> Dict[str, Any]:
    """å°†æ—¥å¿—å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
    if isinstance(log, AlertPublishLog):
        return {
            "id": log.id,
            "message_id": log.message_id,
            "alert_id": log.alert_id,
            "publish_status": log.publish_status.value if log.publish_status else None,
            "rabbitmq_queue": log.rabbitmq_queue,
            "retry_count": log.retry_count,
            "error_message": log.error_message,
            "created_at": log.created_at.isoformat() if log.created_at else None,
            "updated_at": log.updated_at.isoformat() if log.updated_at else None,
            "last_retry_at": log.last_retry_at.isoformat() if log.last_retry_at else None
        }
    elif isinstance(log, AlertNotificationLog):
        return {
            "id": log.id,
            "message_id": log.message_id,
            "alert_id": log.alert_id,
            "notification_status": log.notification_status.value if log.notification_status else None,
            "notification_channel": log.notification_channel.value if log.notification_channel else None,
            "target_info": log.target_info,
            "retry_count": log.retry_count,
            "error_message": log.error_message,
            "created_at": log.created_at.isoformat() if log.created_at else None,
            "updated_at": log.updated_at.isoformat() if log.updated_at else None,
            "last_retry_at": log.last_retry_at.isoformat() if log.last_retry_at else None,
            "delivered_at": log.delivered_at.isoformat() if log.delivered_at else None
        }
    elif isinstance(log, CompensationTaskLog):
        return {
            "id": log.id,
            "task_id": log.task_id,
            "task_type": log.task_type.value if log.task_type else None,
            "target_table": log.target_table,
            "target_id": log.target_id,
            "execution_result": log.execution_result,
            "processed_count": log.processed_count,
            "error_message": log.error_message,
            "started_at": log.started_at.isoformat() if log.started_at else None,
            "completed_at": log.completed_at.isoformat() if log.completed_at else None,
            "created_at": log.created_at.isoformat() if log.created_at else None,
            "executor_host": log.executor_host,
            "executor_process_id": log.executor_process_id
        }
    else:
        # é€šç”¨è½¬æ¢
        result = {}
        for column in log.__table__.columns:
            value = getattr(log, column.name)
            if isinstance(value, datetime):
                result[column.name] = value.isoformat()
            elif hasattr(value, 'value'):  # æšä¸¾ç±»å‹
                result[column.name] = value.value
            else:
                result[column.name] = value
        return result


def _calculate_publish_stats(logs: List[AlertPublishLog]) -> Dict[str, Any]:
    """è®¡ç®—å‘å¸ƒæ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    if not logs:
        return {
            "total_count": 0,
            "success_count": 0,
            "failed_count": 0,
            "pending_count": 0,
            "success_rate": 0.0
        }
    
    total_count = len(logs)
    success_count = sum(1 for log in logs if log.publish_status == PublishStatus.SUCCESS)
    failed_count = sum(1 for log in logs if log.publish_status == PublishStatus.FAILED)
    pending_count = sum(1 for log in logs if log.publish_status == PublishStatus.PENDING)
    
    return {
        "total_count": total_count,
        "success_count": success_count,
        "failed_count": failed_count,
        "pending_count": pending_count,
        "success_rate": round(success_count / total_count * 100, 2) if total_count > 0 else 0.0
    }


def _calculate_notification_stats(logs: List[AlertNotificationLog]) -> Dict[str, Any]:
    """è®¡ç®—é€šçŸ¥æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    if not logs:
        return {
            "total_count": 0,
            "success_count": 0,
            "failed_count": 0,
            "pending_count": 0,
            "success_rate": 0.0,
            "channel_distribution": {}
        }
    
    total_count = len(logs)
    success_count = sum(1 for log in logs if log.notification_status == NotificationStatus.SUCCESS)
    failed_count = sum(1 for log in logs if log.notification_status == NotificationStatus.FAILED)
    pending_count = sum(1 for log in logs if log.notification_status == NotificationStatus.PENDING)
    
    # ç»Ÿè®¡æ¸ é“åˆ†å¸ƒ
    channel_distribution = {}
    for log in logs:
        channel = log.notification_channel.value if log.notification_channel else "unknown"
        channel_distribution[channel] = channel_distribution.get(channel, 0) + 1
    
    return {
        "total_count": total_count,
        "success_count": success_count,
        "failed_count": failed_count,
        "pending_count": pending_count,
        "success_rate": round(success_count / total_count * 100, 2) if total_count > 0 else 0.0,
        "channel_distribution": channel_distribution
    }


def _calculate_task_stats(logs: List[CompensationTaskLog]) -> Dict[str, Any]:
    """è®¡ç®—ä»»åŠ¡æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    if not logs:
        return {
            "total_count": 0,
            "success_count": 0,
            "failed_count": 0,
            "success_rate": 0.0,
            "task_type_distribution": {}
        }
    
    total_count = len(logs)
    success_count = sum(1 for log in logs if log.execution_result == "SUCCESS")
    failed_count = sum(1 for log in logs if log.execution_result == "FAILED")
    
    # ç»Ÿè®¡ä»»åŠ¡ç±»å‹åˆ†å¸ƒ
    task_type_distribution = {}
    for log in logs:
        task_type = log.task_type.value if log.task_type else "unknown"
        task_type_distribution[task_type] = task_type_distribution.get(task_type, 0) + 1
    
    return {
        "total_count": total_count,
        "success_count": success_count,
        "failed_count": failed_count,
        "success_rate": round(success_count / total_count * 100, 2) if total_count > 0 else 0.0,
        "task_type_distribution": task_type_distribution
    }


def _calculate_overall_stats(publish_logs: List[AlertPublishLog], 
                           notification_logs: List[AlertNotificationLog],
                           task_logs: List[CompensationTaskLog]) -> Dict[str, Any]:
    """è®¡ç®—æ•´ä½“ç»Ÿè®¡ä¿¡æ¯"""
    
    total_operations = len(publish_logs) + len(notification_logs) + len(task_logs)
    
    if total_operations == 0:
        return {
            "total_operations": 0,
            "overall_success_rate": 0.0,
            "compensation_efficiency": 0.0
        }
    
    # è®¡ç®—æ•´ä½“æˆåŠŸç‡
    publish_success = sum(1 for log in publish_logs if log.publish_status == PublishStatus.SUCCESS)
    notification_success = sum(1 for log in notification_logs if log.notification_status == NotificationStatus.SUCCESS)
    task_success = sum(1 for log in task_logs if log.execution_result == "SUCCESS")
    
    total_success = publish_success + notification_success + task_success
    overall_success_rate = round(total_success / total_operations * 100, 2) if total_operations > 0 else 0.0
    
    # è®¡ç®—è¡¥å¿æ•ˆç‡ï¼ˆè¡¥å¿ä»»åŠ¡æˆåŠŸç‡ï¼‰
    compensation_efficiency = round(task_success / len(task_logs) * 100, 2) if task_logs else 0.0
    
    return {
        "total_operations": total_operations,
        "overall_success_rate": overall_success_rate,
        "compensation_efficiency": compensation_efficiency
    } 