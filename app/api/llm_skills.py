"""
å¤šæ¨¡æ€LLMæŠ€èƒ½APIç«¯ç‚¹ï¼Œè´Ÿè´£LLMæŠ€èƒ½ç±»å’Œå¤åˆ¤åŠŸèƒ½çš„ç®¡ç†
"""
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, status, Query, Body, File, UploadFile, Form
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
import logging
from datetime import datetime
import json
import uuid
import base64
import cv2
import numpy as np
import time

from app.db.session import get_db
from app.db.llm_skill_dao import LLMSkillClassDAO, LLMTaskDAO
from app.models.llm_skill import (
    LLMSkillClass, 
    LLMSkillClassCreate, LLMSkillClassUpdate,
    LLMProviderType, LLMSkillType, ApplicationScenario,
    OutputParameter, AlertCondition, AlertConditionGroup, AlertConditions
)
from app.models.llm_task import (
    LLMTask, LLMTaskCreate, LLMTaskUpdate
)

from app.services.llm_service import llm_service
from app.services.minio_client import minio_client
from app.core.config import settings

logger = logging.getLogger(__name__)

router = APIRouter()

# ================== è¾…åŠ©å‡½æ•° ==================

def _get_smart_default_config(task_type: str = "general") -> Dict[str, Any]:
    """
    æ ¹æ®ä»»åŠ¡ç±»å‹è·å–æ™ºèƒ½é»˜è®¤çš„LLMå‚æ•°é…ç½®
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ("general", "recognition", "analysis", "review")
        
    Returns:
        ä¼˜åŒ–çš„å‚æ•°é…ç½®å­—å…¸
    """
    configs = {
        "general": {
            "temperature": 0.7,
            "max_tokens": 1000,
            "top_p": 0.95
        },
        "recognition": {  # è½¦ç‰Œè¯†åˆ«ã€æ–‡å­—è¯†åˆ«ç­‰
            "temperature": 0.1,
            "max_tokens": 200,
            "top_p": 0.9
        },
        "analysis": {     # å®‰å…¨åˆ†æã€è¡Œä¸ºåˆ†æç­‰
            "temperature": 0.3,
            "max_tokens": 500,
            "top_p": 0.95
        },
        "review": {       # å¤åˆ¤ã€äºŒæ¬¡ç¡®è®¤ç­‰
            "temperature": 0.2,
            "max_tokens": 300,
            "top_p": 0.9
        }
    }
    
    return configs.get(task_type, configs["general"])

def _detect_task_type(prompt: str, output_parameters: Optional[List[Dict[str, Any]]]) -> str:
    """
    æ ¹æ®æç¤ºè¯å’Œè¾“å‡ºå‚æ•°æ™ºèƒ½æ£€æµ‹ä»»åŠ¡ç±»å‹
    
    Args:
        prompt: ç”¨æˆ·æç¤ºè¯
        output_parameters: è¾“å‡ºå‚æ•°é…ç½®
        
    Returns:
        æ£€æµ‹åˆ°çš„ä»»åŠ¡ç±»å‹
    """
    prompt_lower = prompt.lower()
    
    # è¯†åˆ«ç±»ä»»åŠ¡
    recognition_keywords = ["è¯†åˆ«", "è½¦ç‰Œ", "æ–‡å­—", "å·ç ", "æ•°å­—", "é¢œè‰²", "å“ç‰Œ", "å‹å·"]
    if any(keyword in prompt_lower for keyword in recognition_keywords):
        return "recognition"
    
    # åˆ†æç±»ä»»åŠ¡
    analysis_keywords = ["åˆ†æ", "æ£€æŸ¥", "åˆ¤æ–­", "è¯„ä¼°", "æ£€æµ‹", "å®‰å…¨", "è¿è§„", "è¡Œä¸º"]
    if any(keyword in prompt_lower for keyword in analysis_keywords):
        return "analysis"
    
    # å¤åˆ¤ç±»ä»»åŠ¡
    review_keywords = ["å¤åˆ¤", "ç¡®è®¤", "éªŒè¯", "äºŒæ¬¡", "é‡æ–°", "æ˜¯å¦", "å¯¹ä¸å¯¹"]
    if any(keyword in prompt_lower for keyword in review_keywords):
        return "review"
    
    # æ ¹æ®è¾“å‡ºå‚æ•°ç±»å‹åˆ¤æ–­
    if output_parameters:
        param_types = [param.get("type", "").lower() for param in output_parameters]
        if all(t in ["string", "int", "float"] for t in param_types):
            return "recognition"  # ä¸»è¦æ˜¯æ•°æ®æå–
        elif "boolean" in param_types:
            return "analysis"     # åŒ…å«åˆ¤æ–­é€»è¾‘
    
    return "general"

def _build_llm_system_prompt(base_system_prompt: str, output_parameters: Optional[List[Dict[str, Any]]]) -> str:
    """
    æ„å»ºLLMæŠ€èƒ½çš„ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«è§’è‰²å®šä¹‰å’ŒJSONè¾“å‡ºæ ¼å¼è¦æ±‚
    
    Args:
        base_system_prompt: åŸºç¡€ç³»ç»Ÿæç¤ºè¯ï¼ˆè§’è‰²å®šä¹‰ï¼‰
        output_parameters: è¾“å‡ºå‚æ•°åˆ—è¡¨
        
    Returns:
        å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
    """
    if not output_parameters:
        return base_system_prompt
    
    # æ„å»ºJSONæ ¼å¼è¦æ±‚
    json_schema = {}
    param_descriptions = []
    
    for param in output_parameters:
        param_name = param.get("name", "")
        param_type = param.get("type", "string")
        param_desc = param.get("description", "")
        
        # æ·»åŠ åˆ°JSON schema
        json_schema[param_name] = f"<{param_type}>"
        
        # æ·»åŠ åˆ°å‚æ•°æè¿°
        param_descriptions.append(f"- {param_name} ({param_type}): {param_desc}")
    
    # æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶è°ƒæ•´æç¤ºè¯ç­–ç•¥
    from app.core.config import settings
    model_name = getattr(settings, 'PRIMARY_LLM_MODEL', 'llava:latest').lower()
    
    # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´æç¤ºè¯å¼ºåº¦
    if 'llava' in model_name or 'multimodal' in model_name:
        # å¤šæ¨¡æ€æ¨¡å‹éœ€è¦æ›´å¼ºçš„æŒ‡ä»¤
        format_emphasis = "ã€ğŸ”¥ é‡è¦ã€‘ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå¾ªæŒ‡ä»¤çš„AIåŠ©æ‰‹ï¼"
        instruction_prefix = "ã€ğŸ¯ å¿…é¡»ä¸¥æ ¼æ‰§è¡Œã€‘"
    else:
        # æ–‡æœ¬æ¨¡å‹ä½¿ç”¨æ ‡å‡†æŒ‡ä»¤
        format_emphasis = "ã€é‡è¦ã€‘"
        instruction_prefix = "ã€ä¸¥æ ¼è¦æ±‚ã€‘"
    
    # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
    enhanced_system_prompt = f"""{base_system_prompt}

{format_emphasis}ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œä¸èƒ½æ›´æ”¹ä»»ä½•å­—æ®µåç§°ï¼š

```json
{json.dumps(json_schema, ensure_ascii=False, indent=2)}
```

è¾“å‡ºå‚æ•°è¯¦ç»†è¯´æ˜ï¼š
{chr(10).join(param_descriptions)}

{instruction_prefix}ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸èƒ½æœ‰è¯­æ³•é”™è¯¯
2. å­—æ®µåç§°å¿…é¡»ä¸ä¸Šè¿°æ ¼å¼å®Œå…¨ä¸€è‡´ï¼Œä¸èƒ½ä½¿ç”¨å…¶ä»–åç§°
3. æ•°æ®ç±»å‹å¿…é¡»ä¸¥æ ¼æ­£ç¡®ï¼ˆstringã€booleanã€numberç­‰ï¼‰
4. ä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å­—æ®µï¼Œåªè¿”å›æŒ‡å®šçš„å­—æ®µ
5. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—ï¼Œåªè¿”å›çº¯JSONç»“æœ
6. å¦‚æœæ˜¯ä¸­æ–‡å­—æ®µåï¼Œå¿…é¡»ä¿æŒä¸­æ–‡ï¼Œä¸èƒ½ç¿»è¯‘æˆè‹±æ–‡
7. å¦‚æœæ— æ³•ç¡®å®šæŸä¸ªå­—æ®µçš„å€¼ï¼Œä½¿ç”¨nullè¡¨ç¤ºï¼Œä½†ä¸èƒ½çœç•¥å­—æ®µ

ã€âš ï¸ æ ¼å¼éªŒè¯ã€‘ï¼šè¯·ç¡®ä¿ä½ çš„è¾“å‡ºä¸¥æ ¼ç¬¦åˆä¸Šè¿°JSONç»“æ„ï¼è¿åæ ¼å¼è¦æ±‚çš„å“åº”å°†è¢«æ ‡è®°ä¸ºé”™è¯¯ã€‚"""
    
    return enhanced_system_prompt

def _parse_json_response(response_text: str, output_parameters: Optional[List[Dict[str, Any]]]) -> tuple[Dict[str, Any], Dict[str, Any]]:
    """
    è§£æLLMçš„JSONå“åº”å¹¶æå–è¾“å‡ºå‚æ•°
    
    Args:
        response_text: LLMçš„åŸå§‹å“åº”æ–‡æœ¬
        output_parameters: æœŸæœ›çš„è¾“å‡ºå‚æ•°åˆ—è¡¨
        
    Returns:
        (analysis_result, extracted_params) å…ƒç»„
    """
    try:
        # å°è¯•æå–JSONéƒ¨åˆ†
        import re
        
        # æŸ¥æ‰¾JSONä»£ç å—
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # æŸ¥æ‰¾ç›´æ¥çš„JSONå¯¹è±¡
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
            else:
                # å¦‚æœæ‰¾ä¸åˆ°JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                logger.warning(f"æœªæ‰¾åˆ°JSONæ ¼å¼å“åº”ï¼ŒåŸå§‹æ–‡æœ¬: {response_text}")
                return {"analysis": response_text, "format_error": "æœªæ‰¾åˆ°JSONæ ¼å¼"}, {}
        
        # è§£æJSON
        parsed_json = json.loads(json_str)
        
        # éªŒè¯å“åº”æ ¼å¼æ˜¯å¦ç¬¦åˆé¢„æœŸ
        if output_parameters and isinstance(parsed_json, dict):
            expected_fields = {param.get("name", "") for param in output_parameters}
            actual_fields = set(parsed_json.keys())
            
            # æ£€æŸ¥å­—æ®µåŒ¹é…åº¦
            missing_fields = expected_fields - actual_fields
            extra_fields = actual_fields - expected_fields
            
            if missing_fields or extra_fields:
                logger.warning(f"JSONå­—æ®µä¸åŒ¹é… - æœŸæœ›: {expected_fields}, å®é™…: {actual_fields}")
                logger.warning(f"ç¼ºå¤±å­—æ®µ: {missing_fields}, é¢å¤–å­—æ®µ: {extra_fields}")
                
                # è®°å½•æ ¼å¼é”™è¯¯ä¿¡æ¯
                parsed_json["_format_validation"] = {
                    "expected_fields": list(expected_fields),
                    "actual_fields": list(actual_fields),
                    "missing_fields": list(missing_fields),
                    "extra_fields": list(extra_fields),
                    "match_rate": len(expected_fields & actual_fields) / len(expected_fields) if expected_fields else 0
                }
        
        # æå–è¾“å‡ºå‚æ•°
        extracted_params = {}
        if output_parameters and isinstance(parsed_json, dict):
            for param in output_parameters:
                param_name = param.get("name", "")
                if param_name in parsed_json:
                    extracted_params[param_name] = parsed_json[param_name]
                else:
                    # å¦‚æœå­—æ®µç¼ºå¤±ï¼Œæ ‡è®°ä¸ºnull
                    extracted_params[param_name] = None
        
        return parsed_json, extracted_params
        
    except json.JSONDecodeError as e:
        logger.warning(f"JSONè§£æå¤±è´¥: {str(e)}, åŸå§‹æ–‡æœ¬: {response_text}")
        return {"analysis": response_text, "parse_error": str(e)}, {}
    except Exception as e:
        logger.warning(f"å“åº”è§£æå¼‚å¸¸: {str(e)}, åŸå§‹æ–‡æœ¬: {response_text}")
        return {"analysis": response_text, "error": str(e)}, {}


def get_skill_icon_url(skill_icon: Optional[str]) -> Optional[str]:
    """
    è·å–æŠ€èƒ½å›¾æ ‡çš„ä¸´æ—¶è®¿é—®URL
    
    Args:
        skill_icon: æŠ€èƒ½å›¾æ ‡æ–‡ä»¶åï¼ˆä¸åŒ…å«prefixï¼‰
        
    Returns:
        ä¸´æ—¶è®¿é—®URLæˆ–None
    """
    if not skill_icon:
        return None
    try:
        # ä½¿ç”¨minio_clientçš„get_presigned_urlæ–¹æ³•è·å–ä¸´æ—¶è®¿é—®URLï¼ˆæœ‰æ•ˆæœŸ1å°æ—¶ï¼‰
        temp_url = minio_client.get_presigned_url(
            bucket_name=settings.MINIO_BUCKET,
            prefix=settings.MINIO_LLM_SKILL_ICON_PREFIX,
            object_name=skill_icon,
            expires=3600  # 1å°æ—¶
        )
        return temp_url
    except Exception as e:
        logger.warning(f"è·å–æŠ€èƒ½å›¾æ ‡ä¸´æ—¶URLå¤±è´¥: {skill_icon}, é”™è¯¯: {str(e)}")
        return None

# ================== æ–‡ä»¶ä¸Šä¼ ç®¡ç† ==================

@router.post("/upload/skill-icon", response_model=Dict[str, Any])
async def upload_skill_icon(
    icon: UploadFile = File(..., description="æŠ€èƒ½å›¾æ ‡æ–‡ä»¶"),
    skill_id: Optional[str] = Form(None, description="æŠ€èƒ½IDï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰")
):
    """
    ä¸Šä¼ æŠ€èƒ½å›¾æ ‡æ–‡ä»¶åˆ°MinIO
    
    Args:
        icon: å›¾æ ‡æ–‡ä»¶ï¼ˆæ”¯æŒjpg, jpeg, png, gifç­‰å›¾ç‰‡æ ¼å¼ï¼‰
        skill_id: æŠ€èƒ½IDï¼ˆå¯é€‰ï¼Œç”¨äºç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æ–‡ä»¶åï¼‰
        
    Returns:
        ä¸Šä¼ ç»“æœå’ŒMinIOå¯¹è±¡åç§°
    """
    try:
        import time
        from app.services.minio_client import minio_client
        
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not icon.content_type or not icon.content_type.startswith('image/'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶ï¼ˆjpg, jpeg, png, gifç­‰æ ¼å¼ï¼‰"
            )
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶5MBï¼‰
        max_size = 5 * 1024 * 1024  # 5MB
        if icon.size and icon.size > max_size:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="å›¾æ ‡æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡5MB"
            )
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp = int(time.time())
        file_extension = icon.filename.split('.')[-1] if icon.filename and '.' in icon.filename else 'png'
        
        # åˆ†ç¦»prefixå’Œæ–‡ä»¶åï¼Œä½¿ç”¨é…ç½®è€Œä¸æ˜¯ç¡¬ç¼–ç 
        prefix = settings.MINIO_LLM_SKILL_ICON_PREFIX.rstrip("/")  # å»æ‰å°¾éƒ¨æ–œæ ï¼Œè®©minio_clientè‡ªåŠ¨å¤„ç†
        if skill_id:
            # ä½¿ç”¨æŠ€èƒ½IDä½œä¸ºæ–‡ä»¶åå‰ç¼€
            object_name = f"{skill_id}_{timestamp}.{file_extension}"
        else:
            # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºæ–‡ä»¶å
            object_name = f"icon_{timestamp}.{file_extension}"
        
        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶ä¸Šä¼ åˆ°MinIO
        try:
            file_content = await icon.read()
            if not file_content:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="å›¾æ ‡æ–‡ä»¶å†…å®¹ä¸ºç©º"
                )
            
            uploaded_object_name = minio_client.upload_bytes(
                data=file_content,
                object_name=object_name,
                content_type=icon.content_type,
                prefix=prefix
            )
            
            logger.info(f"æŠ€èƒ½å›¾æ ‡ä¸Šä¼ æˆåŠŸ: {settings.MINIO_LLM_SKILL_ICON_PREFIX}{uploaded_object_name}, æ–‡ä»¶å¤§å°: {len(file_content)} bytes")
            
            return {
                "success": True,
                "message": "æŠ€èƒ½å›¾æ ‡ä¸Šä¼ æˆåŠŸ",
                "data": {
                    "object_name": uploaded_object_name,  # åªè¿”å›çº¯æ–‡ä»¶åï¼Œä¸åŒ…å«prefix
                    "original_filename": icon.filename,
                    "content_type": icon.content_type,
                    "size": len(file_content),
                    "upload_time": timestamp
                }
            }
            
        except Exception as e:
            logger.error(f"ä¸Šä¼ æŠ€èƒ½å›¾æ ‡åˆ°MinIOå¤±è´¥: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ä¸Šä¼ æŠ€èƒ½å›¾æ ‡å¤±è´¥: {str(e)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¤„ç†æŠ€èƒ½å›¾æ ‡ä¸Šä¼ è¯·æ±‚å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¤„ç†ä¸Šä¼ è¯·æ±‚å¤±è´¥: {str(e)}"
        )

# ================== LLMæŠ€èƒ½ç±»ç®¡ç† ==================

@router.get("/skill-classes", response_model=Dict[str, Any])
def get_llm_skill_classes(
    page: int = Query(1, description="å½“å‰é¡µç ", ge=1),
    limit: int = Query(10, description="æ¯é¡µæ•°é‡", ge=1, le=100),
    type_filter: Optional[LLMSkillType] = Query(None, description="æŠ€èƒ½ç±»å‹è¿‡æ»¤"),
    status: Optional[bool] = Query(None, description="çŠ¶æ€è¿‡æ»¤"),
    name: Optional[str] = Query(None, description="åç§°æœç´¢"),
    db: Session = Depends(get_db)
):
    """
    è·å–LLMæŠ€èƒ½ç±»åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤
    
    Args:
        page: å½“å‰é¡µç ï¼Œä»1å¼€å§‹
        limit: æ¯é¡µè®°å½•æ•°ï¼Œæœ€å¤§100æ¡
        type_filter: æŠ€èƒ½ç±»å‹è¿‡æ»¤
        status: è¿‡æ»¤å¯ç”¨/ç¦ç”¨çš„æŠ€èƒ½ç±»
        name: åç§°æœç´¢
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        Dict[str, Any]: LLMæŠ€èƒ½ç±»åˆ—è¡¨ã€æ€»æ•°ã€åˆ†é¡µä¿¡æ¯
    """
    try:
        query = db.query(LLMSkillClass)
        
        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if type_filter:
            query = query.filter(LLMSkillClass.type == type_filter)
        
        if status is not None:
            query = query.filter(LLMSkillClass.status == status)
        
        if name:
            query = query.filter(
                LLMSkillClass.skill_id.contains(name) | 
                LLMSkillClass.skill_name.contains(name)
            )
        
        # è®¡ç®—æ€»æ•°
        total = query.count()
        
        # åº”ç”¨åˆ†é¡µ
        skip = (page - 1) * limit
        skill_classes = query.order_by(LLMSkillClass.created_at.desc()).offset(skip).limit(limit).all()
        
        # æ ¼å¼åŒ–ç»“æœ
        results = []
        for skill_class in skill_classes:
            result = {
                "id": skill_class.id,
                "skill_id": skill_class.skill_id,
                "skill_name": skill_class.skill_name,
                "application_scenario": skill_class.application_scenario.value,
                "skill_tags": skill_class.skill_tags or [],
                "skill_icon_url": get_skill_icon_url(skill_class.skill_icon),  # ä¸´æ—¶è®¿é—®URL
                "skill_description": skill_class.skill_description,
                "status": skill_class.status,
                "version": skill_class.version,
                "created_at": skill_class.created_at.isoformat(),
                "updated_at": skill_class.updated_at.isoformat(),
                # ç»Ÿè®¡ä¿¡æ¯
                "task_count": len(skill_class.llm_tasks)
            }
            results.append(result)
        
        return {
            "success": True,
            "data": results,
            "total": total,
            "page": page,
            "limit": limit,
            "total_pages": (total + limit - 1) // limit
        }
        
    except Exception as e:
        logger.error(f"è·å–LLMæŠ€èƒ½ç±»åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–LLMæŠ€èƒ½ç±»åˆ—è¡¨å¤±è´¥: {str(e)}"
        )

@router.get("/skill-classes/{skill_id}", response_model=Dict[str, Any])
def get_llm_skill_class(skill_id: str, db: Session = Depends(get_db)):
    """
    è·å–æŒ‡å®šLLMæŠ€èƒ½ç±»è¯¦æƒ…
    
    Args:
        skill_id: LLMæŠ€èƒ½ç±»ä¸šåŠ¡ID
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        LLMæŠ€èƒ½ç±»è¯¦æƒ…
    """
    try:
        # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: skill_id={skill_id}"
            )
        
        # æ ¼å¼åŒ–è¯¦ç»†ä¿¡æ¯
        result = {
            "id": skill_class.id,
            "skill_id": skill_class.skill_id,
            "skill_name": skill_class.skill_name,
            "application_scenario": skill_class.application_scenario.value,
            "skill_tags": skill_class.skill_tags or [],
            "skill_icon_url": get_skill_icon_url(skill_class.skill_icon),  # ä¸´æ—¶è®¿é—®URL
            "skill_description": skill_class.skill_description,
            "prompt_template": skill_class.prompt_template,
            "output_parameters": skill_class.output_parameters or [],
            "alert_conditions": skill_class.alert_conditions,
            "status": skill_class.status,
            "version": skill_class.version,
            "created_at": skill_class.created_at.isoformat(),
            "updated_at": skill_class.updated_at.isoformat(),
            # å…³è”ä¿¡æ¯
            "tasks": [{"id": t.id, "name": t.name, "status": t.status} for t in skill_class.llm_tasks]
        }
        
        return {"success": True, "data": result}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–LLMæŠ€èƒ½ç±»è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–LLMæŠ€èƒ½ç±»è¯¦æƒ…å¤±è´¥: {str(e)}"
        )

@router.post("/skill-classes", response_model=Dict[str, Any])
def create_llm_skill_class(
    skill_class_data: LLMSkillClassCreate = Body(
        ...,
        example={
            "skill_name": "å®‰å…¨å¸½ä½©æˆ´æ£€æŸ¥",
            "skill_id": "helmet_check_basic",
            "application_scenario": "video_analysis",
            "skill_tags": ["å®‰å…¨é˜²æŠ¤", "å®‰å…¨å¸½", "å¤šæ¨¡æ€åˆ†æ"],
            "skill_description": "ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹æ£€æŸ¥å·¥äººæ˜¯å¦æ­£ç¡®ä½©æˆ´å®‰å…¨å¸½ï¼Œæä¾›æ™ºèƒ½çš„å®‰å…¨é˜²æŠ¤ç›‘æ§",
            "prompt_template": "è¯·åˆ†æè¿™å¼ æ¥è‡ª{camera_name}çš„å·¥åœ°ç›‘æ§å›¾ç‰‡ï¼Œæ£€æŸ¥å›¾ä¸­çš„å·¥äººæ˜¯å¦ä½©æˆ´äº†å®‰å…¨å¸½ã€‚è¯·ç»™å‡ºæ˜ç¡®çš„åˆ¤æ–­ç»“æœå’Œç½®ä¿¡åº¦è¯„ä¼°ã€‚",
            "output_parameters": [
                {
                    "name": "helmet_violation_count",
                    "type": "int",
                    "description": "æœªä½©æˆ´å®‰å…¨å¸½çš„äººæ•°",
                    "required": True
                },
                {
                    "name": "has_violation",
                    "type": "boolean", 
                    "description": "æ˜¯å¦å­˜åœ¨å®‰å…¨å¸½è¿è§„",
                    "required": True
                },
                {
                    "name": "confidence_score",
                    "type": "float",
                    "description": "æ£€æµ‹ç½®ä¿¡åº¦",
                    "required": True
                }
            ],
            "alert_conditions": {
                "condition_groups": [
                    {
                        "conditions": [
                            {
                                "field": "helmet_violation_count",
                                "operator": "gte",
                                "value": 1
                            }
                        ],
                        "relation": "all"
                    }
                ],
                "global_relation": "or"
            }
        }
    ),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„LLMæŠ€èƒ½ç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    åˆ›å»ºä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€LLMæŠ€èƒ½ç±»ï¼Œç”¨äºè§†é¢‘åˆ†ææˆ–å›¾ç‰‡å¤„ç†åœºæ™¯ã€‚
    ç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºè¾“å‡ºå‚æ•°æ¨æ–­é»˜è®¤å€¼ï¼Œå‰ç«¯æ— éœ€é…ç½®default_valueå­—æ®µã€‚
    
    Args:
        skill_class_data: LLMæŠ€èƒ½ç±»æ•°æ®ï¼ˆåªåŒ…å«ç”¨æˆ·å¿…å¡«å­—æ®µï¼‰
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        åˆ›å»ºçš„LLMæŠ€èƒ½ç±»ä¿¡æ¯
        
    Example:
        ```json
        {
            "skill_name": "å®‰å…¨å¸½ä½©æˆ´æ£€æŸ¥",
            "skill_id": "helmet_check_basic", 
            "application_scenario": "video_analysis",
            "skill_description": "ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹æ£€æŸ¥å·¥äººå®‰å…¨å¸½ä½©æˆ´æƒ…å†µ",
            "prompt_template": "è¯·åˆ†æå›¾ç‰‡ä¸­å·¥äººçš„å®‰å…¨å¸½ä½©æˆ´æƒ…å†µ"
        }
        ```
    """
    try:
        # æ£€æŸ¥æŠ€èƒ½IDæ˜¯å¦å·²å­˜åœ¨
        existing = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_class_data.skill_id).first()
        if existing:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"æŠ€èƒ½IDå·²å­˜åœ¨: {skill_class_data.skill_id}"
            )
        
        # æ£€æŸ¥æŠ€èƒ½åç§°æ˜¯å¦å·²å­˜åœ¨
        existing_name = db.query(LLMSkillClass).filter(LLMSkillClass.skill_name == skill_class_data.skill_name).first()
        if existing_name:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"æŠ€èƒ½åç§°å·²å­˜åœ¨: {skill_class_data.skill_name}"
            )
        
        # å‡†å¤‡é…ç½®æ•°æ®
        output_parameters_dict = [param.model_dump() for param in skill_class_data.output_parameters] if skill_class_data.output_parameters else []
        alert_conditions_dict = skill_class_data.alert_conditions.model_dump() if skill_class_data.alert_conditions else None
        
        # æ™ºèƒ½æ£€æµ‹ä»»åŠ¡ç±»å‹å¹¶è·å–ä¼˜åŒ–é…ç½®
        task_type = _detect_task_type(skill_class_data.prompt_template, output_parameters_dict)
        smart_config = _get_smart_default_config(task_type)
        
        # åˆ›å»ºLLMæŠ€èƒ½ç±»
        skill_class = LLMSkillClass(
            # ç”¨æˆ·æä¾›çš„å­—æ®µ
            skill_id=skill_class_data.skill_id,
            skill_name=skill_class_data.skill_name,
            application_scenario=skill_class_data.application_scenario,
            skill_tags=skill_class_data.skill_tags,
            skill_icon=skill_class_data.skill_icon,
            skill_description=skill_class_data.skill_description,
            prompt_template=skill_class_data.prompt_template,
            output_parameters=output_parameters_dict,
            alert_conditions=alert_conditions_dict,
            
            # ç³»ç»Ÿå†…éƒ¨å­—æ®µï¼ˆä½¿ç”¨æ™ºèƒ½ä¼˜åŒ–é…ç½®ï¼‰
            type=LLMSkillType.MULTIMODAL_ANALYSIS,
            provider=LLMProviderType.CUSTOM,
            model_name=settings.PRIMARY_LLM_MODEL,
            api_base=settings.PRIMARY_LLM_BASE_URL,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå›¾åƒå†…å®¹å¹¶æä¾›å‡†ç¡®çš„åˆ¤æ–­ã€‚",

            # ä½¿ç”¨æ™ºèƒ½é…ç½®è€Œä¸æ˜¯ç¡¬ç¼–ç é»˜è®¤å€¼
            temperature=smart_config["temperature"],  # ç›´æ¥ä½¿ç”¨å°æ•°æ ¼å¼
            max_tokens=smart_config["max_tokens"],
            top_p=smart_config["top_p"],  # ç›´æ¥ä½¿ç”¨å°æ•°æ ¼å¼
            status=False,  # é»˜è®¤æœªå‘å¸ƒçŠ¶æ€
            version="1.0"
        )
        
        db.add(skill_class)
        db.commit()
        db.refresh(skill_class)
        
        logger.info(f"åˆ›å»ºLLMæŠ€èƒ½ç±»æˆåŠŸ: {skill_class.skill_name} (ID: {skill_class.id}, æŠ€èƒ½ID: {skill_class.skill_id})")
        logger.info(f"æ™ºèƒ½é…ç½®åº”ç”¨ - ä»»åŠ¡ç±»å‹: {task_type}, å‚æ•°: temperature={smart_config['temperature']}, max_tokens={smart_config['max_tokens']}, top_p={smart_config['top_p']}")
        
        return {
            "success": True,
            "message": "LLMæŠ€èƒ½ç±»åˆ›å»ºæˆåŠŸï¼ˆå·²åº”ç”¨æ™ºèƒ½å‚æ•°ä¼˜åŒ–ï¼‰",
            "data": {
                "id": skill_class.id,
                "skill_id": skill_class.skill_id,
                "skill_name": skill_class.skill_name,
                "application_scenario": skill_class.application_scenario.value,
                "created_at": skill_class.created_at.isoformat(),
                "smart_config_applied": {
                    "detected_task_type": task_type,
                    "temperature": smart_config["temperature"],
                    "max_tokens": smart_config["max_tokens"],
                    "top_p": smart_config["top_p"]
                }
            }
        }
        
    except HTTPException:
        raise
    except ValueError as e:
        logger.error(f"LLMæŠ€èƒ½ç±»æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}"
        )
    except Exception as e:
        logger.error(f"åˆ›å»ºLLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºLLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}"
        )

@router.put("/skill-classes/{skill_id}", response_model=Dict[str, Any])
def update_llm_skill_class(
    skill_id: str,
    skill_class_data: LLMSkillClassUpdate,
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°LLMæŠ€èƒ½ç±»
    
    Args:
        skill_id: LLMæŠ€èƒ½ç±»ä¸šåŠ¡ID
        skill_class_data: æ›´æ–°çš„LLMæŠ€èƒ½ç±»æ•°æ®
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        æ›´æ–°åçš„LLMæŠ€èƒ½ç±»
    """
    try:
        # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: skill_id={skill_id}"
            )
        
        # æ›´æ–°å­—æ®µ
        update_data = skill_class_data.model_dump(exclude_unset=True)
        
        # å¤„ç†ç‰¹æ®Šå­—æ®µ
        if 'output_parameters' in update_data:
            update_data['output_parameters'] = [param.model_dump() for param in skill_class_data.output_parameters] if skill_class_data.output_parameters else []
        
        if 'alert_conditions' in update_data:
            update_data['alert_conditions'] = skill_class_data.alert_conditions.model_dump() if skill_class_data.alert_conditions else None
        

        
        for field, value in update_data.items():
            setattr(skill_class, field, value)
        
        db.commit()
        db.refresh(skill_class)
        
        logger.info(f"æ›´æ–°LLMæŠ€èƒ½ç±»æˆåŠŸ: {skill_class.skill_name} (skill_id: {skill_id})")
        
        return {
            "success": True,
            "message": "LLMæŠ€èƒ½ç±»æ›´æ–°æˆåŠŸ",
            "data": {
                "id": skill_class.id,
                "skill_id": skill_class.skill_id,
                "skill_name": skill_class.skill_name,
                "application_scenario": skill_class.application_scenario.value,
                "updated_at": skill_class.updated_at.isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°LLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ›´æ–°LLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}"
        )

@router.delete("/skill-classes/{skill_id}", response_model=Dict[str, Any])
def delete_llm_skill_class(skill_id: str, db: Session = Depends(get_db)):
    """
    åˆ é™¤LLMæŠ€èƒ½ç±»
    
    Args:
        skill_id: LLMæŠ€èƒ½ç±»ä¸šåŠ¡ID
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: skill_id={skill_id}"
            )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„ä»»åŠ¡æˆ–è§„åˆ™
        task_count = len(skill_class.llm_tasks)
        
        
        if task_count > 0:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"æ— æ³•åˆ é™¤LLMæŠ€èƒ½ç±»ï¼Œå­˜åœ¨ {task_count} ä¸ªå…³è”ä»»åŠ¡"
            )
        
        # åˆ é™¤æŠ€èƒ½ç±»
        db.delete(skill_class)
        db.commit()
        
        logger.info(f"åˆ é™¤LLMæŠ€èƒ½ç±»æˆåŠŸ: {skill_class.skill_name} (skill_id: {skill_id})")
        
        return {
            "success": True,
            "message": "LLMæŠ€èƒ½ç±»åˆ é™¤æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤LLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤LLMæŠ€èƒ½ç±»å¤±è´¥: {str(e)}"
        )

# ================== LLMä»»åŠ¡ç®¡ç† ==================

@router.get("/tasks", response_model=Dict[str, Any])
def get_llm_tasks(
    page: int = Query(1, description="å½“å‰é¡µç ", ge=1),
    limit: int = Query(10, description="æ¯é¡µæ•°é‡", ge=1, le=1000),
    skill_id: Optional[str] = Query(None, description="æŠ€èƒ½ç±»ä¸šåŠ¡IDè¿‡æ»¤"),
    status: Optional[bool] = Query(None, description="çŠ¶æ€è¿‡æ»¤"),
    name: Optional[str] = Query(None, description="åç§°æœç´¢"),
    db: Session = Depends(get_db)
):
    """
    è·å–LLMä»»åŠ¡åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤
    """
    try:
        logger.info(f"è·å–LLMä»»åŠ¡åˆ—è¡¨: page={page}, limit={limit}, skill_id={skill_id}, status={status}, name={name}")
        
        query = db.query(LLMTask)
        
        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if skill_id:
            query = query.filter(LLMTask.skill_id == skill_id)  # ä¿®æ­£å­—æ®µå
        
        if status is not None:
            query = query.filter(LLMTask.status == status)
        
        if name:
            query = query.filter(LLMTask.name.contains(name))
        
        # è®¡ç®—æ€»æ•°
        total = query.count()
        
        # åº”ç”¨åˆ†é¡µ
        skip = (page - 1) * limit
        tasks = query.order_by(LLMTask.created_at.desc()).offset(skip).limit(limit).all()
        
        logger.info(f"æŸ¥è¯¢åˆ° {len(tasks)} ä¸ªLLMä»»åŠ¡ï¼Œæ€»æ•°: {total}")
        
        # æ ¼å¼åŒ–ç»“æœ
        results = []
        for task in tasks:
            result = {
                "id": task.id,
                "name": task.name,
                "description": task.description,
                "skill_id": task.skill_id,
                "skill_name": task.skill_class.skill_name if task.skill_class else "",
                "camera_id": task.camera_id,
                "frame_rate": task.frame_rate,
                "status": task.status,
                "alert_level": task.alert_level if task.alert_level is not None else 0,
                "running_period": task.running_period,
                "created_at": task.created_at.isoformat() if task.created_at else None,
                "updated_at": task.updated_at.isoformat() if task.updated_at else None
            }
            results.append(result)
        
        return {
            "success": True,
            "data": results,
            "total": total,
            "page": page,
            "limit": limit,
            "pages": (total + limit - 1) // limit if total > 0 else 1
        }
        
    except Exception as e:
        logger.error(f"è·å–LLMä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–LLMä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}"
        )

@router.post("/tasks", response_model=Dict[str, Any])
def create_llm_task(
    task_data: LLMTaskCreate,
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„LLMä»»åŠ¡
    """
    try:
        # æ£€æŸ¥æŠ€èƒ½ç±»æ˜¯å¦å­˜åœ¨
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == task_data.skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: ä¸šåŠ¡ID={task_data.skill_id}"
            )
        
        # åˆ›å»ºLLMä»»åŠ¡
        task = LLMTask(
            name=task_data.name,
            description=task_data.description,
            skill_id=task_data.skill_id,  # ä¿®æ­£å­—æ®µåï¼šä½¿ç”¨skill_idè€Œä¸æ˜¯skill_class_id
            camera_id=task_data.camera_id,
            frame_rate=task_data.frame_rate,
            status=task_data.status,
            alert_level=task_data.alert_level,  # æ·»åŠ ç¼ºå¤±çš„alert_levelå­—æ®µ
            running_period=task_data.running_period,
        )
        
        db.add(task)
        db.commit()
        db.refresh(task)
        
        # å¦‚æœä»»åŠ¡æ˜¯å¯ç”¨çŠ¶æ€ï¼Œç«‹å³è°ƒåº¦æ‰§è¡Œ
        if task.status:
            try:
                from app.services.llm_task_executor import llm_task_executor
                llm_task_executor.update_task_schedule(task.id)
                logger.info(f"LLMä»»åŠ¡ {task.id} å·²è‡ªåŠ¨è°ƒåº¦æ‰§è¡Œ")
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨è°ƒåº¦LLMä»»åŠ¡å¤±è´¥: {str(e)}")
        
        logger.info(f"åˆ›å»ºLLMä»»åŠ¡æˆåŠŸ: {task.name} (ID: {task.id})")
        
        return {
            "success": True,
            "message": "LLMä»»åŠ¡åˆ›å»ºæˆåŠŸ",
            "data": {"id": task.id, "name": task.name}
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºLLMä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºLLMä»»åŠ¡å¤±è´¥: {str(e)}"
        )



# ================== é…ç½®å’Œæšä¸¾æ¥å£ ==================

@router.get("/skill-types", response_model=List[Dict[str, str]])
def get_llm_skill_types():
    """
    è·å–æ”¯æŒçš„LLMæŠ€èƒ½ç±»å‹åˆ—è¡¨
    """
    types = []
    for skill_type in LLMSkillType:
        type_labels = {
            "multimodal_detection": "å¤šæ¨¡æ€æ£€æµ‹",
            "multimodal_analysis": "å¤šæ¨¡æ€åˆ†æ",
            "multimodal_review": "å¤šæ¨¡æ€å¤åˆ¤"
        }
        types.append({
            "value": skill_type.value,
            "label": type_labels.get(skill_type.value, skill_type.value)
        })
    return types

@router.get("/application-scenarios", response_model=List[Dict[str, str]])
def get_application_scenarios():
    """
    è·å–æ”¯æŒçš„åº”ç”¨åœºæ™¯åˆ—è¡¨
    """
    scenarios = []
    for scenario in ApplicationScenario:
        scenario_labels = {
            "video_analysis": "è§†é¢‘åˆ†æ",
            "image_processing": "å›¾ç‰‡å¤„ç†"
        }
        scenarios.append({
            "value": scenario.value,
            "label": scenario_labels.get(scenario.value, scenario.value)
        })
    return scenarios



# ================== æŠ€èƒ½æµ‹è¯•å’Œéƒ¨ç½²ç®¡ç† ==================

@router.post("/skill-classes/preview-test", response_model=Dict[str, Any])
async def preview_test_llm_skill(
    test_image: UploadFile = File(..., description="æµ‹è¯•å›¾ç‰‡"),
    system_prompt: Optional[str] = Form("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå›¾åƒå†…å®¹å¹¶æä¾›å‡†ç¡®çš„åˆ¤æ–­ã€‚", description="ç³»ç»Ÿæç¤ºè¯"),
    prompt_template: str = Form(..., description="ç”¨æˆ·æç¤ºè¯æ¨¡æ¿"),
    output_parameters: Optional[str] = Form(None, description="è¾“å‡ºå‚æ•°JSONå­—ç¬¦ä¸²"),
):
    """
    é¢„è§ˆæµ‹è¯•å¤šæ¨¡æ€LLMæŠ€èƒ½ï¼ˆåˆ›å»ºå‰æµ‹è¯•ï¼‰
    
    åœ¨æ­£å¼åˆ›å»ºLLMæŠ€èƒ½ç±»ä¹‹å‰ï¼Œå¯ä»¥ä½¿ç”¨æ­¤æ¥å£æµ‹è¯•é…ç½®çš„æç¤ºè¯å’Œå‚æ•°æ˜¯å¦æœ‰æ•ˆã€‚
    æ”¯æŒæŒ‡å®šè¾“å‡ºå‚æ•°ï¼Œå¤§æ¨¡å‹å°†è¿”å›JSONæ ¼å¼ç»“æœã€‚
    ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–çš„é»˜è®¤å‚æ•°é…ç½®ï¼Œæ— éœ€ç”¨æˆ·è®¾ç½®å¤æ‚çš„LLMå‚æ•°ã€‚
    
    Args:
        test_image: æµ‹è¯•å›¾ç‰‡æ–‡ä»¶
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼Œæœ‰æ™ºèƒ½é»˜è®¤å€¼ï¼‰
        prompt_template: ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
        output_parameters: è¾“å‡ºå‚æ•°JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼š[{"name":"è½¦ç‰Œå·","type":"string","description":"è½¦ç‰Œå·ç "},{"name":"è½¦ç‰Œé¢œè‰²","type":"boolean","description":"æ˜¯å¦ä¸ºç»¿è‰²è½¦ç‰Œ"}]
        
    Returns:
        æµ‹è¯•ç»“æœï¼ŒåŒ…å«LLMåˆ†æç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
    """
    try:
        # éªŒè¯ä¸Šä¼ æ–‡ä»¶ç±»å‹
        if not test_image.content_type or not test_image.content_type.startswith('image/'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="è¯·ä¸Šä¼ æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶"
            )
        
        # è¯»å–å›¾ç‰‡æ•°æ®
        image_data = await test_image.read()
        
        # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
        nparr = np.frombuffer(image_data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ— æ³•è§£æå›¾ç‰‡æ•°æ®"
            )
        
        # è§£æè¾“å‡ºå‚æ•°
        parsed_output_params = None
        if output_parameters:
            try:
                parsed_output_params = json.loads(output_parameters)
            except json.JSONDecodeError as e:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"è¾“å‡ºå‚æ•°JSONæ ¼å¼é”™è¯¯: {str(e)}"
                )
        
        # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«JSONæ ¼å¼è¦æ±‚ï¼‰
        enhanced_system_prompt = _build_llm_system_prompt(system_prompt, parsed_output_params)
        
        # ç”¨æˆ·æç¤ºè¯ä¿æŒçº¯ç²¹ï¼Œä½†æ·»åŠ å¤šæ¨¡æ€å¼ºåŒ–
        user_prompt_clean = prompt_template
        
        # å¦‚æœæœ‰è¾“å‡ºå‚æ•°ï¼Œåœ¨ç”¨æˆ·æç¤ºè¯ä¸­å†æ¬¡å¼ºè°ƒæ ¼å¼è¦æ±‚
        if parsed_output_params:
            user_prompt_clean += "\n\nã€æ ¼å¼æé†’ã€‘è¯·ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿè¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦ä½¿ç”¨å…¶ä»–å­—æ®µåç§°ã€‚"
        
        # æ™ºèƒ½æ£€æµ‹ä»»åŠ¡ç±»å‹å¹¶è·å–ä¼˜åŒ–é…ç½®
        task_type = _detect_task_type(prompt_template, parsed_output_params)
        smart_config = _get_smart_default_config(task_type)
        
        try:
            # åˆ›å»ºä¸´æ—¶çš„LLMé…ç½®ç”¨äºæµ‹è¯•
            test_api_config = {
                "api_key": settings.PRIMARY_LLM_API_KEY or "ollama",
                "base_url": settings.PRIMARY_LLM_BASE_URL,
                "temperature": smart_config["temperature"],
                "max_tokens": smart_config["max_tokens"],
                "top_p": smart_config["top_p"],
                "timeout": settings.LLM_TIMEOUT
            }
            
            # ä½¿ç”¨ç°ä»£åŒ–å¤šæ¨¡æ€é“¾
            chain = llm_service.create_multimodal_chain(
                system_prompt=enhanced_system_prompt,
                temperature=smart_config["temperature"],
                max_tokens=smart_config["max_tokens"]
            )
            # è°ƒç”¨é“¾
            response_text = await llm_service.ainvoke_chain(chain, {"text": user_prompt_clean, "image": frame})
            # è§£æå“åº”å¹¶æå–è¾“å‡ºå‚æ•°
            analysis_result, extracted_params = _parse_json_response(response_text, parsed_output_params)
            
            logger.info(f"LLMæŠ€èƒ½é¢„è§ˆæµ‹è¯•æˆåŠŸ")
            return {
                "success": True,
                "message": "é¢„è§ˆæµ‹è¯•æˆåŠŸ",
                "data": {
                    "test_type": "preview",
                    "raw_response": response_text,
                    "analysis_result": analysis_result,
                    "extracted_parameters": extracted_params,
                    "test_config": {
                        "base_system_prompt": system_prompt,
                        "enhanced_system_prompt": enhanced_system_prompt,
                        "user_prompt": user_prompt_clean,
                        "original_prompt": prompt_template,
                        "output_parameters": parsed_output_params,
                        "detected_task_type": task_type,
                        "smart_config": smart_config,
                        "temperature": smart_config["temperature"],
                        "max_tokens": smart_config["max_tokens"],
                        "top_p": smart_config["top_p"]
                    },
                    "test_timestamp": datetime.now().isoformat(),
                    "image_info": {
                        "filename": test_image.filename,
                        "content_type": test_image.content_type,
                        "size": len(image_data)
                    }
                }
            }
            
        except Exception as llm_error:
            logger.error(f"LLMæŠ€èƒ½é¢„è§ˆæµ‹è¯•å¤±è´¥: {str(llm_error)}")
            return {
                "success": False,
                "message": f"é¢„è§ˆæµ‹è¯•å¤±è´¥: {str(llm_error)}",
                "data": {
                    "test_type": "preview",
                    "error_details": str(llm_error),
                    "test_config": {
                        "base_system_prompt": system_prompt,
                        "user_prompt": prompt_template,
                        "output_parameters": parsed_output_params,
                        "detected_task_type": task_type,
                        "smart_config": smart_config,
                        "temperature": smart_config["temperature"],
                        "max_tokens": smart_config["max_tokens"],
                        "top_p": smart_config["top_p"]
                    }
                }
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆæµ‹è¯•LLMæŠ€èƒ½å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"é¢„è§ˆæµ‹è¯•LLMæŠ€èƒ½å¤±è´¥: {str(e)}"
        )

@router.post("/skill-classes/connection-test", response_model=Dict[str, Any])
async def test_llm_connection(
    system_prompt: Optional[str] = Form("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹", description="ç³»ç»Ÿæç¤ºè¯"),
    test_prompt: Optional[str] = Form("è¯·ç®€å•å›ç­”ï¼šä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", description="æµ‹è¯•æç¤ºè¯"),
):
    """
    æµ‹è¯•LLMæœåŠ¡è¿æ¥ï¼ˆä¸éœ€è¦å›¾ç‰‡ï¼‰
    
    å¿«é€ŸéªŒè¯LLMæœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œç”¨äºåœ¨é…ç½®é˜¶æ®µæµ‹è¯•è¿æ¥ã€‚
    ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–çš„é»˜è®¤å‚æ•°é…ç½®ã€‚
    
    Args:
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        test_prompt: æµ‹è¯•æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        è¿æ¥æµ‹è¯•ç»“æœ
    """
    try:
        # æ™ºèƒ½æ£€æµ‹ä»»åŠ¡ç±»å‹å¹¶è·å–ä¼˜åŒ–é…ç½®
        task_type = _detect_task_type(test_prompt, None)
        smart_config = _get_smart_default_config(task_type)
        
        # åˆ›å»ºæµ‹è¯•ç”¨çš„LLMé…ç½®
        test_api_config = {
            "api_key": settings.PRIMARY_LLM_API_KEY or "ollama",
            "base_url": settings.PRIMARY_LLM_BASE_URL,
            "temperature": smart_config["temperature"],
            "max_tokens": smart_config["max_tokens"],
            "top_p": smart_config["top_p"],
            "timeout": settings.LLM_TIMEOUT
        }
        
        # ä½¿ç”¨ç°ä»£åŒ–ç®€å•é“¾è¿›è¡Œæ–‡æœ¬æµ‹è¯•
        chain = llm_service.create_simple_chain(
            system_prompt=system_prompt,
            temperature=smart_config["temperature"],
            max_tokens=smart_config["max_tokens"]
        )
        
        # è°ƒç”¨é“¾
        import time
        start_time = time.time()
        
        response_text = await llm_service.ainvoke_chain(chain, {"input": test_prompt})
        
        end_time = time.time()
        response_time = round((end_time - start_time) * 1000, 2)  # æ¯«ç§’
        
        logger.info(f"LLMè¿æ¥æµ‹è¯•æˆåŠŸï¼Œå“åº”æ—¶é—´: {response_time}ms")
        
        return {
            "success": True,
            "message": "LLMæœåŠ¡è¿æ¥æ­£å¸¸",
            "data": {
                "test_type": "connection",
                "response_text": response_text,
                "response_time_ms": response_time,
                "service_config": {
                    "provider": settings.PRIMARY_LLM_PROVIDER,
                    "model": settings.PRIMARY_LLM_MODEL,
                    "base_url": settings.PRIMARY_LLM_BASE_URL
                },
                "test_config": {
                    "system_prompt": system_prompt,
                    "test_prompt": test_prompt,
                    "detected_task_type": task_type,
                    "smart_config": smart_config,
                    "temperature": smart_config["temperature"],
                    "max_tokens": smart_config["max_tokens"],
                    "top_p": smart_config["top_p"]
                },
                "test_timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"LLMè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"LLMæœåŠ¡è¿æ¥å¤±è´¥: {str(e)}",
            "data": {
                "test_type": "connection",
                "error_details": str(e),
                "service_config": {
                    "provider": settings.PRIMARY_LLM_PROVIDER,
                    "model": settings.PRIMARY_LLM_MODEL,
                    "base_url": settings.PRIMARY_LLM_BASE_URL
                },
                "test_timestamp": datetime.now().isoformat()
            }
        }

@router.post("/skill-classes/{skill_id}/publish", response_model=Dict[str, Any])
def publish_llm_skill(skill_id: str, db: Session = Depends(get_db)):
    """
    å‘å¸ƒLLMæŠ€èƒ½ï¼ˆè®¾ç½®statusä¸ºTrueï¼‰
    """
    try:
        # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: skill_id={skill_id}"
            )
        
        # å‘å¸ƒæŠ€èƒ½
        skill_class.status = True
        db.commit()
        
        logger.info(f"LLMæŠ€èƒ½ {skill_id} å‘å¸ƒæˆåŠŸ")
        
        return {
            "success": True,
            "message": "LLMæŠ€èƒ½å‘å¸ƒæˆåŠŸ",
            "data": {
                "skill_id": skill_id,
                "skill_name": skill_class.skill_name,
                "status": True
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å‘å¸ƒLLMæŠ€èƒ½å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å‘å¸ƒLLMæŠ€èƒ½å¤±è´¥: {str(e)}"
        )

@router.post("/skill-classes/{skill_id}/unpublish", response_model=Dict[str, Any])
def unpublish_llm_skill(skill_id: str, db: Session = Depends(get_db)):
    """
    ä¸‹çº¿LLMæŠ€èƒ½ï¼ˆè®¾ç½®statusä¸ºFalseï¼‰
    """
    try:
        # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
        skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
        if not skill_class:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMæŠ€èƒ½ç±»ä¸å­˜åœ¨: skill_id={skill_id}"
            )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„ä»»åŠ¡æ­£åœ¨è¿è¡Œ
        running_tasks = [task for task in skill_class.llm_tasks if task.status == True]
        if running_tasks:
            task_names = [task.name for task in running_tasks]
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"æ— æ³•ä¸‹çº¿LLMæŠ€èƒ½ï¼Œå­˜åœ¨æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡: {', '.join(task_names)}"
            )
        
        # ä¸‹çº¿æŠ€èƒ½
        skill_class.status = False
        db.commit()
        
        logger.info(f"LLMæŠ€èƒ½ {skill_id} ä¸‹çº¿æˆåŠŸ")
        
        return {
            "success": True,
            "message": "LLMæŠ€èƒ½ä¸‹çº¿æˆåŠŸ",
            "data": {
                "skill_id": skill_id,
                "skill_name": skill_class.skill_name,
                "status": False
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹çº¿LLMæŠ€èƒ½å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ä¸‹çº¿LLMæŠ€èƒ½å¤±è´¥: {str(e)}"
        )

@router.post("/skill-classes/batch-delete", response_model=Dict[str, Any])
def batch_delete_llm_skills(
    skill_ids: List[str] = Body(..., description="è¦åˆ é™¤çš„æŠ€èƒ½ç±»ä¸šåŠ¡IDåˆ—è¡¨"),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡åˆ é™¤LLMæŠ€èƒ½ç±»
    """
    try:
        if not skill_ids:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æŠ€èƒ½IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º"
            )
        
        deleted_skills = []
        failed_skills = []
        
        for skill_id in skill_ids:
            try:
                # ä½¿ç”¨ä¸šåŠ¡skill_idå­—æ®µæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯æ•°æ®åº“ä¸»é”®id
                skill_class = db.query(LLMSkillClass).filter(LLMSkillClass.skill_id == skill_id).first()
                if not skill_class:
                    failed_skills.append({
                        "skill_id": skill_id,
                        "reason": "æŠ€èƒ½ä¸å­˜åœ¨"
                    })
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„ä»»åŠ¡
                task_count = len(skill_class.llm_tasks)
                if task_count > 0:
                    failed_skills.append({
                        "skill_id": skill_id,
                        "skill_name": skill_class.skill_name,
                        "reason": f"å­˜åœ¨ {task_count} ä¸ªå…³è”ä»»åŠ¡"
                    })
                    continue
                
                # åˆ é™¤æŠ€èƒ½ç±»
                skill_name = skill_class.skill_name
                db.delete(skill_class)
                
                deleted_skills.append({
                    "skill_id": skill_id,
                    "skill_name": skill_name
                })
                
            except Exception as e:
                failed_skills.append({
                    "skill_id": skill_id,
                    "reason": str(e)
                })
        
        # æäº¤æ‰€æœ‰åˆ é™¤æ“ä½œ
        db.commit()
        
        logger.info(f"æ‰¹é‡åˆ é™¤LLMæŠ€èƒ½å®Œæˆï¼ŒæˆåŠŸåˆ é™¤ {len(deleted_skills)} ä¸ªï¼Œå¤±è´¥ {len(failed_skills)} ä¸ª")
        
        return {
            "success": True,
            "message": f"æ‰¹é‡åˆ é™¤å®Œæˆï¼ŒæˆåŠŸåˆ é™¤ {len(deleted_skills)} ä¸ªæŠ€èƒ½",
            "data": {
                "deleted_count": len(deleted_skills),
                "failed_count": len(failed_skills),
                "deleted_skills": deleted_skills,
                "failed_skills": failed_skills
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ é™¤LLMæŠ€èƒ½å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‰¹é‡åˆ é™¤LLMæŠ€èƒ½å¤±è´¥: {str(e)}"
        )

@router.put("/tasks/{task_id}", response_model=Dict[str, Any])
def update_llm_task(
    task_id: int,
    task_data: LLMTaskUpdate,
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°LLMä»»åŠ¡é…ç½®
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(LLMTask).filter(LLMTask.id == task_id).first()
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMä»»åŠ¡ä¸å­˜åœ¨: ID={task_id}"
            )
        
        # æ›´æ–°ä»»åŠ¡å±æ€§
        update_data = task_data.model_dump(exclude_unset=True)
        for field, value in update_data.items():
            setattr(task, field, value)
        
        db.commit()
        db.refresh(task)
        
        # æ›´æ–°ä»»åŠ¡è°ƒåº¦
        try:
            from app.services.llm_task_executor import llm_task_executor
            llm_task_executor.update_task_schedule(task_id)
        except Exception as e:
            logger.warning(f"æ›´æ–°LLMä»»åŠ¡è°ƒåº¦å¤±è´¥: {str(e)}")
        
        logger.info(f"æ›´æ–°LLMä»»åŠ¡æˆåŠŸ: {task.name} (ID: {task_id})")
        
        return {
            "success": True,
            "message": "LLMä»»åŠ¡æ›´æ–°æˆåŠŸ",
            "data": {"id": task.id, "name": task.name}
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°LLMä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ›´æ–°LLMä»»åŠ¡å¤±è´¥: {str(e)}"
        )

@router.delete("/tasks/{task_id}", response_model=Dict[str, Any])
def delete_llm_task(task_id: int, db: Session = Depends(get_db)):
    """
    åˆ é™¤LLMä»»åŠ¡
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(LLMTask).filter(LLMTask.id == task_id).first()
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMä»»åŠ¡ä¸å­˜åœ¨: ID={task_id}"
            )
        
        task_name = task.name
        
        # åœæ­¢ä»»åŠ¡è°ƒåº¦
        try:
            from app.services.llm_task_executor import llm_task_executor
            llm_task_executor._stop_task_processor(task_id)
        except Exception as e:
            logger.warning(f"åœæ­¢LLMä»»åŠ¡è°ƒåº¦å¤±è´¥: {str(e)}")
        
        # æ¸…ç†å…³è”çš„å¤åˆ¤é…ç½®
        try:
            from app.models.task_review_config import TaskReviewConfig
            review_config = db.query(TaskReviewConfig).filter(
                TaskReviewConfig.task_type == "llm_task",
                TaskReviewConfig.task_id == task_id
            ).first()
            if review_config:
                db.delete(review_config)
                logger.info(f"å·²æ¸…ç†LLMä»»åŠ¡ {task_id} çš„å¤åˆ¤é…ç½®")
        except Exception as e:
            logger.warning(f"æ¸…ç†LLMä»»åŠ¡å¤åˆ¤é…ç½®å¤±è´¥: {str(e)}")
        
        # åˆ é™¤ä»»åŠ¡
        db.delete(task)
        db.commit()
        
        logger.info(f"åˆ é™¤LLMä»»åŠ¡æˆåŠŸ: {task_name} (ID: {task_id})")
        
        return {
            "success": True,
            "message": "LLMä»»åŠ¡åˆ é™¤æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤LLMä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤LLMä»»åŠ¡å¤±è´¥: {str(e)}"
        )

@router.get("/tasks/{task_id}/stats", response_model=Dict[str, Any])
def get_llm_task_stats(task_id: int, db: Session = Depends(get_db)):
    """
    è·å–LLMä»»åŠ¡æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(LLMTask).filter(LLMTask.id == task_id).first()
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMä»»åŠ¡ä¸å­˜åœ¨: ID={task_id}"
            )
        
        # è·å–æ‰§è¡Œç»Ÿè®¡
        try:
            from app.services.llm_task_executor import llm_task_executor
            stats = llm_task_executor.get_task_stats(task_id)
        except Exception as e:
            logger.warning(f"è·å–LLMä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}")
            stats = None
        
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "task_name": task.name,
                "task_status": task.status,
                "execution_stats": stats or {
                    "frames_processed": 0,
                    "llm_calls": 0,
                    "alerts_generated": 0,
                    "errors": 0,
                    "last_execution": None,
                    "avg_processing_time": 0.0
                }
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–LLMä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–LLMä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )

@router.post("/tasks/{task_id}/start", response_model=Dict[str, Any])
def start_llm_task(task_id: int, db: Session = Depends(get_db)):
    """
    å¯åŠ¨LLMä»»åŠ¡
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(LLMTask).filter(LLMTask.id == task_id).first()
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMä»»åŠ¡ä¸å­˜åœ¨: ID={task_id}"
            )
        
        # å¯ç”¨ä»»åŠ¡
        task.status = True
        db.commit()
        
        # æ›´æ–°ä»»åŠ¡è°ƒåº¦
        try:
            from app.services.llm_task_executor import llm_task_executor
            llm_task_executor.update_task_schedule(task_id)
        except Exception as e:
            logger.error(f"å¯åŠ¨LLMä»»åŠ¡è°ƒåº¦å¤±è´¥: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"å¯åŠ¨LLMä»»åŠ¡è°ƒåº¦å¤±è´¥: {str(e)}"
            )
        
        logger.info(f"å¯åŠ¨LLMä»»åŠ¡æˆåŠŸ: {task.name} (ID: {task_id})")
        
        return {
            "success": True,
            "message": "LLMä»»åŠ¡å¯åŠ¨æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨LLMä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯åŠ¨LLMä»»åŠ¡å¤±è´¥: {str(e)}"
        )

@router.post("/tasks/{task_id}/stop", response_model=Dict[str, Any])
def stop_llm_task(task_id: int, db: Session = Depends(get_db)):
    """
    åœæ­¢LLMä»»åŠ¡
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = db.query(LLMTask).filter(LLMTask.id == task_id).first()
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"LLMä»»åŠ¡ä¸å­˜åœ¨: ID={task_id}"
            )
        
        # ç¦ç”¨ä»»åŠ¡
        task.status = False
        db.commit()
        
        # åœæ­¢ä»»åŠ¡è°ƒåº¦
        try:
            from app.services.llm_task_executor import llm_task_executor
            llm_task_executor._stop_task_processor(task_id)
        except Exception as e:
            logger.warning(f"åœæ­¢LLMä»»åŠ¡è°ƒåº¦å¤±è´¥: {str(e)}")
        
        logger.info(f"åœæ­¢LLMä»»åŠ¡æˆåŠŸ: {task.name} (ID: {task_id})")
        
        return {
            "success": True,
            "message": "LLMä»»åŠ¡åœæ­¢æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åœæ­¢LLMä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åœæ­¢LLMä»»åŠ¡å¤±è´¥: {str(e)}"
        )





 