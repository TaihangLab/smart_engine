from typing import List, Optional, Dict, Any
from datetime import datetime
import logging
from fastapi import APIRouter, Depends, HTTPException, Query, Response, Request
from sqlalchemy.orm import Session
import asyncio
import math

from app.db.session import get_db
from app.models.alert import AlertResponse
from app.services.alert_service import alert_service, register_sse_client, unregister_sse_client, publish_test_alert, connected_clients
from app.services.sse_connection_manager import sse_manager

logger = logging.getLogger(__name__)

router = APIRouter()

@router.get("/stream", description="å®æ—¶æŠ¥è­¦SSEæµ")
async def alert_stream(request: Request):
    """
    åˆ›å»ºSSEè¿æ¥ï¼Œç”¨äºå®æ—¶æ¨é€æŠ¥è­¦ä¿¡æ¯ã€‚
    è¿™ä¸ªç«¯ç‚¹ä¼šä¿æŒè¿æ¥æ‰“å¼€ï¼Œå¹¶åœ¨æœ‰æ–°æŠ¥è­¦æ—¶é€šè¿‡SSEåè®®æ¨é€æ•°æ®ã€‚
    """
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    logger.info(f"æ”¶åˆ°SSEè¿æ¥è¯·æ±‚ï¼Œå®¢æˆ·ç«¯IP: {client_ip}")
    
    # æ³¨å†Œå®¢æˆ·ç«¯ - ä½¿ç”¨è¿æ¥ç®¡ç†å™¨
    client_queue = await register_sse_client(client_ip, user_agent)
    logger.info(f"å·²æ³¨å†ŒSSEå®¢æˆ·ç«¯ï¼Œå®¢æˆ·ç«¯IP: {client_ip}")

    # åˆ›å»ºå“åº”å¯¹è±¡å¹¶è®¾ç½®SSEå¿…éœ€çš„å¤´éƒ¨
    response = Response(
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        }
    )
    logger.debug(f"å·²åˆ›å»ºSSEå“åº”å¯¹è±¡ï¼Œå®¢æˆ·ç«¯IP: {client_ip}")
    
    # åˆ›å»ºSSEæµç”Ÿæˆå™¨
    async def event_generator():
        message_count = 0
        heartbeat_count = 0
        client_id = getattr(client_queue, '_client_id', 'unknown')
        
        try:
            # å‘é€åˆå§‹è¿æ¥æˆåŠŸæ¶ˆæ¯
            logger.debug(f"å‘é€SSEè¿æ¥æˆåŠŸæ¶ˆæ¯ï¼Œå®¢æˆ·ç«¯ID: {client_id}")
            yield "data: {\"event\": \"connected\"}\n\n"
            message_count += 1
            
            # ç­‰å¾…é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
            while True:
                if await request.is_disconnected():
                    logger.info(f"æ£€æµ‹åˆ°SSEå®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œå®¢æˆ·ç«¯ID: {client_id}")
                    break
                
                # ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯ï¼Œè®¾ç½®è¶…æ—¶é˜²æ­¢é˜»å¡
                try:
                    message = await asyncio.wait_for(client_queue.get(), timeout=1.0)
                    yield message
                    message_count += 1
                    logger.debug(f"å·²å‘SSEå®¢æˆ·ç«¯å‘é€æ¶ˆæ¯ï¼Œå®¢æˆ·ç«¯ID: {client_id}, æ¶ˆæ¯è®¡æ•°: {message_count}")
                except asyncio.TimeoutError:
                    # å‘é€å¿ƒè·³ä¿æŒè¿æ¥
                    yield ": heartbeat\n\n"
                    heartbeat_count += 1
                    logger.debug(f"å‘é€SSEå¿ƒè·³ï¼Œå®¢æˆ·ç«¯ID: {client_id}")
                    
        except asyncio.CancelledError:
            # è¿æ¥å·²å–æ¶ˆ
            logger.info(f"SSEè¿æ¥å·²å–æ¶ˆï¼Œå®¢æˆ·ç«¯ID: {client_id}")
            pass
        finally:
            # æ³¨é”€å®¢æˆ·ç«¯
            unregister_sse_client(client_queue)
            logger.info(f"SSEå®¢æˆ·ç«¯è¿æ¥å·²å…³é—­ï¼Œå®¢æˆ·ç«¯ID: {client_id}, å‘é€æ¶ˆæ¯: {message_count}, å¿ƒè·³: {heartbeat_count}")
    
    # è¿”å›SSEå“åº”
    response.body_iterator = event_generator()
    return response

@router.get("/real-time", response_model=Dict[str, Any])
def get_realtime_alerts(
    tag: Optional[str] = Query(None, description="æŒ‰æ ‡ç­¾è¿‡æ»¤"),
    camera_id: Optional[str] = Query(None, description="æŒ‰æ‘„åƒå¤´IDè¿‡æ»¤"),
    camera_name: Optional[str] = Query(None, description="æŒ‰æ‘„åƒå¤´åç§°è¿‡æ»¤"),
    alert_type: Optional[str] = Query(None, description="æŒ‰æŠ¥è­¦ç±»å‹è¿‡æ»¤"),
    alert_level: Optional[int] = Query(None, description="æŒ‰é¢„è­¦ç­‰çº§è¿‡æ»¤"),
    alert_name: Optional[str] = Query(None, description="æŒ‰é¢„è­¦åç§°è¿‡æ»¤"),
    alert_category: Optional[str] = Query(None, description="æŒ‰é¢„è­¦æ¡£æ¡ˆç±»åˆ«æ ‡ç­¾è¿‡æ»¤"),
    location: Optional[str] = Query(None, description="æŒ‰ä½ç½®è¿‡æ»¤"),
    page: int = Query(1, description="é¡µç "),
    limit: int = Query(10, description="æ¯é¡µè®°å½•æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–å®æ—¶é¢„è­¦åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤
    """
    logger.info(f"æ”¶åˆ°è·å–å®æ—¶é¢„è­¦åˆ—è¡¨è¯·æ±‚: tag={tag}, camera_id={camera_id}, camera_name={camera_name}, " 
               f"alert_type={alert_type}, alert_level={alert_level}, alert_name={alert_name}, "
               f"alert_category={alert_category}, location={location}, "
               f"page={page}, limit={limit}")
    
    # è®¡ç®—åˆ†é¡µè·³è¿‡çš„è®°å½•æ•°
    skip = (page - 1) * limit
    
    # è·å–æŠ¥è­¦åˆ—è¡¨
    alerts = alert_service.get_alerts(
        db, 
        camera_id=camera_id,
        camera_name=camera_name,
        alert_type=alert_type,
        alert_level=alert_level,
        alert_name=alert_name,
        alert_category=alert_category,
        location=location,
        skip=skip,
        limit=limit
    )
    
    # æ³¨é‡Šæ‰tagè¿‡æ»¤ä»£ç ï¼Œå› ä¸ºAlertæ¨¡å‹ä¸­æ²¡æœ‰tagså±æ€§
    # å¦‚æœæä¾›äº†æ ‡ç­¾è¿‡æ»¤ï¼Œè¿‡æ»¤åŒ…å«è¯¥æ ‡ç­¾çš„è®°å½•
    # if tag:
    #     alerts = [alert for alert in alerts if tag in alert.tags]
    
    # è·å–æ€»è®°å½•æ•°ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦å•ç‹¬æŸ¥è¯¢ï¼‰
    total = alert_service.get_alerts_count(
        db, 
        camera_id=camera_id,
        camera_name=camera_name,
        alert_type=alert_type,
        alert_level=alert_level,
        alert_name=alert_name,
        alert_category=alert_category,
        location=location
    )
    
    # è®¡ç®—æ€»é¡µæ•°
    try:
        pages = math.ceil(total / limit)
    except (TypeError, ValueError):
        # å¤„ç†æ— æ³•è½¬æ¢ä¸ºæ•´æ•°çš„æƒ…å†µ
        pages = 1
    
    # å°†Alertå¯¹è±¡è½¬æ¢ä¸ºAlertResponseå¯¹è±¡
    alert_responses = [AlertResponse.from_orm(alert) for alert in alerts]
    
    logger.info(f"è·å–å®æ—¶é¢„è­¦åˆ—è¡¨æˆåŠŸï¼Œè¿”å› {len(alerts)} æ¡è®°å½•ï¼Œæ€»å…± {total} æ¡")
    
    # è¿”å›åˆ†é¡µæ•°æ®
    return {
        "alerts": alert_responses,
        "total": total,
        "page": page,
        "limit": limit,
        "pages": pages
    }

@router.get("/{alert_id}", response_model=AlertResponse)
def get_alert(
    alert_id: int,
    db: Session = Depends(get_db)
):
    """
    æ ¹æ®IDè·å–å•ä¸ªæŠ¥è­¦è®°å½•è¯¦æƒ…
    """
    logger.info(f"æ”¶åˆ°è·å–æŠ¥è­¦è¯¦æƒ…è¯·æ±‚: ID={alert_id}")
    
    alert = alert_service.get_alert_by_id(db, str(alert_id))
    if alert is None:
        logger.warning(f"æŠ¥è­¦è®°å½•ä¸å­˜åœ¨: ID={alert_id}")
        raise HTTPException(status_code=404, detail="æŠ¥è­¦è®°å½•ä¸å­˜åœ¨")
    
    logger.info(f"è·å–æŠ¥è­¦è¯¦æƒ…æˆåŠŸ: ID={alert_id}")
    return alert

@router.post("/test", description="å‘é€æµ‹è¯•æŠ¥è­¦ï¼ˆä»…ä¾›æµ‹è¯•ä½¿ç”¨ï¼‰")
def send_test_alert():
    """
    å‘é€æµ‹è¯•æŠ¥è­¦æ¶ˆæ¯åˆ°RabbitMQï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
    """
    logger.info("æ”¶åˆ°å‘é€æµ‹è¯•æŠ¥è­¦è¯·æ±‚")
    
    success = publish_test_alert()
    if success:
        logger.info("æµ‹è¯•æŠ¥è­¦å‘é€æˆåŠŸ")
        return {"message": "æµ‹è¯•æŠ¥è­¦å·²å‘é€"}
    else:
        logger.error("æµ‹è¯•æŠ¥è­¦å‘é€å¤±è´¥")
        raise HTTPException(status_code=500, detail="å‘é€æµ‹è¯•æŠ¥è­¦å¤±è´¥")

@router.get("/sse/status", description="æŸ¥çœ‹SSEè¿æ¥çŠ¶æ€")
async def sse_status():
    """
    è¿”å›å½“å‰SSEè¿æ¥çŠ¶æ€ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•å’Œç›‘æ§
    """
    # è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    stats = sse_manager.get_connection_stats()
    
    # è·å–è¯¦ç»†è¿æ¥ä¿¡æ¯
    detailed_connections = sse_manager.get_detailed_connections()
    
    status_info = {
        "connected_clients": stats["total_connections"],
        "status": "healthy" if stats["total_connections"] >= 0 else "warning",
        "message": f"å½“å‰æœ‰ {stats['total_connections']} ä¸ªSSEå®¢æˆ·ç«¯è¿æ¥",
        "stats": stats,
        "connections": detailed_connections,
        "manager_info": {
            "manager_started": sse_manager.started,
            "cleanup_interval": sse_manager.cleanup_interval,
            "heartbeat_interval": sse_manager.heartbeat_interval,
            "thresholds": {
                "stale_threshold": sse_manager.stale_threshold,
                "suspicious_threshold": sse_manager.suspicious_threshold, 
                "dead_threshold": sse_manager.dead_threshold,
                "max_error_count": sse_manager.max_error_count
            }
        },
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    logger.info(f"ğŸ“Š SSEçŠ¶æ€æŸ¥è¯¢: {stats['total_connections']} ä¸ªè¿æ¥, å¥åº·: {stats['status_distribution']['healthy']}")
    return status_info

@router.post("/sse/cleanup", description="æ‰‹åŠ¨æ¸…ç†æ­»è¿æ¥")
async def manual_cleanup():
    """
    æ‰‹åŠ¨è§¦å‘SSEè¿æ¥æ¸…ç†
    """
    logger.info("ğŸ§¹ æ”¶åˆ°æ‰‹åŠ¨æ¸…ç†SSEè¿æ¥è¯·æ±‚")
    
    if not sse_manager.started:
        raise HTTPException(status_code=503, detail="SSEè¿æ¥ç®¡ç†å™¨æœªå¯åŠ¨")
    
    cleanup_stats = await sse_manager.cleanup_dead_connections()
    
    return {
        "message": "è¿æ¥æ¸…ç†å®Œæˆ",
        "cleanup_stats": cleanup_stats,
        "timestamp": datetime.now().isoformat()
    }

@router.get("/sse/health", description="SSEæœåŠ¡å¥åº·æ£€æŸ¥")
async def sse_health():
    """
    SSEæœåŠ¡å¥åº·æ£€æŸ¥ç«¯ç‚¹
    """
    stats = sse_manager.get_connection_stats()
    
    # å¥åº·çŠ¶æ€åˆ¤æ–­
    health_score = 100
    issues = []
    
    # æ£€æŸ¥è¿æ¥ç®¡ç†å™¨çŠ¶æ€
    if not sse_manager.started:
        health_score -= 50
        issues.append("è¿æ¥ç®¡ç†å™¨æœªå¯åŠ¨")
    
    # æ£€æŸ¥è¿æ¥åˆ†å¸ƒ
    total_connections = stats["total_connections"]
    status_dist = stats["status_distribution"]
    
    if total_connections > 0:
        unhealthy_ratio = (status_dist["suspicious"] + status_dist["dead"]) / total_connections
        if unhealthy_ratio > 0.3:  # è¶…è¿‡30%çš„è¿æ¥ä¸å¥åº·
            health_score -= 30
            issues.append(f"ä¸å¥åº·è¿æ¥æ¯”ä¾‹è¿‡é«˜: {unhealthy_ratio:.2%}")
        
        if status_dist["dead"] > 5:  # æ­»è¿æ¥è¿‡å¤š
            health_score -= 20
            issues.append(f"æ­»è¿æ¥è¿‡å¤š: {status_dist['dead']} ä¸ª")
    
    # ç¡®å®šå¥åº·çŠ¶æ€
    if health_score >= 90:
        status = "healthy"
    elif health_score >= 70:
        status = "warning" 
    else:
        status = "critical"
    
    return {
        "status": status,
        "health_score": health_score,
        "issues": issues,
        "stats": stats,
        "timestamp": datetime.now().isoformat()
    }

@router.get("/compensation/status", description="æŸ¥çœ‹è¡¥å¿æœåŠ¡çŠ¶æ€")
async def compensation_status():
    """
    è¿”å›æŠ¥è­¦è¡¥å¿æœåŠ¡çš„çŠ¶æ€ä¿¡æ¯
    """
    try:
        from app.services.alert_compensation_service import get_compensation_stats
        stats = get_compensation_stats()
        logger.info(f"è¡¥å¿æœåŠ¡çŠ¶æ€æŸ¥è¯¢: {stats}")
        return stats
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢è¡¥å¿æœåŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        return {"error": str(e)}

@router.post("/compensation/trigger", description="æ‰‹åŠ¨è§¦å‘è¡¥å¿æ£€æŸ¥")
async def trigger_compensation():
    """
    æ‰‹åŠ¨è§¦å‘ä¸€æ¬¡è¡¥å¿æ£€æŸ¥ï¼ˆä»…ä¾›è°ƒè¯•ä½¿ç”¨ï¼‰
    """
    try:
        from app.services.alert_compensation_service import compensation_service
        await compensation_service._check_and_compensate()
        logger.info("âœ… æ‰‹åŠ¨è¡¥å¿æ£€æŸ¥å·²è§¦å‘")
        return {"message": "è¡¥å¿æ£€æŸ¥å·²æ‰§è¡Œ", "status": "success"}
    except Exception as e:
        logger.error(f"âŒ æ‰‹åŠ¨è§¦å‘è¡¥å¿å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è§¦å‘è¡¥å¿å¤±è´¥: {str(e)}")

@router.get("/dead-letter/stats", description="æŸ¥çœ‹æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡")
async def dead_letter_stats():
    """
    è·å–æ­»ä¿¡é˜Ÿåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from app.services.rabbitmq_client import rabbitmq_client
        stats = rabbitmq_client.get_dead_letter_queue_stats()
        logger.info(f"æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡æŸ¥è¯¢: {stats}")
        return stats
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ­»ä¿¡é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return {"error": str(e)}

@router.get("/dead-letter/messages", description="æŸ¥çœ‹æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯")
async def get_dead_letter_messages(
    max_count: int = Query(10, description="æœ€å¤§è¿”å›æ¶ˆæ¯æ•°é‡", ge=1, le=100)
):
    """
    è·å–æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆä»…æŸ¥çœ‹ï¼Œä¸å¤„ç†ï¼‰
    """
    try:
        from app.services.rabbitmq_client import rabbitmq_client
        
        # è·å–æ­»ä¿¡æ¶ˆæ¯ï¼ˆä½†ä¸ç¡®è®¤ï¼Œä»…æŸ¥çœ‹ï¼‰
        dead_messages = rabbitmq_client.get_dead_letter_messages(max_count)
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®ï¼ˆç§»é™¤delivery_tagç­‰å†…éƒ¨ä¿¡æ¯ï¼‰
        formatted_messages = []
        for dead_info in dead_messages:
            formatted_message = {
                'message_data': dead_info['message_data'],
                'dead_reason': dead_info.get('dead_reason', 'unknown'),
                'death_count': dead_info.get('death_count', 0),
                'retry_count': dead_info.get('retry_count', 0),
                'first_death_time': dead_info.get('first_death_time'),
                'routing_key': dead_info.get('routing_key')
            }
            formatted_messages.append(formatted_message)
        
        logger.info(f"æŸ¥è¯¢æ­»ä¿¡æ¶ˆæ¯: è¿”å› {len(formatted_messages)} æ¡")
        return {
            "messages": formatted_messages,
            "total_count": len(formatted_messages),
            "max_requested": max_count
        }
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢æ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")

@router.post("/dead-letter/reprocess", description="æ‰‹åŠ¨é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯")
async def reprocess_dead_letters(
    max_count: int = Query(10, description="æœ€å¤§å¤„ç†æ¶ˆæ¯æ•°é‡", ge=1, le=50)
):
    """
    æ‰‹åŠ¨è§¦å‘æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯çš„é‡æ–°å¤„ç†
    """
    try:
        from app.services.alert_compensation_service import compensation_service
        from app.core.config import settings
        
        # é™åˆ¶æœ€å¤§å¤„ç†æ•°é‡ä¸è¶…è¿‡é…ç½®çš„è¡¥å¿æ•°é‡
        max_count = min(max_count, settings.ALERT_MAX_COMPENSATION_COUNT)
        
        logger.info(f"å¼€å§‹æ‰‹åŠ¨é‡æ–°å¤„ç†æ­»ä¿¡æ¶ˆæ¯ï¼Œæœ€å¤§æ•°é‡: {max_count}")
        
        # è·å–æ­»ä¿¡æ¶ˆæ¯
        from app.services.rabbitmq_client import rabbitmq_client
        dead_messages = rabbitmq_client.get_dead_letter_messages(max_count)
        
        if not dead_messages:
            return {
                "message": "æ­»ä¿¡é˜Ÿåˆ—ä¸ºç©º",
                "processed": 0,
                "failed": 0,
                "total": 0
            }
        
        # å¤„ç†æ­»ä¿¡æ¶ˆæ¯
        processed_count = 0
        failed_count = 0
        
        for dead_info in dead_messages:
            try:
                message_data = dead_info['message_data']
                delivery_tag = dead_info['delivery_tag']
                
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡æ–°å¤„ç†
                should_reprocess = compensation_service._should_reprocess_dead_message(dead_info)
                
                if should_reprocess:
                    # é‡æ–°å¤„ç†
                    success = rabbitmq_client.reprocess_dead_message(
                        delivery_tag, 
                        message_data, 
                        increase_retry=True
                    )
                    
                    if success:
                        processed_count += 1
                    else:
                        failed_count += 1
                else:
                    # ä¸¢å¼ƒè¯¥æ¶ˆæ¯
                    rabbitmq_client.channel.basic_ack(delivery_tag=delivery_tag)
                    failed_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å•ä¸ªæ­»ä¿¡æ¶ˆæ¯å¤±è´¥: {str(e)}")
                failed_count += 1
        
        result = {
            "message": "æ­»ä¿¡æ¶ˆæ¯é‡æ–°å¤„ç†å®Œæˆ",
            "processed": processed_count,
            "failed": failed_count,
            "total": len(dead_messages)
        }
        
        logger.info(f"âœ… æ‰‹åŠ¨æ­»ä¿¡å¤„ç†å®Œæˆ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ‰‹åŠ¨é‡æ–°å¤„ç†æ­»ä¿¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é‡æ–°å¤„ç†æ­»ä¿¡å¤±è´¥: {str(e)}")

@router.delete("/dead-letter/purge", description="æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—")
async def purge_dead_letter_queue():
    """
    æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆå±é™©æ“ä½œï¼Œè°¨æ…ä½¿ç”¨ï¼‰
    """
    try:
        from app.services.rabbitmq_client import rabbitmq_client
        
        # æ‰§è¡Œæ¸…ç©ºæ“ä½œ
        purged_count = rabbitmq_client.purge_dead_letter_queue()
        
        result = {
            "message": "æ­»ä¿¡é˜Ÿåˆ—å·²æ¸…ç©º",
            "purged_count": purged_count,
            "status": "success"
        }
        
        logger.warning(f"âš ï¸ æ­»ä¿¡é˜Ÿåˆ—å·²è¢«æ¸…ç©º: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºæ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {str(e)}")

@router.post("/recovery/trigger", summary="è§¦å‘æ¶ˆæ¯æ¢å¤")
async def trigger_message_recovery(
    start_time: Optional[str] = Query(None, description="æ¢å¤èµ·å§‹æ—¶é—´ï¼Œæ ¼å¼: YYYY-MM-DD HH:MM:SS"),
    end_time: Optional[str] = Query(None, description="æ¢å¤ç»“æŸæ—¶é—´ï¼Œæ ¼å¼: YYYY-MM-DD HH:MM:SS"),
    recovery_mode: str = Query("auto", description="æ¢å¤æ¨¡å¼: auto/manual/database/deadletter")
):
    """
    è§¦å‘æ¶ˆæ¯æ¢å¤
    
    æ¢å¤æ¨¡å¼è¯´æ˜ï¼š
    - auto: è‡ªåŠ¨æ¢å¤ï¼ˆæ•°æ®åº“ + æ­»ä¿¡é˜Ÿåˆ—ï¼‰
    - database: ä»…ä»æ•°æ®åº“æ¢å¤
    - deadletter: ä»…ä»æ­»ä¿¡é˜Ÿåˆ—æ¢å¤
    - manual: æ‰‹åŠ¨æ¢å¤ï¼ˆé«˜çº§åˆ«æŠ¥è­¦ï¼‰
    """
    try:
        from datetime import datetime
        from app.services.message_recovery_service import recover_missing_messages
        
        # è§£ææ—¶é—´å‚æ•°
        parsed_start_time = None
        parsed_end_time = None
        
        if start_time:
            parsed_start_time = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
        if end_time:
            parsed_end_time = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")
        
        # æ‰§è¡Œæ¶ˆæ¯æ¢å¤
        recovery_result = await recover_missing_messages(
            start_time=parsed_start_time,
            end_time=parsed_end_time,
            recovery_mode=recovery_mode
        )
        
        return {
            "message": "æ¶ˆæ¯æ¢å¤ä»»åŠ¡å·²å®Œæˆ",
            "recovery_result": recovery_result,
            "timestamp": datetime.now().isoformat()
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"è§¦å‘æ¶ˆæ¯æ¢å¤å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¶ˆæ¯æ¢å¤å¤±è´¥: {str(e)}")

@router.get("/recovery/status", summary="è·å–æ¶ˆæ¯æ¢å¤çŠ¶æ€")
async def get_message_recovery_status():
    """è·å–æ¶ˆæ¯æ¢å¤æœåŠ¡çš„å½“å‰çŠ¶æ€"""
    try:
        from app.services.message_recovery_service import get_recovery_status
        
        status = get_recovery_status()
        
        return {
            "message": "è·å–æ¢å¤çŠ¶æ€æˆåŠŸ",
            "status": status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"è·å–æ¢å¤çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ¢å¤çŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/consistency/check", summary="æ£€æŸ¥æ¶ˆæ¯ä¸€è‡´æ€§")
async def check_message_consistency_endpoint(
    start_time: Optional[str] = Query(None, description="æ£€æŸ¥èµ·å§‹æ—¶é—´ï¼Œæ ¼å¼: YYYY-MM-DD HH:MM:SS"),
    end_time: Optional[str] = Query(None, description="æ£€æŸ¥ç»“æŸæ—¶é—´ï¼Œæ ¼å¼: YYYY-MM-DD HH:MM:SS")
):
    """
    æ£€æŸ¥æ¶ˆæ¯ä¸€è‡´æ€§ï¼Œå‘ç°å¯èƒ½ä¸¢å¤±çš„æ¶ˆæ¯
    
    å¯¹æ¯”MySQLæ•°æ®åº“å’ŒRabbitMQæ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯ï¼Œ
    åˆ†ææ½œåœ¨çš„æ¶ˆæ¯ä¸¢å¤±æƒ…å†µå¹¶æä¾›æ¢å¤å»ºè®®
    """
    try:
        from datetime import datetime
        from app.services.message_recovery_service import check_message_consistency
        
        # è§£ææ—¶é—´å‚æ•°
        parsed_start_time = None
        parsed_end_time = None
        
        if start_time:
            parsed_start_time = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
        if end_time:
            parsed_end_time = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")
        
        # æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥
        consistency_report = await check_message_consistency(
            start_time=parsed_start_time,
            end_time=parsed_end_time
        )
        
        return {
            "message": "æ¶ˆæ¯ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆ",
            "consistency_report": consistency_report,
            "timestamp": datetime.now().isoformat()
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"æ¶ˆæ¯ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¶ˆæ¯ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")

@router.get("/startup/recovery/status", summary="è·å–å¯åŠ¨æ¢å¤çŠ¶æ€")
async def get_startup_recovery_status():
    """è·å–ç³»ç»Ÿå¯åŠ¨æ¢å¤çš„çŠ¶æ€ä¿¡æ¯"""
    try:
        from app.services.startup_recovery_service import get_startup_recovery_status
        
        status = get_startup_recovery_status()
        
        return {
            "message": "è·å–å¯åŠ¨æ¢å¤çŠ¶æ€æˆåŠŸ",
            "startup_recovery": status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"è·å–å¯åŠ¨æ¢å¤çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¯åŠ¨æ¢å¤çŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/startup/recovery/trigger", summary="æ‰‹åŠ¨è§¦å‘å¯åŠ¨æ¢å¤")
async def trigger_startup_recovery():
    """æ‰‹åŠ¨è§¦å‘ä¸€æ¬¡å¯åŠ¨æ¢å¤ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    try:
        from app.services.startup_recovery_service import run_startup_recovery
        
        logger.info("ğŸ”§ æ‰‹åŠ¨è§¦å‘å¯åŠ¨æ¢å¤")
        result = await run_startup_recovery()
        
        return {
            "message": "å¯åŠ¨æ¢å¤å·²å®Œæˆ",
            "recovery_result": result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è§¦å‘å¯åŠ¨æ¢å¤å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨æ¢å¤å¤±è´¥: {str(e)}")

@router.get("/sse/config", description="è·å–SSEé…ç½®ä¿¡æ¯")
async def sse_config():
    """
    è·å–å½“å‰SSEè¿æ¥ç®¡ç†å™¨çš„é…ç½®ä¿¡æ¯
    """
    from app.core.config import settings
    
    sse_config = settings.get_sse_config()
    
    config_info = {
        "current_environment": settings.SSE_ENVIRONMENT,
        "active_config": sse_config,
        "available_environments": {
            "production": {
                "description": "ç”Ÿäº§ç¯å¢ƒé…ç½®",
                "heartbeat_interval": settings.SSE_HEARTBEAT_INTERVAL,
                "stale_threshold": settings.SSE_STALE_THRESHOLD,
                "suspicious_threshold": settings.SSE_SUSPICIOUS_THRESHOLD,
                "dead_threshold": settings.SSE_DEAD_THRESHOLD,
            },
            "security": {
                "description": "å®‰é˜²ç›‘æ§ç³»ç»Ÿé…ç½®",
                "heartbeat_interval": settings.SSE_SECURITY_HEARTBEAT_INTERVAL,
                "stale_threshold": settings.SSE_SECURITY_STALE_THRESHOLD,
                "suspicious_threshold": settings.SSE_SECURITY_SUSPICIOUS_THRESHOLD,
                "dead_threshold": settings.SSE_SECURITY_DEAD_THRESHOLD,
            },
            "highload": {
                "description": "é«˜è´Ÿè½½ç¯å¢ƒé…ç½®",
                "heartbeat_interval": settings.SSE_HIGHLOAD_HEARTBEAT_INTERVAL,
                "max_queue_size": settings.SSE_HIGHLOAD_MAX_QUEUE_SIZE,
                "cleanup_interval": settings.SSE_HIGHLOAD_CLEANUP_INTERVAL,
                "send_timeout": settings.SSE_HIGHLOAD_SEND_TIMEOUT,
            },
            "development": {
                "description": "å¼€å‘æµ‹è¯•ç¯å¢ƒé…ç½®",
                "heartbeat_interval": settings.SSE_DEV_HEARTBEAT_INTERVAL,
                "stale_threshold": settings.SSE_DEV_STALE_THRESHOLD,
                "suspicious_threshold": settings.SSE_DEV_SUSPICIOUS_THRESHOLD,
                "dead_threshold": settings.SSE_DEV_DEAD_THRESHOLD,
            }
        },
        "advanced_features": {
            "connection_pooling": settings.SSE_ENABLE_CONNECTION_POOLING,
            "compression": settings.SSE_ENABLE_COMPRESSION,
            "metrics": settings.SSE_ENABLE_METRICS,
            "backoff": settings.SSE_ENABLE_BACKOFF,
            "health_check": settings.SSE_ENABLE_HEALTH_CHECK,
            "rate_limiting": settings.SSE_ENABLE_RATE_LIMITING,
            "ip_whitelist": settings.SSE_ENABLE_IP_WHITELIST
        },
        "thresholds": {
            "max_connections_per_ip": settings.SSE_MAX_CONNECTIONS_PER_IP,
            "connection_rate_limit": settings.SSE_CONNECTION_RATE_LIMIT,
            "unhealthy_threshold": settings.SSE_UNHEALTHY_THRESHOLD,
            "dead_connection_alert_threshold": settings.SSE_DEAD_CONNECTION_ALERT_THRESHOLD
        },
        "manager_info": {
            "manager_started": sse_manager.started,
            "loaded_config": {
                "heartbeat_interval": sse_manager.heartbeat_interval,
                "cleanup_interval": sse_manager.cleanup_interval,
                "max_queue_size": sse_manager.max_queue_size,
                "send_timeout": sse_manager.send_timeout
            }
        },
        "usage_recommendations": {
            "å®‰é˜²ç›‘æ§ç³»ç»Ÿ": "ä½¿ç”¨ SSE_ENVIRONMENT=security è·å¾—æ›´é¢‘ç¹çš„è¿æ¥æ£€æµ‹",
            "é«˜å¹¶å‘åœºæ™¯": "ä½¿ç”¨ SSE_ENVIRONMENT=highload ä¼˜åŒ–æ€§èƒ½",
            "å¼€å‘è°ƒè¯•": "ä½¿ç”¨ SSE_ENVIRONMENT=development å¿«é€Ÿæ£€æµ‹é—®é¢˜",
            "ç”Ÿäº§éƒ¨ç½²": "ä½¿ç”¨ SSE_ENVIRONMENT=production å¹³è¡¡æ€§èƒ½å’Œç¨³å®šæ€§"
        },
        "timestamp": datetime.now().isoformat()
    }
    
    logger.info(f"ğŸ“‹ SSEé…ç½®ä¿¡æ¯æŸ¥è¯¢: å½“å‰ç¯å¢ƒ={settings.SSE_ENVIRONMENT}")
    return config_info